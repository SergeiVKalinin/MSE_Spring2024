{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxxsyixKd0pLeMXna1VFXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeiVKalinin/MSE_Spring2024/blob/main/Module%204/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final exam for the UTK MSE510 Spring 2024 Course, please choose **one** project from the list below. Feel free to suggest own project of comparable complexity - esp. if aligned with your research. When submitting the final, please make sure that each point in the bulleted list becomes the section in submitted Colab and COlab can run from the beginnign to the end."
      ],
      "metadata": {
        "id": "gP8-w3fsDeMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE as generative model"
      ],
      "metadata": {
        "id": "x-jkhFV-FCqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Select dataset (standard or your own) that comprizes some high dimensional data (e.g. images or molecular represnetations) and labels (e.g. attributes such as \"beard/no beard\", \"glasses/no glasses\" for images, or molecular properties). If the data set is too large for the Colab, feel free to downscale image resolution, select subset of data, etc.\n",
        "- Build or adapt the variational autoencoder that can work with the data\n",
        "- Construct the latent representation and latent distribution of the data (for 2D latent space)\n",
        "- Plot the reconstruction error and KL divergence erros as a function of the dimensionality of the latent space (say from 1 to 10)\n",
        "- Explore the distribution of ground truth labels in 2D latent space\n",
        "- Implement the generative model - e.g. build the (linear) relationship between the labels and latent variables, and check if you can change the attibute of image (e.g. encode the image into the latent space, shift it across the direction responsible for certain attribute, and decode from this point)\n"
      ],
      "metadata": {
        "id": "YaRwZYUQLVWw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFGi7FeqH7lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Ising Exploration"
      ],
      "metadata": {
        "id": "WIgcibIPOBer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create Ising Function that will return thermodynamic parameter as a function of two exchange integrals\n",
        "- Explore 2D Ising in the Jc, Js parameter space using Bayesian Optimization.\n",
        "- Realize pure exploratory algorithms minimizing the uncertainty\n",
        "- Realize the greedy algoritm that will attempt to maximize the chosen thermodynamic parameter\n",
        "- Compare the difference\n",
        "- Ideally the output will be the video illustarting the exploration process and evolution of prediction, uncertainty, and acquisition function."
      ],
      "metadata": {
        "id": "EnbqKew0Lt8E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2cubGt2OFFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic Regression as an input to Bayesian Optimization"
      ],
      "metadata": {
        "id": "uNptClvkOFij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Select a own data set (either standard optimization function like Auckley of Forrestal, or just some interesting function like A sin (b x) + c x, Bessel function, etc.)\n",
        "- Generate data by sampling this function with noise, sigma, over certain interval (e.g. [0, 5])\n",
        "- Do symbolic regression over the interval\n",
        "- Choose 3 possible functions generated by PySR\n",
        "- Create the probabilistic models based on these functions (meaning convert them to the probabilistic models and add the priors on parameters).\n",
        "- Do Bayesian Inference for all three functions\n",
        "- Calculate WAIC\n",
        "- Plot the predicitive mean and uncertainty for all three models over larger interval (e.g. [-5, 10]); compare to the ground truth\n",
        "- Plot the integrated predictive uncertainty and the MSE between prediction and ground truth as a function of noise, sigma, during sampling.  "
      ],
      "metadata": {
        "id": "KmFu7uyKOMGk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQv54kRBKui7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}