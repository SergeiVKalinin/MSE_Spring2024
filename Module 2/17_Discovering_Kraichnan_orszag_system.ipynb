{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeiVKalinin/MSE_Spring2024/blob/main/Module%202/17_Discovering_Kraichnan_orszag_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Notebook from: https://github.com/ShuaiGuo16/PINN_symbolic_regression\n",
        "- Detailed walk-through is at: https://towardsdatascience.com/discovering-differential-equations-with-physics-informed-neural-networks-and-symbolic-regression-c28d279c0b4d\n",
        "- Original paper is: https://arxiv.org/pdf/2307.08107.pdf"
      ],
      "metadata": {
        "id": "8I7c6HJQKdx7"
      },
      "id": "8I7c6HJQKdx7"
    },
    {
      "cell_type": "markdown",
      "id": "62f2bc3e",
      "metadata": {
        "id": "62f2bc3e"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, we investigate combining PINN with symbolic regression to discover ODE systems. Our target ODE system can be written as follows:\n",
        "\n",
        "\\begin{align}\n",
        "    \\frac{du_1}{dt} &= e^{-t/10}u_2u_3 \\\\\n",
        "    \\frac{du_2}{dt} &= u_1u_3 \\\\\n",
        "    \\frac{du_3}{dt} &= -2u_1u_2 \\\\\n",
        "\\end{align}\n",
        "\n",
        "with an initial condition of $u_1(0)=1, u_2(0)=0.8, u_3(0)=0.5$.\n",
        "\n",
        "For our case study, we assume that we only know the right-hand side of the third equation to be a linear transformation of $u_1u_2$, and have no knowledge of the first two equations. Essentially, we can rewrite the ODE system as follows:\n",
        "\n",
        "\\begin{align}\n",
        "    \\frac{du_1}{dt} &= f_1(t, u_1, u_2, u_3) \\\\\n",
        "    \\frac{du_2}{dt} &= f_2(t, u_1, u_2, u_3) \\\\\n",
        "    \\frac{du_3}{dt} &= au_1u_2 + b \\\\\n",
        "\\end{align}\n",
        "\n",
        "where $a, b$ are unknown coefficients and $f_1, f_2$ are the unknown functions. By using PINN and symbolic regression, we aim to calibrate the values of $a$ and $b$, as well as the functional forms of $f_1$ and $f_2$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ec7144d",
      "metadata": {
        "id": "5ec7144d"
      },
      "source": [
        "### 0. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eafb443d",
      "metadata": {
        "id": "eafb443d"
      },
      "outputs": [],
      "source": [
        "# Common packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "from scipy.integrate import solve_ivp\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d26d7f0",
      "metadata": {
        "id": "2d26d7f0"
      },
      "source": [
        "### 1. Observational data generation\n",
        "\n",
        "To begin with, we need to generate simulation data of the investigated ODE system, which will be used later for inverse calibration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8fea802",
      "metadata": {
        "id": "b8fea802"
      },
      "outputs": [],
      "source": [
        "def simulate_ODEs(u_init, t_span, obs_num):\n",
        "    \"\"\"Simulate the ODE system and obtain observational data.\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "    u_init: list of initial condition for u1, u2, and u3\n",
        "    t_span: lower and upper time limit for simulation\n",
        "    obs_num: number of observational data points\n",
        "\n",
        "    Outputs:\n",
        "    --------\n",
        "    u_obs: observed data for u's\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the target ODEs\n",
        "    def odes(t, u):\n",
        "        du1dt = np.exp(-t/10) * u[1] * u[2]\n",
        "        du2dt = u[0] * u[2]\n",
        "        du3dt = -2 * u[0] * u[1]\n",
        "        return [du1dt, du2dt, du3dt]\n",
        "\n",
        "    # Solve ODEs\n",
        "    t_eval = np.linspace(t_span[0], t_span[1], obs_num)\n",
        "    sol = solve_ivp(odes, t_span, u_init, method='RK45', t_eval=t_eval)\n",
        "\n",
        "    # Restrcture obtained data\n",
        "    u_obs = np.column_stack((sol.t, sol.y[0], sol.y[1], sol.y[2]))\n",
        "\n",
        "    return u_obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f120d3ce",
      "metadata": {
        "id": "f120d3ce"
      },
      "outputs": [],
      "source": [
        "# Set up simulation\n",
        "u_init = [1, 0.8, 0.5]\n",
        "t_span = [0, 10]\n",
        "obs_num = 1000\n",
        "\n",
        "# Solve ODEs\n",
        "u_obs = simulate_ODEs(u_init, t_span, obs_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d26d4429",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "d26d4429",
        "outputId": "6816998c-65b5-4f5a-9452-94ce92f1085a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the results\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "plt.plot(u_obs[:, 0], u_obs[:, 1], label='u1')\n",
        "plt.plot(u_obs[:, 0], u_obs[:, 2], label='u2')\n",
        "plt.plot(u_obs[:, 0], u_obs[:, 3], label='u3')\n",
        "\n",
        "plt.xlabel('Time (t)', fontsize=14)\n",
        "plt.ylabel('u values', fontsize=14)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.legend(fontsize=12, frameon=True)\n",
        "\n",
        "plt.savefig('u_profile.png', bbox_inches='tight', transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89993b5",
      "metadata": {
        "id": "b89993b5"
      },
      "source": [
        "### 2. Organize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "37aa8149",
      "metadata": {
        "id": "37aa8149"
      },
      "outputs": [],
      "source": [
        "# Set batch size\n",
        "data_batch_size = 100\n",
        "ODE_batch_size = 1000\n",
        "\n",
        "# Samples for enforcing data loss\n",
        "X_train_data = tf.convert_to_tensor(u_obs[:, :1], dtype=tf.float32)\n",
        "y_train_data = tf.convert_to_tensor(u_obs[:, 1:], dtype=tf.float32)\n",
        "train_ds_data = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))\n",
        "train_ds_data = train_ds_data.shuffle(1000).batch(data_batch_size)\n",
        "\n",
        "# Samples for enforcing ODE residual loss\n",
        "N_collocation = 10000\n",
        "X_train_ODE = tf.convert_to_tensor(np.linspace(0, 10, N_collocation).reshape(-1, 1), dtype=tf.float32)\n",
        "train_ds_ODE = tf.data.Dataset.from_tensor_slices((X_train_ODE))\n",
        "train_ds_ODE = train_ds_ODE.shuffle(10*N_collocation).batch(ODE_batch_size)\n",
        "\n",
        "# Generate testing data\n",
        "u_obs_test = simulate_ODEs(u_init, t_span, 5000)\n",
        "X_test, y_test = u_obs_test[:, :1], u_obs_test[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20d5c75",
      "metadata": {
        "id": "f20d5c75"
      },
      "source": [
        "### 3. Physics-informed Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1179fd77",
      "metadata": {
        "id": "1179fd77"
      },
      "source": [
        "#### Define a custom layer for hosting unknown parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2645bed4",
      "metadata": {
        "id": "2645bed4"
      },
      "outputs": [],
      "source": [
        "class ParameterLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, a, b, trainable=True):\n",
        "        super(ParameterLayer, self).__init__()\n",
        "        self._a = tf.convert_to_tensor(a, dtype=tf.float32)\n",
        "        self._b = tf.convert_to_tensor(b, dtype=tf.float32)\n",
        "        self.trainable = trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.a = self.add_weight(\"a\", shape=(1,),\n",
        "                                 initializer=tf.keras.initializers.Constant(value=self._a),\n",
        "                                 trainable=self.trainable)\n",
        "        self.b = self.add_weight(\"b\", shape=(1,),\n",
        "                                 initializer=tf.keras.initializers.Constant(value=self._b),\n",
        "                                 trainable=self.trainable)\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d29de4",
      "metadata": {
        "id": "f3d29de4"
      },
      "source": [
        "#### Define Physics-informed Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a0713d01",
      "metadata": {
        "id": "a0713d01"
      },
      "outputs": [],
      "source": [
        "def u_net(input_layer):\n",
        "    \"\"\"Definition of the network for u prediction.\"\"\"\n",
        "\n",
        "    hidden = input_layer\n",
        "    for _ in range(2):\n",
        "        hidden = tf.keras.layers.Dense(50, activation=\"tanh\")(hidden)\n",
        "    output = tf.keras.layers.Dense(3)(hidden)\n",
        "    return output\n",
        "\n",
        "\n",
        "def f_net(input_layers, a_init=None, b_init=None):\n",
        "    \"\"\"Definition of the network for f prediction.\"\"\"\n",
        "\n",
        "    hidden = tf.keras.layers.Concatenate()(input_layers)\n",
        "    for _ in range(2):\n",
        "        hidden = tf.keras.layers.Dense(50, activation=\"tanh\")(hidden)\n",
        "    output = tf.keras.layers.Dense(2)(hidden)\n",
        "    output = ParameterLayer(a_init, b_init)(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "def create_PINN(a_init=None, b_init=None, verbose=False):\n",
        "    \"\"\"Definition of a physics-informed neural network.\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "    a_init: initial value for parameter a\n",
        "    b_init: initial value for parameter b\n",
        "    verbose: boolean, indicate whether to show the model summary\n",
        "\n",
        "    Outputs:\n",
        "    --------\n",
        "    model: the PINN model\n",
        "    \"\"\"\n",
        "    # Input\n",
        "    t_input = tf.keras.Input(shape=(1,), name=\"time\")\n",
        "\n",
        "    # u-NN\n",
        "    u = u_net(t_input)\n",
        "\n",
        "    # f-NN\n",
        "    f = f_net([t_input, u], a_init, b_init)\n",
        "\n",
        "    # PINN model\n",
        "    model = tf.keras.models.Model(inputs=t_input, outputs=[u, f])\n",
        "\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdec88aa",
      "metadata": {
        "id": "cdec88aa"
      },
      "source": [
        "#### ODE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "88d2ac2b",
      "metadata": {
        "id": "88d2ac2b"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def ODE_residual_calculator(t, model):\n",
        "    \"\"\"ODE residual calculation.\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "    t: temporal coordinate\n",
        "    model: PINN model\n",
        "\n",
        "    Outputs:\n",
        "    --------\n",
        "    ODE_residual: residual of the governing ODE\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve parameters\n",
        "    a = model.layers[-1].a\n",
        "    b = model.layers[-1].b\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(t)\n",
        "        u, f = model(t)\n",
        "\n",
        "    # Calculate gradients\n",
        "    dudt = tape.batch_jacobian(u, t)[:, :, 0]\n",
        "    du1_dt, du2_dt, du3_dt = dudt[:, :1], dudt[:, 1:2], dudt[:, 2:]\n",
        "\n",
        "    # Compute residuals\n",
        "    res1 = du1_dt - f[:, :1]\n",
        "    res2 = du2_dt - f[:, 1:]\n",
        "    res3 = du3_dt - (a*u[:, :1]*u[:, 1:2] + b)\n",
        "    ODE_residual = tf.concat([res1, res2, res3], axis=1)\n",
        "\n",
        "    return ODE_residual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78156e5",
      "metadata": {
        "id": "c78156e5"
      },
      "source": [
        "#### Gradient descent step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3c2f5842",
      "metadata": {
        "id": "3c2f5842"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(X_ODE, X, y, IC_weight, ODE_weight, data_weight, model):\n",
        "    \"\"\"Calculate gradients of the total loss with respect to network model parameters.\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "    X_ODE: Collocation points for evaluating ODE residuals\n",
        "    X: observed samples\n",
        "    y: target values of the observed samples\n",
        "    IC_weight: weight for initial condition loss\n",
        "    ODE_weight: weight for ODE loss\n",
        "    data_weight: weight for data loss\n",
        "    model: PINN model\n",
        "\n",
        "    Outputs:\n",
        "    --------\n",
        "    ODE_loss: calculated ODE loss\n",
        "    IC_loss: calculated initial condition loss\n",
        "    data_loss: calculated data loss\n",
        "    total_loss: weighted sum of ODE loss, initial condition loss, and data loss\n",
        "    gradients: gradients of the total loss with respect to network model parameters.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_weights)\n",
        "\n",
        "        # Initial condition prediction\n",
        "        y_pred_IC, _ = model(tf.zeros((1, 1)))\n",
        "\n",
        "        # Equation residual\n",
        "        ODE_residual = ODE_residual_calculator(t=X_ODE, model=model)\n",
        "\n",
        "        # Data loss\n",
        "        y_pred_data, _ = model(X)\n",
        "\n",
        "        # Calculate loss\n",
        "        IC_loss = tf.reduce_mean(keras.losses.mean_squared_error(tf.constant([[1.0, 0.8, 0.5]]), y_pred_IC))\n",
        "        ODE_loss = tf.reduce_mean(tf.square(ODE_residual))\n",
        "        data_loss = tf.reduce_mean(keras.losses.mean_squared_error(y, y_pred_data))\n",
        "\n",
        "        # Weight loss\n",
        "        total_loss = IC_loss*IC_weight + ODE_loss*ODE_weight + data_loss*data_weight\n",
        "\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "\n",
        "    return ODE_loss, IC_loss, data_loss, total_loss, gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11429e3",
      "metadata": {
        "id": "f11429e3"
      },
      "source": [
        "#### Define loss tracking class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "663c26c8",
      "metadata": {
        "id": "663c26c8"
      },
      "outputs": [],
      "source": [
        "class LossTracking:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mean_total_loss = keras.metrics.Mean()\n",
        "        self.mean_IC_loss = keras.metrics.Mean()\n",
        "        self.mean_ODE_loss = keras.metrics.Mean()\n",
        "        self.mean_data_loss = keras.metrics.Mean()\n",
        "        self.loss_history = defaultdict(list)\n",
        "\n",
        "    def update(self, total_loss, IC_loss, ODE_loss, data_loss):\n",
        "        self.mean_total_loss(total_loss)\n",
        "        self.mean_IC_loss(IC_loss)\n",
        "        self.mean_ODE_loss(ODE_loss)\n",
        "        self.mean_data_loss(data_loss)\n",
        "\n",
        "    def reset(self):\n",
        "        self.mean_total_loss.reset_states()\n",
        "        self.mean_IC_loss.reset_states()\n",
        "        self.mean_ODE_loss.reset_states()\n",
        "        self.mean_data_loss.reset_states()\n",
        "\n",
        "    def print(self):\n",
        "        print(f\"IC={self.mean_IC_loss.result().numpy():.4e}, \\\n",
        "              ODE={self.mean_ODE_loss.result().numpy():.4e}, \\\n",
        "              data={self.mean_data_loss.result().numpy():.4e}, \\\n",
        "              total_loss={self.mean_total_loss.result().numpy():.4e}\")\n",
        "\n",
        "    def history(self):\n",
        "        self.loss_history['total_loss'].append(self.mean_total_loss.result().numpy())\n",
        "        self.loss_history['IC_loss'].append(self.mean_IC_loss.result().numpy())\n",
        "        self.loss_history['ODE_loss'].append(self.mean_ODE_loss.result().numpy())\n",
        "        self.loss_history['Data_loss'].append(self.mean_data_loss.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f0fef0",
      "metadata": {
        "id": "a3f0fef0"
      },
      "source": [
        "#### Define callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d052c164",
      "metadata": {
        "id": "d052c164"
      },
      "outputs": [],
      "source": [
        "class PrintParameters(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"\\na: {self.model.layers[-1].a.numpy()}, b: {self.model.layers[-1].b.numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265cf8ff",
      "metadata": {
        "id": "265cf8ff"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7c7f4186",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c7f4186",
        "outputId": "3146b60f-b516-4818-bcb3-0454548343c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "IC=1.8311e-01,               ODE=1.1178e+00,               data=2.0604e+00,               total_loss=3.3614e+00\n",
            "1/1 [==============================] - 1s 646ms/step\n",
            "val_IC: 8.0284e-02, val_ODE: 6.2069e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.91459167], b: [0.84386784]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step\n",
            "RMSE: 1.1092809147618323\n",
            "Epoch 2:\n",
            "IC=6.6242e-02,               ODE=2.0240e-01,               data=6.5691e-01,               total_loss=9.2555e-01\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 1.7574e-02, val_ODE: 1.5573e-01, lr: 2.00e-02\n",
            "\n",
            "a: [-0.86703265], b: [0.7309146]\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "RMSE: 0.7832820487556227\n",
            "Epoch 3:\n",
            "IC=8.3233e-03,               ODE=8.2483e-02,               data=5.2726e-01,               total_loss=6.1806e-01\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "val_IC: 2.8140e-03, val_ODE: 4.2431e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.85736495], b: [0.60960954]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n",
            "RMSE: 0.720868311024897\n",
            "Epoch 4:\n",
            "IC=3.3327e-03,               ODE=5.3837e-02,               data=4.3521e-01,               total_loss=4.9238e-01\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "val_IC: 5.7088e-03, val_ODE: 4.4260e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.86800086], b: [0.50513315]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.6312579155037701\n",
            "Epoch 5:\n",
            "IC=8.3678e-03,               ODE=4.1908e-02,               data=3.7453e-01,               total_loss=4.2480e-01\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "val_IC: 7.3148e-03, val_ODE: 2.7505e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.8833454], b: [0.40319037]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 104ms/step\n",
            "RMSE: 0.6003962042850611\n",
            "Epoch 6:\n",
            "IC=2.9404e-03,               ODE=2.8838e-02,               data=3.5394e-01,               total_loss=3.8572e-01\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 9.9896e-04, val_ODE: 2.9538e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.89927036], b: [0.3118494]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.5826759589545345\n",
            "Epoch 7:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.0138e-03,               ODE=2.2132e-02,               data=3.3951e-01,               total_loss=3.6466e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.7848e-03, val_ODE: 2.2942e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.91411334], b: [0.23034337]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.575391951984167\n",
            "Epoch 8:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.8654e-03,               ODE=1.8546e-02,               data=3.3093e-01,               total_loss=3.5234e-01\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.7080e-03, val_ODE: 1.9950e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.9277191], b: [0.16122337]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.5727680392049598\n",
            "Epoch 9:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.5982e-03,               ODE=1.4440e-02,               data=3.2807e-01,               total_loss=3.4411e-01\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.0172e-03, val_ODE: 1.6276e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.9397909], b: [0.10407896]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.5671426346564457\n",
            "Epoch 10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.9782e-03,               ODE=1.3347e-02,               data=3.2442e-01,               total_loss=3.3974e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.3389e-03, val_ODE: 9.2452e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-0.9508367], b: [0.0571215]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.5683669784848819\n",
            "Epoch 11:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.5767e-03,               ODE=1.0889e-02,               data=3.2399e-01,               total_loss=3.3645e-01\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7371e-03, val_ODE: 1.1452e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.96108323], b: [0.02307638]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.5631324920040532\n",
            "Epoch 12:\n",
            "IC=1.8511e-03,               ODE=1.0735e-02,               data=3.1979e-01,               total_loss=3.3237e-01\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 5.7062e-04, val_ODE: 1.0211e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.97140735], b: [-0.00230208]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.5617083784367436\n",
            "Epoch 13:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.2854e-03,               ODE=1.1513e-02,               data=3.1670e-01,               total_loss=3.2950e-01\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5517e-03, val_ODE: 9.4637e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-0.9817926], b: [-0.01961468]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.5587996538920483\n",
            "Epoch 14:\n",
            "IC=1.5341e-03,               ODE=1.0807e-02,               data=3.1485e-01,               total_loss=3.2719e-01\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 3.0232e-04, val_ODE: 1.1158e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-0.9922949], b: [-0.02988543]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.5603707903909447\n",
            "Epoch 15:\n",
            "IC=3.0504e-03,               ODE=1.2167e-02,               data=3.1606e-01,               total_loss=3.3128e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5676e-04, val_ODE: 1.2396e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.003063], b: [-0.041054]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.5602286745737348\n",
            "Epoch 16:\n",
            "IC=3.2455e-03,               ODE=1.1700e-02,               data=3.1283e-01,               total_loss=3.2778e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.2995e-03, val_ODE: 8.5074e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.014416], b: [-0.04336591]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.5532324093673585\n",
            "Epoch 17:\n",
            "IC=1.6769e-03,               ODE=1.0323e-02,               data=3.0656e-01,               total_loss=3.1856e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8599e-03, val_ODE: 7.9929e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.0265807], b: [-0.04766824]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.5491556299222043\n",
            "Epoch 18:\n",
            "IC=1.5102e-03,               ODE=9.1693e-03,               data=3.0126e-01,               total_loss=3.1194e-01\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 4.1184e-03, val_ODE: 7.8401e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.040202], b: [-0.04679481]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "RMSE: 0.5472483998032817\n",
            "Epoch 19:\n",
            "IC=1.6051e-03,               ODE=1.2606e-02,               data=3.0312e-01,               total_loss=3.1733e-01\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 8.3582e-04, val_ODE: 8.3945e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.0535818], b: [-0.04618051]\n",
            "1/1 [==============================] - 0s 55ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.5432516093102933\n",
            "Epoch 20:\n",
            "IC=8.6370e-04,               ODE=1.3929e-02,               data=2.9462e-01,               total_loss=3.0942e-01\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5633e-03, val_ODE: 7.3464e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.0667987], b: [-0.04500891]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.5390509536173174\n",
            "Epoch 21:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.0906e-03,               ODE=9.5333e-03,               data=2.9032e-01,               total_loss=3.0094e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.1721e-03, val_ODE: 6.9762e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.0811166], b: [-0.04230371]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.5354671006847115\n",
            "Epoch 22:\n",
            "IC=1.2400e-03,               ODE=7.4013e-03,               data=2.8328e-01,               total_loss=2.9192e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.5050e-03, val_ODE: 8.0407e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.096041], b: [-0.03579605]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.5402586126848083\n",
            "Epoch 23:\n",
            "IC=2.4715e-03,               ODE=9.1112e-03,               data=2.8415e-01,               total_loss=2.9573e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.2107e-03, val_ODE: 1.0593e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1104987], b: [-0.03461592]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.527382955554608\n",
            "Epoch 24:\n",
            "IC=2.0065e-03,               ODE=9.2482e-03,               data=2.7520e-01,               total_loss=2.8646e-01\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "val_IC: 7.4072e-04, val_ODE: 8.5564e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1243827], b: [-0.03039108]\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "RMSE: 0.5231555168022429\n",
            "Epoch 25:\n",
            "IC=8.5046e-04,               ODE=8.9409e-03,               data=2.6892e-01,               total_loss=2.7871e-01\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 2.1221e-03, val_ODE: 8.3031e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.138125], b: [-0.02612301]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.5120420571292303\n",
            "Epoch 26:\n",
            "IC=1.0846e-03,               ODE=1.1162e-02,               data=2.6283e-01,               total_loss=2.7508e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6385e-03, val_ODE: 1.0579e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1515361], b: [-0.02531309]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.5069892982733765\n",
            "Epoch 27:\n",
            "IC=1.8923e-03,               ODE=1.5369e-02,               data=2.5621e-01,               total_loss=2.7347e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.9599e-03, val_ODE: 2.1434e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1640997], b: [-0.02222892]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.4942723006892452\n",
            "Epoch 28:\n",
            "IC=3.1955e-03,               ODE=1.2697e-02,               data=2.3967e-01,               total_loss=2.5556e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 7.1161e-04, val_ODE: 1.0502e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1763262], b: [-0.01897999]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.4878878134651172\n",
            "Epoch 29:\n",
            "IC=1.5896e-03,               ODE=1.3334e-02,               data=2.2696e-01,               total_loss=2.4188e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6289e-04, val_ODE: 1.2353e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.1906284], b: [-0.01566565]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.4604423457585823\n",
            "Epoch 30:\n",
            "IC=3.6167e-03,               ODE=1.7723e-02,               data=2.0767e-01,               total_loss=2.2901e-01\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.5654e-02, val_ODE: 3.0850e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.2052075], b: [-0.0141959]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.44045526638771293\n",
            "Epoch 31:\n",
            "IC=4.1320e-03,               ODE=2.8711e-02,               data=1.9248e-01,               total_loss=2.2533e-01\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.4636e-04, val_ODE: 1.7467e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.2192584], b: [-0.00914426]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.4059052030916495\n",
            "Epoch 32:\n",
            "IC=2.1605e-03,               ODE=2.2328e-02,               data=1.6554e-01,               total_loss=1.9003e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5711e-03, val_ODE: 1.8084e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.2366813], b: [-0.00540634]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.39383125745138825\n",
            "Epoch 33:\n",
            "IC=3.4201e-03,               ODE=2.1717e-02,               data=1.3715e-01,               total_loss=1.6229e-01\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0647e-04, val_ODE: 1.4986e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.2583684], b: [-0.00012223]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.3486065231311085\n",
            "Epoch 34:\n",
            "IC=1.1037e-03,               ODE=1.9787e-02,               data=1.1799e-01,               total_loss=1.3888e-01\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 4.1604e-03, val_ODE: 1.5604e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.2816763], b: [0.00597614]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.34282824884358426\n",
            "Epoch 35:\n",
            "IC=1.6491e-03,               ODE=2.0424e-02,               data=1.0053e-01,               total_loss=1.2261e-01\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.2564e-04, val_ODE: 2.1756e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.3078233], b: [0.01182121]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.2936233979005472\n",
            "Epoch 36:\n",
            "IC=1.3238e-03,               ODE=2.0956e-02,               data=8.1813e-02,               total_loss=1.0409e-01\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.1763e-03, val_ODE: 2.9758e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.3369782], b: [0.0194141]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.29613037482907023\n",
            "Epoch 37:\n",
            "IC=1.4043e-03,               ODE=2.4823e-02,               data=7.7539e-02,               total_loss=1.0377e-01\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0740e-03, val_ODE: 2.0735e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.3681024], b: [0.0263746]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.2664597664306277\n",
            "Epoch 38:\n",
            "IC=1.3173e-03,               ODE=2.0677e-02,               data=6.5605e-02,               total_loss=8.7600e-02\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.2978e-03, val_ODE: 2.1501e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.4010493], b: [0.03435153]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.251607338321899\n",
            "Epoch 39:\n",
            "IC=9.9304e-04,               ODE=1.9905e-02,               data=5.7388e-02,               total_loss=7.8286e-02\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1044e-04, val_ODE: 1.6423e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.4323705], b: [0.04230584]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.22155234837972085\n",
            "Epoch 40:\n",
            "IC=7.5170e-04,               ODE=1.8719e-02,               data=5.0456e-02,               total_loss=6.9926e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.8071e-04, val_ODE: 1.5095e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.4651304], b: [0.0491484]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.21423618749866066\n",
            "Epoch 41:\n",
            "IC=3.3134e-04,               ODE=1.4902e-02,               data=4.4289e-02,               total_loss=5.9523e-02\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.4333e-04, val_ODE: 1.3864e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.4986359], b: [0.05208162]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.20340420274654772\n",
            "Epoch 42:\n",
            "IC=2.8775e-04,               ODE=1.3628e-02,               data=4.0017e-02,               total_loss=5.3933e-02\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.8553e-06, val_ODE: 1.3793e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.5309825], b: [0.05539658]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "RMSE: 0.20638764579738883\n",
            "Epoch 43:\n",
            "IC=4.0109e-04,               ODE=1.3654e-02,               data=3.8361e-02,               total_loss=5.2416e-02\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "val_IC: 7.3573e-05, val_ODE: 9.9802e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.5624276], b: [0.05837671]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.18500255541314864\n",
            "Epoch 44:\n",
            "IC=3.0962e-04,               ODE=1.0492e-02,               data=3.5169e-02,               total_loss=4.5971e-02\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "val_IC: 7.5039e-04, val_ODE: 1.1897e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.5926293], b: [0.0612087]\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "RMSE: 0.18478317497913407\n",
            "Epoch 45:\n",
            "IC=3.7239e-04,               ODE=1.0010e-02,               data=3.3326e-02,               total_loss=4.3709e-02\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 5.3034e-04, val_ODE: 1.5331e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.6220853], b: [0.06226432]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "RMSE: 0.17576554275467796\n",
            "Epoch 46:\n",
            "IC=4.7559e-04,               ODE=1.0496e-02,               data=3.0442e-02,               total_loss=4.1414e-02\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 1.0183e-03, val_ODE: 1.2435e-02, lr: 2.00e-02\n",
            "\n",
            "a: [-1.649675], b: [0.06431895]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.1932244424310856\n",
            "Epoch 47:\n",
            "IC=7.5959e-04,               ODE=1.0100e-02,               data=3.1119e-02,               total_loss=4.1979e-02\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 2.4119e-04, val_ODE: 6.0465e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.675901], b: [0.06441275]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.15452240997529285\n",
            "Epoch 48:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.0888e-04,               ODE=7.8020e-03,               data=2.6728e-02,               total_loss=3.5139e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.5755e-04, val_ODE: 6.1747e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.7020042], b: [0.0641787]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.15451750287341587\n",
            "Epoch 49:\n",
            "IC=9.0610e-04,               ODE=8.6222e-03,               data=2.4093e-02,               total_loss=3.3621e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.4458e-04, val_ODE: 7.8247e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.7248597], b: [0.06354418]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.15061994559227831\n",
            "Epoch 50:\n",
            "IC=7.5640e-04,               ODE=6.8924e-03,               data=2.2758e-02,               total_loss=3.0407e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.1797e-04, val_ODE: 6.7136e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.7460481], b: [0.06160576]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.15641941787131158\n",
            "Epoch 51:\n",
            "IC=6.6510e-04,               ODE=6.4961e-03,               data=1.9733e-02,               total_loss=2.6894e-02\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.1661e-04, val_ODE: 2.8492e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.7661011], b: [0.0581836]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.1287775812272855\n",
            "Epoch 52:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.7501e-04,               ODE=4.4046e-03,               data=1.5383e-02,               total_loss=2.0363e-02\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 5.2904e-04, val_ODE: 3.3338e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.7845991], b: [0.05656564]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "RMSE: 0.12329609325334191\n",
            "Epoch 53:\n",
            "IC=4.1964e-04,               ODE=3.0316e-03,               data=1.4120e-02,               total_loss=1.7571e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.9612e-04, val_ODE: 4.2479e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.802242], b: [0.05473738]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.11250090920673153\n",
            "Epoch 54:\n",
            "IC=5.8322e-04,               ODE=3.1742e-03,               data=1.3087e-02,               total_loss=1.6844e-02\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.4263e-04, val_ODE: 3.1502e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8184364], b: [0.05280132]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.11620318638283976\n",
            "Epoch 55:\n",
            "IC=4.4522e-04,               ODE=3.0183e-03,               data=1.1903e-02,               total_loss=1.5367e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.5132e-04, val_ODE: 1.9890e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8333203], b: [0.05154547]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.10415921646736769\n",
            "Epoch 56:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.6435e-04,               ODE=1.6539e-03,               data=1.0706e-02,               total_loss=1.2625e-02\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.6501e-04, val_ODE: 1.6193e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8478214], b: [0.05034304]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.10319272946744881\n",
            "Epoch 57:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.1966e-04,               ODE=1.6463e-03,               data=1.0116e-02,               total_loss=1.1881e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6458e-04, val_ODE: 9.7292e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8618715], b: [0.04920726]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.09882875904422227\n",
            "Epoch 58:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.4027e-04,               ODE=1.2817e-03,               data=9.3087e-03,               total_loss=1.0731e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.3586e-05, val_ODE: 1.2854e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8749394], b: [0.04769534]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0947200100969282\n",
            "Epoch 59:\n",
            "IC=1.0520e-04,               ODE=1.3009e-03,               data=9.1949e-03,               total_loss=1.0601e-02\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.5110e-04, val_ODE: 1.1270e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8873786], b: [0.04733246]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.09336856505618957\n",
            "Epoch 60:\n",
            "IC=2.8606e-04,               ODE=1.3780e-03,               data=8.7893e-03,               total_loss=1.0453e-02\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 6.3432e-04, val_ODE: 1.9027e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.8985666], b: [0.04645601]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.09400140024707758\n",
            "Epoch 61:\n",
            "IC=6.6004e-04,               ODE=2.3779e-03,               data=8.5619e-03,               total_loss=1.1600e-02\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 9.6980e-04, val_ODE: 1.6570e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9093223], b: [0.04532528]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "RMSE: 0.0887135515960314\n",
            "Epoch 62:\n",
            "IC=2.8831e-04,               ODE=1.5841e-03,               data=7.6371e-03,               total_loss=9.5096e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6329e-04, val_ODE: 2.1821e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9191482], b: [0.04471238]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.08489952902454848\n",
            "Epoch 63:\n",
            "IC=1.7816e-04,               ODE=1.2799e-03,               data=7.2469e-03,               total_loss=8.7051e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.1427e-04, val_ODE: 2.8585e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9284993], b: [0.04363191]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.08961095727915448\n",
            "Epoch 64:\n",
            "IC=4.1261e-04,               ODE=1.8421e-03,               data=7.3246e-03,               total_loss=9.5792e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3087e-04, val_ODE: 1.6052e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9365042], b: [0.04295018]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0838580234454788\n",
            "Epoch 65:\n",
            "IC=3.3960e-04,               ODE=1.5695e-03,               data=6.9170e-03,               total_loss=8.8261e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8697e-05, val_ODE: 1.1973e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.944352], b: [0.04218499]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.08117947190695779\n",
            "Epoch 66:\n",
            "IC=2.1881e-04,               ODE=1.2509e-03,               data=6.3085e-03,               total_loss=7.7781e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.4666e-04, val_ODE: 1.2291e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9519169], b: [0.0421285]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0805954379914771\n",
            "Epoch 67:\n",
            "IC=6.9232e-04,               ODE=2.1113e-03,               data=6.6042e-03,               total_loss=9.4078e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.0543e-05, val_ODE: 9.8127e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.958642], b: [0.04170248]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.07696922034545112\n",
            "Epoch 68:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.9111e-04,               ODE=2.5937e-03,               data=6.4201e-03,               total_loss=9.5050e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.1961e-04, val_ODE: 2.3534e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9640191], b: [0.04147082]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.08028771176558984\n",
            "Epoch 69:\n",
            "IC=3.5991e-04,               ODE=1.8815e-03,               data=6.2038e-03,               total_loss=8.4452e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.3457e-04, val_ODE: 2.2223e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9697257], b: [0.04078675]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.07595363707419742\n",
            "Epoch 70:\n",
            "IC=2.9129e-04,               ODE=1.5571e-03,               data=5.9467e-03,               total_loss=7.7951e-03\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 9.0409e-05, val_ODE: 1.0484e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.974614], b: [0.04030545]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.07185178650854822\n",
            "Epoch 71:\n",
            "IC=6.9336e-04,               ODE=2.3851e-03,               data=5.8970e-03,               total_loss=8.9755e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.2353e-05, val_ODE: 1.1516e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9792013], b: [0.03955022]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.07231390611844558\n",
            "Epoch 72:\n",
            "IC=2.4821e-04,               ODE=1.3982e-03,               data=5.4223e-03,               total_loss=7.0687e-03\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "val_IC: 2.2768e-04, val_ODE: 1.4018e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9833088], b: [0.03910173]\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "RMSE: 0.07304385480164716\n",
            "Epoch 73:\n",
            "IC=1.8752e-04,               ODE=1.2419e-03,               data=5.0952e-03,               total_loss=6.5246e-03\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "val_IC: 3.6569e-04, val_ODE: 1.5367e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9878725], b: [0.03814718]\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "RMSE: 0.07005299724692222\n",
            "Epoch 74:\n",
            "IC=3.9822e-04,               ODE=1.7738e-03,               data=4.9719e-03,               total_loss=7.1439e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7984e-04, val_ODE: 2.3449e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.991902], b: [0.0372756]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.07423159440238428\n",
            "Epoch 75:\n",
            "IC=5.7540e-04,               ODE=2.7631e-03,               data=5.3291e-03,               total_loss=8.6675e-03\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "val_IC: 1.2146e-03, val_ODE: 4.6138e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.99507], b: [0.03793557]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "RMSE: 0.0775297567853176\n",
            "Epoch 76:\n",
            "IC=5.0599e-04,               ODE=2.2413e-03,               data=4.9418e-03,               total_loss=7.6892e-03\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 6.0021e-05, val_ODE: 9.8321e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9976349], b: [0.03752854]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "RMSE: 0.06534611489425347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77:\n",
            "IC=9.8379e-04,               ODE=3.7431e-03,               data=5.2891e-03,               total_loss=1.0016e-02\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "val_IC: 1.3422e-03, val_ODE: 4.1043e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9993498], b: [0.03729029]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.07675123506314308\n",
            "Epoch 78:\n",
            "IC=1.1896e-03,               ODE=4.6877e-03,               data=5.4108e-03,               total_loss=1.1288e-02\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "val_IC: 1.9967e-03, val_ODE: 5.5147e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9999338], b: [0.0372407]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.07554317051780089\n",
            "Epoch 79:\n",
            "IC=1.1338e-03,               ODE=3.2294e-03,               data=4.5650e-03,               total_loss=8.9282e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 4.1382e-04, val_ODE: 3.1746e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.999865], b: [0.03661]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.06576211807076114\n",
            "Epoch 80:\n",
            "IC=4.6620e-04,               ODE=1.7437e-03,               data=4.0873e-03,               total_loss=6.2972e-03\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 2.2436e-05, val_ODE: 8.5869e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0013764], b: [0.03635711]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.06411786110347616\n",
            "Epoch 81:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.6225e-04,               ODE=1.0044e-03,               data=3.8476e-03,               total_loss=5.0142e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.4036e-05, val_ODE: 1.3975e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.004147], b: [0.03525011]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.059959333455566075\n",
            "Epoch 82:\n",
            "IC=2.5915e-04,               ODE=1.5333e-03,               data=3.8613e-03,               total_loss=5.6538e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.1811e-04, val_ODE: 2.3207e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0071106], b: [0.03499047]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.06260725955943185\n",
            "Epoch 83:\n",
            "IC=1.8227e-04,               ODE=1.1767e-03,               data=3.5367e-03,               total_loss=4.8956e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7403e-05, val_ODE: 1.0130e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0098107], b: [0.0342346]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.056306382758288843\n",
            "Epoch 84:\n",
            "IC=6.6490e-05,               ODE=9.2866e-04,               data=3.3522e-03,               total_loss=4.3474e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.9739e-05, val_ODE: 8.9528e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.012477], b: [0.03398784]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.055865349455679\n",
            "Epoch 85:\n",
            "IC=3.1485e-04,               ODE=1.3569e-03,               data=3.3897e-03,               total_loss=5.0614e-03\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 1.3334e-03, val_ODE: 2.7103e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0147746], b: [0.03376833]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.05997281687586729\n",
            "Epoch 86:\n",
            "IC=6.5675e-04,               ODE=2.8643e-03,               data=4.1466e-03,               total_loss=7.6677e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6457e-05, val_ODE: 5.9880e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0153236], b: [0.03298452]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.05655135131598446\n",
            "Epoch 87:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.6697e-04,               ODE=1.7295e-03,               data=3.3116e-03,               total_loss=5.2081e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.2797e-04, val_ODE: 7.8834e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0158942], b: [0.03206239]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.05708427549897186\n",
            "Epoch 88:\n",
            "IC=1.6697e-04,               ODE=9.2305e-04,               data=3.0454e-03,               total_loss=4.1354e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 8.0697e-05, val_ODE: 8.3119e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0171971], b: [0.03126732]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.051836751122317386\n",
            "Epoch 89:\n",
            "IC=1.3556e-04,               ODE=9.6698e-04,               data=2.8237e-03,               total_loss=3.9262e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.4237e-05, val_ODE: 7.1504e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0186553], b: [0.0300624]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.05130563389258484\n",
            "Epoch 90:\n",
            "IC=1.3956e-04,               ODE=8.6985e-04,               data=2.6154e-03,               total_loss=3.6248e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.4083e-05, val_ODE: 6.2245e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0199745], b: [0.02990726]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.051882791686276124\n",
            "Epoch 91:\n",
            "IC=6.8729e-05,               ODE=6.3736e-04,               data=2.4940e-03,               total_loss=3.2001e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.9018e-05, val_ODE: 5.6512e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0214396], b: [0.02930793]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04829601386128942\n",
            "Epoch 92:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.8463e-05,               ODE=6.4066e-04,               data=2.3460e-03,               total_loss=3.0751e-03\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 6.1062e-05, val_ODE: 1.2419e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0227985], b: [0.02831588]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04839471904510424\n",
            "Epoch 93:\n",
            "IC=1.2584e-04,               ODE=1.0065e-03,               data=2.5309e-03,               total_loss=3.6633e-03\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 2.1780e-04, val_ODE: 1.3697e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.023596], b: [0.02761138]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.047791108697644\n",
            "Epoch 94:\n",
            "IC=2.7212e-04,               ODE=1.3966e-03,               data=2.4379e-03,               total_loss=4.1066e-03\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 7.0430e-04, val_ODE: 1.7664e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0242872], b: [0.02645862]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.050609796025799916\n",
            "Epoch 95:\n",
            "IC=3.6881e-04,               ODE=1.8730e-03,               data=2.5433e-03,               total_loss=4.7851e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.2680e-04, val_ODE: 2.8464e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0239356], b: [0.02617137]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.05080782431834459\n",
            "Epoch 96:\n",
            "IC=7.9111e-04,               ODE=3.8584e-03,               data=3.1346e-03,               total_loss=7.7841e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.3310e-03, val_ODE: 8.2936e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0227387], b: [0.02458414]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.061955228271556875\n",
            "Epoch 97:\n",
            "IC=6.6749e-04,               ODE=3.3328e-03,               data=2.6569e-03,               total_loss=6.6572e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.5455e-04, val_ODE: 2.1410e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0202887], b: [0.02481581]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0510465900035176\n",
            "Epoch 98:\n",
            "IC=2.4580e-04,               ODE=1.2822e-03,               data=2.0544e-03,               total_loss=3.5824e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.4259e-04, val_ODE: 2.9290e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.019112], b: [0.02442169]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.04933954003409454\n",
            "Epoch 99:\n",
            "IC=6.8837e-04,               ODE=2.8706e-03,               data=2.5117e-03,               total_loss=6.0706e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2855e-04, val_ODE: 2.2496e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.017655], b: [0.02425994]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04278034743700487\n",
            "Epoch 100:\n",
            "IC=2.6690e-04,               ODE=1.7020e-03,               data=2.2802e-03,               total_loss=4.2491e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.8888e-04, val_ODE: 1.8251e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0172882], b: [0.02380316]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04408842399711776\n",
            "Epoch 101:\n",
            "IC=2.9850e-04,               ODE=1.6775e-03,               data=1.9276e-03,               total_loss=3.9036e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.0713e-04, val_ODE: 9.8349e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0172126], b: [0.02255838]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.04653804303485514\n",
            "Epoch 102:\n",
            "IC=2.3774e-04,               ODE=1.1326e-03,               data=1.8072e-03,               total_loss=3.1776e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8064e-04, val_ODE: 9.3000e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0171182], b: [0.0216808]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.03878838868561468\n",
            "Epoch 103:\n",
            "IC=1.1464e-04,               ODE=7.1229e-04,               data=1.4775e-03,               total_loss=2.3044e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 8.4612e-05, val_ODE: 1.4245e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0174856], b: [0.02083309]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.039010024281281766\n",
            "Epoch 104:\n",
            "IC=2.0853e-04,               ODE=1.3617e-03,               data=1.6855e-03,               total_loss=3.2557e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.2041e-04, val_ODE: 1.2791e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.017699], b: [0.02001315]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.04157074017555496\n",
            "Epoch 105:\n",
            "IC=1.9430e-04,               ODE=9.4109e-04,               data=1.4693e-03,               total_loss=2.6047e-03\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 3.8171e-04, val_ODE: 1.6238e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0173793], b: [0.01885192]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.039443243695622465\n",
            "Epoch 106:\n",
            "IC=2.5007e-04,               ODE=1.7283e-03,               data=1.7547e-03,               total_loss=3.7330e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.7776e-04, val_ODE: 1.2991e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0174987], b: [0.01845207]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.04611127410839872\n",
            "Epoch 107:\n",
            "IC=1.9012e-04,               ODE=1.2868e-03,               data=1.6523e-03,               total_loss=3.1292e-03\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.5794e-04, val_ODE: 6.3983e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0171618], b: [0.01752843]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03449596115661878\n",
            "Epoch 108:\n",
            "IC=2.0348e-04,               ODE=1.1952e-03,               data=1.4311e-03,               total_loss=2.8298e-03\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 4.9654e-05, val_ODE: 8.1374e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0169182], b: [0.01684193]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.038049852953032266\n",
            "Epoch 109:\n",
            "IC=2.8902e-04,               ODE=1.5768e-03,               data=1.4809e-03,               total_loss=3.3468e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.0009e-04, val_ODE: 3.5900e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0168653], b: [0.01640925]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04200798306123063\n",
            "Epoch 110:\n",
            "IC=2.7375e-04,               ODE=1.7406e-03,               data=1.4864e-03,               total_loss=3.5007e-03\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.5544e-04, val_ODE: 1.7044e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0158305], b: [0.01541674]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03663078090121931\n",
            "Epoch 111:\n",
            "IC=2.6723e-04,               ODE=1.4924e-03,               data=1.3492e-03,               total_loss=3.1089e-03\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 6.9146e-05, val_ODE: 7.6260e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0147974], b: [0.0154375]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03358217352056754\n",
            "Epoch 112:\n",
            "IC=2.8257e-04,               ODE=1.8437e-03,               data=1.4469e-03,               total_loss=3.5732e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.2640e-04, val_ODE: 2.4390e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0136256], b: [0.0150748]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.038811015015825664\n",
            "Epoch 113:\n",
            "IC=3.0593e-04,               ODE=1.7041e-03,               data=1.3689e-03,               total_loss=3.3789e-03\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 2.1710e-04, val_ODE: 8.2329e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.012215], b: [0.01449318]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.032302677524157664\n",
            "Epoch 114:\n",
            "IC=3.0684e-04,               ODE=1.6420e-03,               data=1.4461e-03,               total_loss=3.3949e-03\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 4.1513e-04, val_ODE: 1.7870e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0107596], b: [0.01346743]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.039684530129708434\n",
            "Epoch 115:\n",
            "IC=2.5889e-04,               ODE=1.3222e-03,               data=1.2154e-03,               total_loss=2.7965e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.5074e-04, val_ODE: 5.1239e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.009962], b: [0.01211066]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.029648859123262032\n",
            "Epoch 116:\n",
            "IC=5.8793e-05,               ODE=5.5803e-04,               data=8.5019e-04,               total_loss=1.4670e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5241e-05, val_ODE: 5.3681e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0102606], b: [0.01126243]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "RMSE: 0.02863607388488677\n",
            "Epoch 117:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=9.7506e-05,               ODE=8.3358e-04,               data=1.1176e-03,               total_loss=2.0486e-03\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.2361e-04, val_ODE: 9.0850e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0109565], b: [0.01096816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03134489295588384\n",
            "Epoch 118:\n",
            "IC=1.2009e-04,               ODE=8.5992e-04,               data=8.9026e-04,               total_loss=1.8703e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.9937e-05, val_ODE: 3.0865e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0115142], b: [0.01058574]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.026435649805373204\n",
            "Epoch 119:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.2573e-05,               ODE=7.2307e-04,               data=8.8561e-04,               total_loss=1.6913e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.2173e-04, val_ODE: 1.6888e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0121455], b: [0.00993916]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.03951903713677198\n",
            "Epoch 120:\n",
            "IC=6.1184e-05,               ODE=8.7671e-04,               data=9.2304e-04,               total_loss=1.8609e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.4924e-05, val_ODE: 6.5298e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0126846], b: [0.01010177]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.029775495298537055\n",
            "Epoch 121:\n",
            "IC=2.4338e-04,               ODE=1.4665e-03,               data=1.1583e-03,               total_loss=2.8682e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.8617e-04, val_ODE: 1.8957e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0133219], b: [0.00999154]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03294184041304681\n",
            "Epoch 122:\n",
            "IC=2.1416e-04,               ODE=1.8811e-03,               data=1.2096e-03,               total_loss=3.3049e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7903e-04, val_ODE: 2.7882e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0126686], b: [0.00926602]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.03326283347516767\n",
            "Epoch 123:\n",
            "IC=3.2706e-04,               ODE=2.3659e-03,               data=1.2980e-03,               total_loss=3.9910e-03\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 2.3270e-04, val_ODE: 1.4196e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0121074], b: [0.00888151]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03397246337234613\n",
            "Epoch 124:\n",
            "IC=1.4531e-04,               ODE=1.4639e-03,               data=8.9874e-04,               total_loss=2.5079e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.2822e-05, val_ODE: 1.7095e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.011977], b: [0.00835502]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.03543169527377847\n",
            "Epoch 125:\n",
            "IC=1.5654e-04,               ODE=1.0680e-03,               data=9.5569e-04,               total_loss=2.1802e-03\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 1.6126e-04, val_ODE: 1.5162e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0120945], b: [0.00815146]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.03272382046749425\n",
            "Epoch 126:\n",
            "IC=1.7341e-04,               ODE=1.4176e-03,               data=9.3918e-04,               total_loss=2.5302e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.6301e-04, val_ODE: 4.0848e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0122888], b: [0.00675644]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.040506329725477186\n",
            "Epoch 127:\n",
            "IC=9.9075e-04,               ODE=4.9886e-03,               data=2.1651e-03,               total_loss=8.1444e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.9690e-04, val_ODE: 6.7689e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.009154], b: [0.00743684]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.04818216635799742\n",
            "Epoch 128:\n",
            "IC=7.7464e-04,               ODE=4.4580e-03,               data=1.8439e-03,               total_loss=7.0766e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 9.4098e-06, val_ODE: 1.0692e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0039444], b: [0.0087426]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.02629921008680999\n",
            "Epoch 129:\n",
            "IC=7.7623e-04,               ODE=4.9679e-03,               data=2.1369e-03,               total_loss=7.8810e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1099e-03, val_ODE: 3.9653e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9983742], b: [0.00874147]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04220280680298516\n",
            "Epoch 130:\n",
            "IC=5.9418e-04,               ODE=3.2779e-03,               data=1.5326e-03,               total_loss=5.4047e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2994e-04, val_ODE: 1.2068e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9935644], b: [0.00917446]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.030694028299397987\n",
            "Epoch 131:\n",
            "IC=3.8411e-04,               ODE=1.8666e-03,               data=1.1365e-03,               total_loss=3.3872e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9753e-04, val_ODE: 8.1054e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9923003], b: [0.00833862]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.025574923105448087\n",
            "Epoch 132:\n",
            "IC=1.3162e-04,               ODE=1.2350e-03,               data=8.6152e-04,               total_loss=2.2281e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.0716e-05, val_ODE: 5.0640e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9926556], b: [0.00713946]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.026103166237663844\n",
            "Epoch 133:\n",
            "IC=1.2524e-04,               ODE=9.3919e-04,               data=7.0920e-04,               total_loss=1.7736e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.3935e-05, val_ODE: 6.8509e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9940859], b: [0.00686693]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.027666604619784416\n",
            "Epoch 134:\n",
            "IC=1.2660e-04,               ODE=1.2638e-03,               data=1.0934e-03,               total_loss=2.4838e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0525e-04, val_ODE: 1.6244e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.995552], b: [0.00650014]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.043326413706992396\n",
            "Epoch 135:\n",
            "IC=2.5604e-04,               ODE=1.7075e-03,               data=1.4466e-03,               total_loss=3.4101e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.8338e-04, val_ODE: 2.4112e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9969568], b: [0.00580481]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.033337385465159325\n",
            "Epoch 136:\n",
            "IC=2.1975e-04,               ODE=1.7301e-03,               data=9.9150e-04,               total_loss=2.9414e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.2362e-04, val_ODE: 1.6273e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9982404], b: [0.00485693]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.028092511227463684\n",
            "Epoch 137:\n",
            "IC=3.3746e-04,               ODE=1.2386e-03,               data=1.2503e-03,               total_loss=2.8264e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5793e-04, val_ODE: 1.0807e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9997929], b: [0.00459824]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.028008047884132928\n",
            "Epoch 138:\n",
            "IC=2.3206e-04,               ODE=9.6440e-04,               data=7.2751e-04,               total_loss=1.9240e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.2653e-04, val_ODE: 3.8713e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0012128], b: [0.00503115]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03485289076580315\n",
            "Epoch 139:\n",
            "IC=2.0709e-04,               ODE=8.8097e-04,               data=7.8112e-04,               total_loss=1.8692e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.7209e-04, val_ODE: 7.5283e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0023856], b: [0.00418688]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.022037767101132866\n",
            "Epoch 140:\n",
            "IC=1.4229e-04,               ODE=6.7477e-04,               data=5.6888e-04,               total_loss=1.3859e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.3699e-05, val_ODE: 9.9188e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0033195], b: [0.0044438]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.02365467943711311\n",
            "Epoch 141:\n",
            "IC=8.7904e-05,               ODE=5.5169e-04,               data=5.0777e-04,               total_loss=1.1474e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.2203e-04, val_ODE: 5.0276e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0045152], b: [0.00422319]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.02110752607400005\n",
            "Epoch 142:\n",
            "IC=4.6813e-05,               ODE=4.2714e-04,               data=4.7067e-04,               total_loss=9.4462e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0340e-05, val_ODE: 3.6365e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0057638], b: [0.0042327]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.019676997929472494\n",
            "Epoch 143:\n",
            "IC=1.3951e-05,               ODE=3.5300e-04,               data=3.6973e-04,               total_loss=7.3669e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.9308e-05, val_ODE: 4.9235e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0071304], b: [0.00425861]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.01982138169446937\n",
            "Epoch 144:\n",
            "IC=1.5864e-04,               ODE=1.4108e-03,               data=7.0941e-04,               total_loss=2.2789e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5304e-05, val_ODE: 6.5834e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.007661], b: [0.00446137]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.020680239566640637\n",
            "Epoch 145:\n",
            "IC=1.1086e-04,               ODE=1.0115e-03,               data=5.2480e-04,               total_loss=1.6472e-03\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "val_IC: 4.5700e-05, val_ODE: 6.3167e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0072188], b: [0.00422565]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.023325873174937346\n",
            "Epoch 146:\n",
            "IC=5.7223e-05,               ODE=5.3661e-04,               data=5.0521e-04,               total_loss=1.0990e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0398e-04, val_ODE: 8.8158e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0068886], b: [0.0042676]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "RMSE: 0.021865939720728655\n",
            "Epoch 147:\n",
            "IC=2.8055e-04,               ODE=1.9348e-03,               data=9.0215e-04,               total_loss=3.1175e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.4664e-04, val_ODE: 8.0050e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0061498], b: [0.00378252]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.02397912717419978\n",
            "Epoch 148:\n",
            "IC=1.8387e-04,               ODE=1.2632e-03,               data=6.2850e-04,               total_loss=2.0756e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.4341e-05, val_ODE: 1.9554e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.005408], b: [0.00343855]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.03731565398908712\n",
            "Epoch 149:\n",
            "IC=7.1086e-04,               ODE=3.8355e-03,               data=1.9693e-03,               total_loss=6.5157e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.9715e-04, val_ODE: 3.7539e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0037642], b: [0.00371343]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.03746673030476495\n",
            "Epoch 150:\n",
            "IC=6.4782e-04,               ODE=3.9045e-03,               data=1.9808e-03,               total_loss=6.5331e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.8859e-04, val_ODE: 3.5326e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0004194], b: [0.0034268]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0353417485139618\n",
            "Epoch 151:\n",
            "IC=4.9507e-04,               ODE=2.9320e-03,               data=2.6242e-03,               total_loss=6.0513e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.8498e-03, val_ODE: 3.4636e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9977899], b: [0.00370394]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.05161827974449971\n",
            "Epoch 152:\n",
            "IC=7.0887e-04,               ODE=3.2458e-03,               data=1.4036e-03,               total_loss=5.3583e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.8897e-04, val_ODE: 7.3041e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9964329], b: [0.00293575]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.044117100220521996\n",
            "Epoch 153:\n",
            "IC=6.7438e-04,               ODE=3.5720e-03,               data=2.3245e-03,               total_loss=6.5709e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.9623e-04, val_ODE: 1.2253e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9954989], b: [0.00227278]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.02332460211227263\n",
            "Epoch 154:\n",
            "IC=1.2740e-03,               ODE=6.0971e-03,               data=4.4282e-03,               total_loss=1.1799e-02\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2018e-03, val_ODE: 3.9880e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9947945], b: [0.00281258]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.036893783594335476\n",
            "Epoch 155:\n",
            "IC=7.7954e-04,               ODE=3.8992e-03,               data=1.7668e-03,               total_loss=6.4456e-03\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 9.9635e-04, val_ODE: 2.8138e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9925991], b: [0.00243043]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.03986669680743097\n",
            "Epoch 156:\n",
            "IC=4.3454e-04,               ODE=1.9513e-03,               data=1.5314e-03,               total_loss=3.9172e-03\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 2.6886e-04, val_ODE: 1.9018e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9920248], b: [0.00291561]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "RMSE: 0.04317229206702844\n",
            "Epoch 157:\n",
            "IC=5.9803e-04,               ODE=2.2609e-03,               data=1.8742e-03,               total_loss=4.7331e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6853e-04, val_ODE: 2.7566e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.991962], b: [0.00285322]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.031350654273846465\n",
            "Epoch 158:\n",
            "IC=3.5132e-04,               ODE=2.2355e-03,               data=1.0815e-03,               total_loss=3.6683e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.4278e-04, val_ODE: 2.2945e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9932827], b: [0.00307596]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.028430933370127493\n",
            "Epoch 159:\n",
            "IC=2.2448e-04,               ODE=1.5540e-03,               data=7.2051e-04,               total_loss=2.4990e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.8225e-05, val_ODE: 4.4925e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9939177], b: [0.00443773]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01946451947761461\n",
            "Epoch 160:\n",
            "IC=6.7525e-05,               ODE=6.7340e-04,               data=4.5745e-04,               total_loss=1.1984e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.0931e-05, val_ODE: 6.1750e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9952997], b: [0.00462872]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.021038877116131217\n",
            "Epoch 161:\n",
            "IC=1.1485e-04,               ODE=5.7855e-04,               data=5.9206e-04,               total_loss=1.2855e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.2519e-04, val_ODE: 7.7341e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9967436], b: [0.00450443]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.02084474010506673\n",
            "Epoch 162:\n",
            "IC=1.1780e-04,               ODE=6.3195e-04,               data=4.1514e-04,               total_loss=1.1649e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.2039e-06, val_ODE: 5.5459e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.998733], b: [0.00343999]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.017611207678530427\n",
            "Epoch 163:\n",
            "IC=3.4472e-05,               ODE=4.7377e-04,               data=3.9113e-04,               total_loss=8.9937e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.4805e-05, val_ODE: 3.6288e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0003588], b: [0.00306186]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.01981693547179617\n",
            "Epoch 164:\n",
            "IC=6.4474e-05,               ODE=5.9413e-04,               data=3.7205e-04,               total_loss=1.0306e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.7546e-06, val_ODE: 4.8383e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0020134], b: [0.0029985]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.018200587639417974\n",
            "Epoch 165:\n",
            "IC=4.3902e-05,               ODE=4.9739e-04,               data=4.7187e-04,               total_loss=1.0132e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.5830e-06, val_ODE: 3.9349e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0032425], b: [0.00258291]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.023834093857596727\n",
            "Epoch 166:\n",
            "IC=8.5650e-05,               ODE=4.7810e-04,               data=5.4300e-04,               total_loss=1.1068e-03\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 7.6753e-05, val_ODE: 5.7926e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0044208], b: [0.00264094]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.019016160518710773\n",
            "Epoch 167:\n",
            "IC=8.0806e-05,               ODE=5.9183e-04,               data=3.7884e-04,               total_loss=1.0515e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1501e-04, val_ODE: 8.9573e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0057135], b: [0.00253472]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0369440842265917\n",
            "Epoch 168:\n",
            "IC=5.3934e-04,               ODE=1.8205e-03,               data=1.9015e-03,               total_loss=4.2614e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.3260e-04, val_ODE: 2.1977e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0061226], b: [0.00233567]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.03475528951596425\n",
            "Epoch 169:\n",
            "IC=3.8051e-04,               ODE=2.3362e-03,               data=1.0775e-03,               total_loss=3.7942e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.2092e-04, val_ODE: 1.3925e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.00579], b: [0.00225207]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.02265194814368905\n",
            "Epoch 170:\n",
            "IC=1.6872e-04,               ODE=1.3642e-03,               data=6.4659e-04,               total_loss=2.1795e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.2670e-05, val_ODE: 6.3222e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.00555], b: [0.00357158]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0323833190158084\n",
            "Epoch 171:\n",
            "IC=2.0626e-04,               ODE=9.9149e-04,               data=8.6560e-04,               total_loss=2.0633e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.7626e-05, val_ODE: 8.5965e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.005883], b: [0.00450433]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.017366492989235503\n",
            "Epoch 172:\n",
            "IC=9.6001e-05,               ODE=7.3972e-04,               data=5.9924e-04,               total_loss=1.4350e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7785e-04, val_ODE: 6.3183e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0070329], b: [0.00412206]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01858317321382082\n",
            "Epoch 173:\n",
            "IC=8.8320e-05,               ODE=5.6549e-04,               data=4.3660e-04,               total_loss=1.0904e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6253e-04, val_ODE: 1.0258e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.007901], b: [0.00299304]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.02134762360353619\n",
            "Epoch 174:\n",
            "IC=2.2486e-04,               ODE=1.6864e-03,               data=6.6516e-04,               total_loss=2.5764e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.9896e-05, val_ODE: 8.8533e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.007856], b: [0.00299999]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.018371874983959455\n",
            "Epoch 175:\n",
            "IC=1.0031e-04,               ODE=6.6627e-04,               data=3.3096e-04,               total_loss=1.0975e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.9723e-05, val_ODE: 4.4285e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.007552], b: [0.00284261]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.016861633292883548\n",
            "Epoch 176:\n",
            "IC=7.8786e-05,               ODE=4.5231e-04,               data=3.8608e-04,               total_loss=9.1718e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 6.9514e-05, val_ODE: 7.8848e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-2.007907], b: [0.00249312]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.021335472473656494\n",
            "Epoch 177:\n",
            "IC=5.9312e-04,               ODE=4.4588e-03,               data=1.5455e-03,               total_loss=6.5974e-03\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 5.7405e-04, val_ODE: 7.5000e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-2.0062752], b: [0.00348917]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.054495672026253855\n",
            "Epoch 178:\n",
            "IC=1.0785e-03,               ODE=5.3396e-03,               data=2.7231e-03,               total_loss=9.1412e-03\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 7.0079e-04, val_ODE: 1.7356e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9999199], b: [0.00366029]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.02948025323552404\n",
            "Epoch 179:\n",
            "IC=7.2900e-04,               ODE=3.6739e-03,               data=1.5794e-03,               total_loss=5.9823e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.0021e-04, val_ODE: 3.4611e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9943037], b: [0.00323071]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.035138632921100296\n",
            "Epoch 180:\n",
            "IC=3.7953e-04,               ODE=2.7355e-03,               data=1.0890e-03,               total_loss=4.2041e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.4867e-04, val_ODE: 2.1957e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9897621], b: [0.00299754]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.02726517694814964\n",
            "Epoch 181:\n",
            "IC=2.2302e-04,               ODE=9.9363e-04,               data=6.9962e-04,               total_loss=1.9163e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.3079e-05, val_ODE: 5.1168e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9888737], b: [0.00230555]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.018410675742046946\n",
            "Epoch 182:\n",
            "IC=1.3391e-04,               ODE=6.8242e-04,               data=8.3719e-04,               total_loss=1.6535e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.6010e-05, val_ODE: 1.1187e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9904355], b: [0.00165727]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.04751653998627643\n",
            "Epoch 183:\n",
            "IC=4.9317e-04,               ODE=1.3929e-03,               data=1.0562e-03,               total_loss=2.9422e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0281e-04, val_ODE: 1.1379e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9920248], b: [0.00255768]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.018514801170316304\n",
            "Epoch 184:\n",
            "IC=2.2039e-04,               ODE=1.5889e-03,               data=1.0576e-03,               total_loss=2.8669e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.3258e-05, val_ODE: 1.8860e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9933578], b: [0.00242341]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.029612013721685707\n",
            "Epoch 185:\n",
            "IC=2.0486e-04,               ODE=1.6842e-03,               data=7.4966e-04,               total_loss=2.6387e-03\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "val_IC: 3.0757e-04, val_ODE: 1.2559e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9941351], b: [0.00231108]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.019595997288406865\n",
            "Epoch 186:\n",
            "IC=7.9270e-05,               ODE=8.2005e-04,               data=4.4751e-04,               total_loss=1.3468e-03\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "val_IC: 1.3471e-04, val_ODE: 8.3577e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9954832], b: [0.00254425]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.020038681706131656\n",
            "Epoch 187:\n",
            "IC=8.7711e-05,               ODE=6.3594e-04,               data=3.5444e-04,               total_loss=1.0781e-03\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.1673e-05, val_ODE: 5.2239e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.996978], b: [0.00237245]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.018954850638288133\n",
            "Epoch 188:\n",
            "IC=1.7327e-04,               ODE=9.7579e-04,               data=7.7448e-04,               total_loss=1.9235e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.3861e-04, val_ODE: 2.8346e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9984561], b: [0.00237877]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.038829341456428995\n",
            "Epoch 189:\n",
            "IC=2.8231e-04,               ODE=1.4977e-03,               data=1.0598e-03,               total_loss=2.8399e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.9809e-04, val_ODE: 2.5091e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9982126], b: [0.00131898]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.03018555878533957\n",
            "Epoch 190:\n",
            "IC=3.9799e-04,               ODE=3.4705e-03,               data=1.1357e-03,               total_loss=5.0042e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.8401e-04, val_ODE: 4.4540e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9966586], b: [0.00330032]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03690582621566399\n",
            "Epoch 191:\n",
            "IC=3.4758e-04,               ODE=2.2761e-03,               data=1.2004e-03,               total_loss=3.8240e-03\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.3766e-03, val_ODE: 4.5635e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9948771], b: [0.00356409]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.08570293490698712\n",
            "Epoch 192:\n",
            "IC=1.2498e-03,               ODE=3.6774e-03,               data=4.0054e-03,               total_loss=8.9326e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3516e-04, val_ODE: 1.0675e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9954739], b: [0.00391531]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0375249842791653\n",
            "Epoch 193:\n",
            "IC=1.0123e-03,               ODE=4.7410e-03,               data=4.5591e-03,               total_loss=1.0312e-02\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.2339e-03, val_ODE: 2.0927e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9968815], b: [0.00274171]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.04080528297416516\n",
            "Epoch 194:\n",
            "IC=1.3976e-03,               ODE=5.2850e-03,               data=2.2032e-03,               total_loss=8.8858e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.8788e-03, val_ODE: 6.3307e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.996981], b: [0.0031539]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.04414070899327357\n",
            "Epoch 195:\n",
            "IC=6.0591e-04,               ODE=3.4979e-03,               data=1.0928e-03,               total_loss=5.1966e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0929e-04, val_ODE: 1.8074e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9975399], b: [0.00443152]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.02564405508459093\n",
            "Epoch 196:\n",
            "IC=3.2757e-04,               ODE=1.8979e-03,               data=1.0753e-03,               total_loss=3.3008e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.9379e-04, val_ODE: 9.6307e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9979602], b: [0.00368532]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.023209242040792135\n",
            "Epoch 197:\n",
            "IC=1.7767e-04,               ODE=1.4485e-03,               data=6.3747e-04,               total_loss=2.2637e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6747e-04, val_ODE: 1.0278e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9977107], b: [0.00338724]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.02118551225985353\n",
            "Epoch 198:\n",
            "IC=1.3867e-04,               ODE=8.7341e-04,               data=5.0298e-04,               total_loss=1.5151e-03\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 5.5917e-05, val_ODE: 6.1319e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9976146], b: [0.00329709]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.024158486183178295\n",
            "Epoch 199:\n",
            "IC=1.0181e-04,               ODE=8.4272e-04,               data=6.7370e-04,               total_loss=1.6182e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4101e-04, val_ODE: 2.0790e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.998731], b: [0.002852]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03610673330070096\n",
            "Epoch 200:\n",
            "IC=3.1338e-04,               ODE=1.5120e-03,               data=8.8029e-04,               total_loss=2.7057e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5896e-04, val_ODE: 8.0835e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.999106], b: [0.00254194]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.021531016647682207\n",
            "Epoch 201:\n",
            "IC=2.0369e-04,               ODE=1.6685e-03,               data=8.7572e-04,               total_loss=2.7479e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0544e-04, val_ODE: 7.7897e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9988914], b: [0.00279213]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.027924402258019353\n",
            "Epoch 202:\n",
            "IC=8.4412e-04,               ODE=5.6482e-03,               data=2.8697e-03,               total_loss=9.3620e-03\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0259e-03, val_ODE: 8.7269e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9935968], b: [0.00376133]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.05833073555742964\n",
            "Epoch 203:\n",
            "IC=7.9289e-04,               ODE=4.8910e-03,               data=2.2080e-03,               total_loss=7.8919e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.2478e-04, val_ODE: 4.1112e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9839664], b: [0.0042651]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.035498425306971955\n",
            "Epoch 204:\n",
            "IC=1.7284e-04,               ODE=1.8872e-03,               data=7.7306e-04,               total_loss=2.8331e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6796e-04, val_ODE: 1.6263e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.979648], b: [0.00372047]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.03310387761896017\n",
            "Epoch 205:\n",
            "IC=1.6055e-04,               ODE=1.0719e-03,               data=5.6687e-04,               total_loss=1.7993e-03\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0055e-04, val_ODE: 5.5036e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9803188], b: [0.00307385]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.01813952471015815\n",
            "Epoch 206:\n",
            "IC=5.6660e-05,               ODE=5.4564e-04,               data=3.8324e-04,               total_loss=9.8554e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 5.3089e-06, val_ODE: 5.2687e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.983011], b: [0.00259297]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.016084405193118455\n",
            "Epoch 207:\n",
            "IC=6.6917e-05,               ODE=6.4147e-04,               data=3.4327e-04,               total_loss=1.0517e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.1574e-05, val_ODE: 4.4637e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9863559], b: [0.0021683]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.015885532444880925\n",
            "Epoch 208:\n",
            "IC=5.3964e-05,               ODE=5.1775e-04,               data=3.9682e-04,               total_loss=9.6853e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.0538e-05, val_ODE: 5.4185e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9890217], b: [0.00182367]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.016132974734365084\n",
            "Epoch 209:\n",
            "IC=7.2298e-05,               ODE=4.6659e-04,               data=4.6675e-04,               total_loss=1.0056e-03\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 3.8636e-05, val_ODE: 7.7748e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9918588], b: [0.00207957]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.0181947456751388\n",
            "Epoch 210:\n",
            "IC=8.1275e-05,               ODE=5.7468e-04,               data=3.8036e-04,               total_loss=1.0363e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 8.7719e-05, val_ODE: 3.6857e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9943519], b: [0.00208741]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.016518757262410633\n",
            "Epoch 211:\n",
            "IC=9.6868e-05,               ODE=6.3819e-04,               data=4.7997e-04,               total_loss=1.2150e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5345e-04, val_ODE: 8.2343e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9961721], b: [0.001563]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.01646760842095181\n",
            "Epoch 212:\n",
            "IC=4.0674e-04,               ODE=1.6606e-03,               data=1.1371e-03,               total_loss=3.2044e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8523e-04, val_ODE: 1.8700e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9968425], b: [0.00203987]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.032507892293895814\n",
            "Epoch 213:\n",
            "IC=2.5767e-04,               ODE=1.3048e-03,               data=1.0755e-03,               total_loss=2.6380e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6400e-05, val_ODE: 2.6061e-04, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9965335], b: [0.00107882]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.018086068191320633\n",
            "Epoch 214:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.0286e-04,               ODE=6.5514e-04,               data=5.6546e-04,               total_loss=1.3235e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2149e-04, val_ODE: 1.1992e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9971547], b: [0.00094538]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.05252011844096852\n",
            "Epoch 215:\n",
            "IC=4.9931e-04,               ODE=2.0586e-03,               data=1.1200e-03,               total_loss=3.6779e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0434e-03, val_ODE: 3.6342e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9972411], b: [0.00253601]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.038747827064865556\n",
            "Epoch 216:\n",
            "IC=2.7068e-04,               ODE=2.0569e-03,               data=7.8711e-04,               total_loss=3.1146e-03\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.5487e-04, val_ODE: 1.7575e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.995478], b: [0.00269136]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.05602865673540721\n",
            "Epoch 217:\n",
            "IC=5.6333e-04,               ODE=2.3789e-03,               data=2.0227e-03,               total_loss=4.9649e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.0270e-03, val_ODE: 4.8631e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.994034], b: [0.00409571]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.04620945379039844\n",
            "Epoch 218:\n",
            "IC=1.1902e-03,               ODE=3.1402e-03,               data=1.3149e-03,               total_loss=5.6454e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.3574e-05, val_ODE: 1.5871e-03, lr: 2.00e-02\n",
            "\n",
            "a: [-1.9920713], b: [0.00235702]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.03612533121829678\n",
            "Epoch 219:\n",
            "IC=3.1710e-05,               ODE=7.4961e-04,               data=7.1506e-04,               total_loss=1.4964e-03\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1040e-05, val_ODE: 3.1697e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9922801], b: [0.00163505]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.016312884629785442\n",
            "Epoch 220:\n",
            "IC=3.0591e-05,               ODE=3.8933e-04,               data=4.5227e-04,               total_loss=8.7219e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 7.4283e-06, val_ODE: 2.5197e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9931378], b: [0.00128936]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.021037417202021867\n",
            "Epoch 221:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.6629e-05,               ODE=3.0455e-04,               data=2.9125e-04,               total_loss=6.4243e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.7137e-05, val_ODE: 2.9412e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9942687], b: [0.00136516]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.014633850265638721\n",
            "Epoch 222:\n",
            "IC=2.9527e-05,               ODE=2.5981e-04,               data=1.9278e-04,               total_loss=4.8212e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5727e-06, val_ODE: 2.2583e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9955032], b: [0.00148988]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.013603838432695152\n",
            "Epoch 223:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=9.5394e-06,               ODE=2.2699e-04,               data=1.8474e-04,               total_loss=4.2127e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5437e-06, val_ODE: 2.4649e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9967046], b: [0.00156456]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.013324440406438015\n",
            "Epoch 224:\n",
            "IC=6.3106e-06,               ODE=2.2007e-04,               data=1.8306e-04,               total_loss=4.0944e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.2618e-06, val_ODE: 2.0062e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9978734], b: [0.00157772]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.013656489875804291\n",
            "Epoch 225:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.4523e-06,               ODE=2.2583e-04,               data=1.7917e-04,               total_loss=4.0945e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 5.7107e-08, val_ODE: 2.0534e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9988718], b: [0.00150484]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012868356855247665\n",
            "Epoch 226:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.5235e-06,               ODE=2.2073e-04,               data=1.7866e-04,               total_loss=4.0191e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0284e-06, val_ODE: 2.3618e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-1.9998244], b: [0.00150858]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.013372072647305304\n",
            "Epoch 227:\n",
            "IC=2.2026e-06,               ODE=2.1275e-04,               data=1.7968e-04,               total_loss=3.9464e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.4598e-07, val_ODE: 2.0748e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.000628], b: [0.00134211]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.012571449024733375\n",
            "Epoch 228:\n",
            "IC=2.0444e-06,               ODE=2.0687e-04,               data=1.6330e-04,               total_loss=3.7221e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.4901e-06, val_ODE: 2.1041e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.001393], b: [0.00126336]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.01251711253881131\n",
            "Epoch 229:\n",
            "IC=1.3272e-06,               ODE=2.0544e-04,               data=1.6386e-04,               total_loss=3.7063e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.0855e-07, val_ODE: 2.0540e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0020688], b: [0.00119054]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012646550854876811\n",
            "Epoch 230:\n",
            "IC=1.3406e-06,               ODE=2.0137e-04,               data=1.6044e-04,               total_loss=3.6314e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 2.0564e-06, val_ODE: 2.0529e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0027914], b: [0.00127978]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012631342149633521\n",
            "Epoch 231:\n",
            "IC=1.0906e-06,               ODE=1.9703e-04,               data=1.5863e-04,               total_loss=3.5674e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.1296e-06, val_ODE: 1.9504e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0033567], b: [0.00127131]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.012652346949938581\n",
            "Epoch 232:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.3042e-06,               ODE=1.9433e-04,               data=1.5757e-04,               total_loss=3.5320e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1123e-06, val_ODE: 2.0941e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0038564], b: [0.00130126]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012574766172263224\n",
            "Epoch 233:\n",
            "IC=2.6499e-06,               ODE=2.0131e-04,               data=1.5901e-04,               total_loss=3.6297e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.2847e-07, val_ODE: 1.9889e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0044103], b: [0.00128434]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012372532737317985\n",
            "Epoch 234:\n",
            "IC=3.7221e-06,               ODE=2.0085e-04,               data=1.6332e-04,               total_loss=3.6789e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 5.2342e-06, val_ODE: 1.9472e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0049253], b: [0.00125152]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.013552069538750731\n",
            "Epoch 235:\n",
            "IC=2.8268e-06,               ODE=2.0257e-04,               data=1.6116e-04,               total_loss=3.6656e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.2240e-06, val_ODE: 2.0389e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.005362], b: [0.00114992]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012309124680270154\n",
            "Epoch 236:\n",
            "IC=2.9056e-06,               ODE=2.0537e-04,               data=1.5590e-04,               total_loss=3.6417e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.7714e-06, val_ODE: 2.3081e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0057828], b: [0.00121911]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012982487634167506\n",
            "Epoch 237:\n",
            "IC=4.1267e-06,               ODE=2.0809e-04,               data=1.5860e-04,               total_loss=3.7082e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.6461e-06, val_ODE: 1.9381e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.006152], b: [0.00112893]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.012458193922485764\n",
            "Epoch 238:\n",
            "IC=5.5697e-06,               ODE=1.9609e-04,               data=1.5278e-04,               total_loss=3.5444e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.2629e-06, val_ODE: 1.8936e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.006549], b: [0.00116342]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012288599995654391\n",
            "Epoch 239:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.1378e-06,               ODE=1.9217e-04,               data=1.5586e-04,               total_loss=3.5218e-04\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "val_IC: 2.0291e-06, val_ODE: 1.8414e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0068312], b: [0.00121437]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.013619596469343225\n",
            "Epoch 240:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.5328e-06,               ODE=1.9402e-04,               data=1.7309e-04,               total_loss=3.7064e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.9414e-06, val_ODE: 2.0991e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0071328], b: [0.00122557]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.012488315022661154\n",
            "Epoch 241:\n",
            "IC=6.9785e-06,               ODE=2.0354e-04,               data=1.6059e-04,               total_loss=3.7111e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.5581e-06, val_ODE: 2.0517e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0074797], b: [0.0011364]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.012470387632696379\n",
            "Epoch 242:\n",
            "IC=3.6393e-06,               ODE=2.0032e-04,               data=1.6301e-04,               total_loss=3.6697e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.7872e-06, val_ODE: 2.0309e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0077307], b: [0.00112563]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.012864250383084145\n",
            "Epoch 243:\n",
            "IC=4.7589e-06,               ODE=2.0746e-04,               data=1.6086e-04,               total_loss=3.7308e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.9061e-06, val_ODE: 1.9207e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.007767], b: [0.00114759]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.012385718566489958\n",
            "Epoch 244:\n",
            "IC=3.9847e-06,               ODE=1.9914e-04,               data=1.5285e-04,               total_loss=3.5598e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6026e-06, val_ODE: 2.2459e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0079176], b: [0.00097513]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.012185377648643782\n",
            "Epoch 245:\n",
            "IC=1.6702e-06,               ODE=1.9384e-04,               data=1.5051e-04,               total_loss=3.4602e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.6253e-06, val_ODE: 1.8525e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008084], b: [0.00099245]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01188343511303096\n",
            "Epoch 246:\n",
            "IC=3.6132e-06,               ODE=1.8634e-04,               data=1.4602e-04,               total_loss=3.3598e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.6718e-06, val_ODE: 1.9124e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0082583], b: [0.00102821]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.012081485991346941\n",
            "Epoch 247:\n",
            "IC=1.7107e-06,               ODE=1.8914e-04,               data=1.4892e-04,               total_loss=3.3977e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.0380e-06, val_ODE: 1.9213e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0084088], b: [0.00095041]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.012587892584929634\n",
            "Epoch 248:\n",
            "IC=2.5413e-06,               ODE=1.8823e-04,               data=1.4930e-04,               total_loss=3.4007e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.2842e-06, val_ODE: 2.0259e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0084984], b: [0.00098009]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012504982104431954\n",
            "Epoch 249:\n",
            "IC=2.9717e-06,               ODE=1.9174e-04,               data=1.5629e-04,               total_loss=3.5100e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.9239e-06, val_ODE: 1.9287e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008583], b: [0.00097816]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011976596980630467\n",
            "Epoch 250:\n",
            "IC=3.6602e-06,               ODE=1.9256e-04,               data=1.4685e-04,               total_loss=3.4306e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.4714e-06, val_ODE: 1.8035e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0087376], b: [0.00100907]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.012069006349275114\n",
            "Epoch 251:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.1942e-06,               ODE=1.9639e-04,               data=1.5135e-04,               total_loss=3.5194e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 6.1525e-06, val_ODE: 1.7888e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0087922], b: [0.00096554]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.012665344242385608\n",
            "Epoch 252:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.1962e-06,               ODE=2.0771e-04,               data=1.6813e-04,               total_loss=3.8004e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4314e-05, val_ODE: 2.0565e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088596], b: [0.00123659]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012271696523240118\n",
            "Epoch 253:\n",
            "IC=1.1139e-05,               ODE=2.1208e-04,               data=1.5614e-04,               total_loss=3.7936e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8393e-05, val_ODE: 1.9166e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088458], b: [0.00118781]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.014201639300829587\n",
            "Epoch 254:\n",
            "IC=1.1878e-05,               ODE=1.9758e-04,               data=1.5864e-04,               total_loss=3.6809e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0748e-05, val_ODE: 2.1240e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088978], b: [0.00103361]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011824785228256631\n",
            "Epoch 255:\n",
            "IC=6.1136e-06,               ODE=1.9367e-04,               data=1.4289e-04,               total_loss=3.4268e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.0407e-06, val_ODE: 1.8535e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088737], b: [0.00095885]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.01233537713583209\n",
            "Epoch 256:\n",
            "IC=5.6308e-06,               ODE=1.9083e-04,               data=1.4976e-04,               total_loss=3.4622e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.9046e-06, val_ODE: 2.1519e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089126], b: [0.00100587]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.012361823244283946\n",
            "Epoch 257:\n",
            "IC=2.2323e-06,               ODE=1.8794e-04,               data=1.4870e-04,               total_loss=3.3887e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.2708e-06, val_ODE: 1.7098e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090258], b: [0.00104166]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.012017925654973444\n",
            "Epoch 258:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.0864e-06,               ODE=1.8206e-04,               data=1.4789e-04,               total_loss=3.3403e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9220e-06, val_ODE: 1.9169e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089548], b: [0.00095947]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011620617330857745\n",
            "Epoch 259:\n",
            "IC=4.4099e-06,               ODE=1.8126e-04,               data=1.4670e-04,               total_loss=3.3237e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 4.9122e-06, val_ODE: 1.8781e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090141], b: [0.00091778]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "RMSE: 0.012080366769996836\n",
            "Epoch 260:\n",
            "IC=2.9794e-06,               ODE=1.8049e-04,               data=1.5674e-04,               total_loss=3.4021e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.1026e-07, val_ODE: 1.9508e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090458], b: [0.00089186]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012333667696475035\n",
            "Epoch 261:\n",
            "IC=2.7995e-06,               ODE=1.8605e-04,               data=1.5637e-04,               total_loss=3.4522e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.2313e-06, val_ODE: 2.2224e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090947], b: [0.00090864]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.012972778656235234\n",
            "Epoch 262:\n",
            "IC=1.2046e-05,               ODE=1.9324e-04,               data=1.4613e-04,               total_loss=3.5142e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.0361e-06, val_ODE: 1.8788e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090384], b: [0.00083337]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.011834598434245776\n",
            "Epoch 263:\n",
            "IC=5.9928e-06,               ODE=1.8591e-04,               data=1.5130e-04,               total_loss=3.4321e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.5348e-06, val_ODE: 1.7347e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089147], b: [0.00101245]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.011455436879353081\n",
            "Epoch 264:\n",
            "IC=3.9125e-06,               ODE=1.8136e-04,               data=1.4264e-04,               total_loss=3.2791e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 4.5350e-06, val_ODE: 1.8716e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089266], b: [0.00102211]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011695540532652015\n",
            "Epoch 265:\n",
            "IC=5.3091e-06,               ODE=1.6903e-04,               data=1.3443e-04,               total_loss=3.0877e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 5.3972e-06, val_ODE: 1.6901e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089428], b: [0.0010597]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.011588965629323858\n",
            "Epoch 266:\n",
            "IC=3.9681e-06,               ODE=1.6952e-04,               data=1.3519e-04,               total_loss=3.0868e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.2988e-06, val_ODE: 1.8069e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008975], b: [0.00101849]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.01150787536034761\n",
            "Epoch 267:\n",
            "IC=1.9065e-06,               ODE=1.7486e-04,               data=1.3480e-04,               total_loss=3.1157e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.0667e-06, val_ODE: 1.9324e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089376], b: [0.00093193]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.012441567303738556\n",
            "Epoch 268:\n",
            "IC=4.9561e-06,               ODE=1.7184e-04,               data=1.4091e-04,               total_loss=3.1771e-04\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 1.3005e-05, val_ODE: 1.8624e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089629], b: [0.00097953]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.011997550050582822\n",
            "Epoch 269:\n",
            "IC=7.4150e-06,               ODE=1.7612e-04,               data=1.3948e-04,               total_loss=3.2302e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.9279e-06, val_ODE: 1.7518e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089757], b: [0.00107192]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.012008475055678286\n",
            "Epoch 270:\n",
            "IC=4.1181e-06,               ODE=1.6849e-04,               data=1.3399e-04,               total_loss=3.0660e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.8990e-06, val_ODE: 1.7904e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0090566], b: [0.00093731]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.011360886608106392\n",
            "Epoch 271:\n",
            "IC=3.9174e-06,               ODE=1.6885e-04,               data=1.3382e-04,               total_loss=3.0659e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.8124e-06, val_ODE: 1.7145e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008969], b: [0.00087399]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01158690393539216\n",
            "Epoch 272:\n",
            "IC=5.2980e-06,               ODE=1.7588e-04,               data=1.3809e-04,               total_loss=3.1927e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.5679e-06, val_ODE: 1.7522e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088794], b: [0.00095101]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011148959374066549\n",
            "Epoch 273:\n",
            "IC=4.3668e-06,               ODE=1.7548e-04,               data=1.5747e-04,               total_loss=3.3731e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7536e-06, val_ODE: 1.7230e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0089302], b: [0.00094854]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011461506785630134\n",
            "Epoch 274:\n",
            "IC=1.0549e-05,               ODE=1.7881e-04,               data=1.3616e-04,               total_loss=3.2552e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.3936e-05, val_ODE: 1.8210e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008882], b: [0.00102281]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0115030613701529\n",
            "Epoch 275:\n",
            "IC=7.0471e-06,               ODE=1.6605e-04,               data=1.3106e-04,               total_loss=3.0415e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.4823e-06, val_ODE: 1.6629e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0088656], b: [0.00092843]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.01148617200254885\n",
            "Epoch 276:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.2890e-06,               ODE=1.6511e-04,               data=1.3934e-04,               total_loss=3.0674e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3105e-05, val_ODE: 1.9917e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0087214], b: [0.00085644]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.01205812837860207\n",
            "Epoch 277:\n",
            "IC=1.0940e-05,               ODE=1.7966e-04,               data=1.3782e-04,               total_loss=3.2841e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.6273e-06, val_ODE: 1.7567e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008652], b: [0.00081669]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011790710817466127\n",
            "Epoch 278:\n",
            "IC=5.1397e-06,               ODE=1.7447e-04,               data=1.4731e-04,               total_loss=3.2692e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2141e-05, val_ODE: 1.6264e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0086215], b: [0.00086185]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.01259921400082444\n",
            "Epoch 279:\n",
            "IC=1.1632e-05,               ODE=1.8549e-04,               data=1.4722e-04,               total_loss=3.4434e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.2092e-06, val_ODE: 1.6541e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008574], b: [0.00093349]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.011200364187880698\n",
            "Epoch 280:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.4238e-06,               ODE=1.7088e-04,               data=1.3343e-04,               total_loss=3.1073e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0817e-06, val_ODE: 1.8635e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008422], b: [0.00085515]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011737758210850272\n",
            "Epoch 281:\n",
            "IC=6.0395e-06,               ODE=1.6652e-04,               data=1.3671e-04,               total_loss=3.0928e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.0583e-05, val_ODE: 1.8576e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008398], b: [0.00070085]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011957877709203845\n",
            "Epoch 282:\n",
            "IC=5.6020e-06,               ODE=1.6550e-04,               data=1.3406e-04,               total_loss=3.0515e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.2729e-06, val_ODE: 1.7338e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0083869], b: [0.00083557]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0120242406546326\n",
            "Epoch 283:\n",
            "IC=3.5950e-06,               ODE=1.6054e-04,               data=1.3703e-04,               total_loss=3.0117e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.1233e-06, val_ODE: 1.6876e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0083728], b: [0.0010093]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011052532838267563\n",
            "Epoch 284:\n",
            "IC=3.8143e-06,               ODE=1.6401e-04,               data=1.2416e-04,               total_loss=2.9198e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.9771e-07, val_ODE: 1.5560e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0084193], b: [0.00095153]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.011209091370662195\n",
            "Epoch 285:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.3133e-06,               ODE=1.6211e-04,               data=1.2851e-04,               total_loss=2.9393e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.4887e-06, val_ODE: 1.6789e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.008354], b: [0.00107401]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.010951849564763807\n",
            "Epoch 286:\n",
            "IC=2.0138e-06,               ODE=1.5928e-04,               data=1.2952e-04,               total_loss=2.9081e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 4.3766e-06, val_ODE: 1.4945e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0083432], b: [0.00106908]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010848665723016645\n",
            "Epoch 287:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.5640e-06,               ODE=1.8378e-04,               data=2.6432e-04,               total_loss=4.5366e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.1577e-05, val_ODE: 1.7743e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0081525], b: [0.00076326]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.01840797815614598\n",
            "Epoch 288:\n",
            "IC=2.6163e-05,               ODE=2.1506e-04,               data=2.1959e-04,               total_loss=4.6082e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.6697e-06, val_ODE: 1.8040e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0079932], b: [0.00037515]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.011260783803525812\n",
            "Epoch 289:\n",
            "IC=6.9792e-06,               ODE=1.7353e-04,               data=1.2065e-04,               total_loss=3.0115e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.1836e-06, val_ODE: 1.5222e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0078595], b: [0.00049816]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.010950827972341252\n",
            "Epoch 290:\n",
            "IC=3.0617e-06,               ODE=1.5525e-04,               data=1.2258e-04,               total_loss=2.8089e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.0100e-07, val_ODE: 1.4461e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0076778], b: [0.00072278]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.010654182229614262\n",
            "Epoch 291:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.1743e-06,               ODE=1.4975e-04,               data=1.1878e-04,               total_loss=2.7071e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.4677e-06, val_ODE: 1.4331e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0076368], b: [0.00074641]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011587856258360393\n",
            "Epoch 292:\n",
            "IC=2.8810e-06,               ODE=1.4728e-04,               data=1.2768e-04,               total_loss=2.7784e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5554e-06, val_ODE: 1.6597e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0075626], b: [0.00089926]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010699498692173938\n",
            "Epoch 293:\n",
            "IC=7.0022e-06,               ODE=1.7911e-04,               data=1.4368e-04,               total_loss=3.2979e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.6349e-05, val_ODE: 1.9457e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0075262], b: [0.00106368]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.011226323549710652\n",
            "Epoch 294:\n",
            "IC=8.5563e-06,               ODE=1.8667e-04,               data=1.3199e-04,               total_loss=3.2721e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.1712e-06, val_ODE: 1.5774e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0074403], b: [0.00092914]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.010779539828278338\n",
            "Epoch 295:\n",
            "IC=5.2512e-06,               ODE=1.7344e-04,               data=1.2694e-04,               total_loss=3.0564e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 7.7073e-06, val_ODE: 1.8659e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0073721], b: [0.0009782]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.011242057450208285\n",
            "Epoch 296:\n",
            "IC=8.6399e-06,               ODE=1.7673e-04,               data=1.3145e-04,               total_loss=3.1682e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5120e-06, val_ODE: 1.7070e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0072274], b: [0.00096705]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.012888833649057026\n",
            "Epoch 297:\n",
            "IC=5.6304e-06,               ODE=1.5982e-04,               data=1.3760e-04,               total_loss=3.0306e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6299e-06, val_ODE: 1.7900e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0071657], b: [0.00092165]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.011628841343656476\n",
            "Epoch 298:\n",
            "IC=5.6593e-06,               ODE=1.7035e-04,               data=1.3151e-04,               total_loss=3.0752e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.1662e-06, val_ODE: 1.4971e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.007091], b: [0.00086477]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.01057150444111973\n",
            "Epoch 299:\n",
            "IC=4.0100e-06,               ODE=1.4863e-04,               data=1.2104e-04,               total_loss=2.7368e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9446e-06, val_ODE: 1.4754e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.007158], b: [0.00084736]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010920076551240394\n",
            "Epoch 300:\n",
            "IC=6.3072e-06,               ODE=1.6924e-04,               data=1.3872e-04,               total_loss=3.1426e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 1.2613e-06, val_ODE: 1.4532e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.007123], b: [0.00077169]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.011047885530973585\n",
            "Epoch 301:\n",
            "IC=5.7744e-06,               ODE=1.6208e-04,               data=1.2765e-04,               total_loss=2.9550e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 7.2890e-07, val_ODE: 1.4893e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0070257], b: [0.00081407]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "RMSE: 0.010602713884458615\n",
            "Epoch 302:\n",
            "IC=5.9024e-06,               ODE=1.6725e-04,               data=1.3433e-04,               total_loss=3.0749e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.4887e-06, val_ODE: 1.7305e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0069318], b: [0.00071539]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.013011333261695292\n",
            "Epoch 303:\n",
            "IC=6.1590e-06,               ODE=1.8890e-04,               data=1.3395e-04,               total_loss=3.2901e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4382e-05, val_ODE: 1.8650e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.006801], b: [0.00085603]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.011301114177108931\n",
            "Epoch 304:\n",
            "IC=1.0235e-05,               ODE=1.7463e-04,               data=1.6485e-04,               total_loss=3.4972e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.3046e-05, val_ODE: 2.1590e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0066447], b: [0.00083336]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011980563701938203\n",
            "Epoch 305:\n",
            "IC=1.9059e-05,               ODE=1.8179e-04,               data=1.2640e-04,               total_loss=3.2725e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.2710e-06, val_ODE: 1.5593e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0066416], b: [0.00091299]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011247765947391011\n",
            "Epoch 306:\n",
            "IC=6.1875e-06,               ODE=1.8933e-04,               data=1.2789e-04,               total_loss=3.2341e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.9856e-06, val_ODE: 1.7188e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0065258], b: [0.00084478]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010653604688481312\n",
            "Epoch 307:\n",
            "IC=4.3724e-06,               ODE=1.5902e-04,               data=1.2870e-04,               total_loss=2.9209e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8940e-06, val_ODE: 1.4212e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0064437], b: [0.00078939]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010296141881193868\n",
            "Epoch 308:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.1527e-06,               ODE=1.4881e-04,               data=1.2023e-04,               total_loss=2.7519e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.5135e-05, val_ODE: 1.4174e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0063636], b: [0.00090463]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.012391218113465512\n",
            "Epoch 309:\n",
            "IC=6.9759e-06,               ODE=1.5841e-04,               data=1.2173e-04,               total_loss=2.8712e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5219e-06, val_ODE: 1.7553e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0063252], b: [0.00071798]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010896981211586332\n",
            "Epoch 310:\n",
            "IC=7.1978e-06,               ODE=1.6464e-04,               data=1.3019e-04,               total_loss=3.0203e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 5.7402e-06, val_ODE: 1.7752e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0062156], b: [0.00092792]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "RMSE: 0.013590100557278996\n",
            "Epoch 311:\n",
            "IC=1.3439e-05,               ODE=1.6645e-04,               data=1.4756e-04,               total_loss=3.2745e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2824e-05, val_ODE: 1.6529e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0063026], b: [0.00077139]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.010943819104543829\n",
            "Epoch 312:\n",
            "IC=9.7621e-06,               ODE=1.6592e-04,               data=1.2443e-04,               total_loss=3.0012e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.5824e-06, val_ODE: 1.9932e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.006285], b: [0.00076507]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011096838284905038\n",
            "Epoch 313:\n",
            "IC=3.0548e-06,               ODE=1.5358e-04,               data=1.2210e-04,               total_loss=2.7874e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.4625e-06, val_ODE: 1.5849e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0062745], b: [0.00064834]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010633135217884199\n",
            "Epoch 314:\n",
            "IC=4.5915e-06,               ODE=1.5028e-04,               data=1.3590e-04,               total_loss=2.9076e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1222e-05, val_ODE: 1.8295e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0062437], b: [0.00068983]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011212374140165038\n",
            "Epoch 315:\n",
            "IC=8.3851e-06,               ODE=1.4787e-04,               data=1.2321e-04,               total_loss=2.7946e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8784e-06, val_ODE: 1.5543e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0062232], b: [0.00070312]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.012478215018273333\n",
            "Epoch 316:\n",
            "IC=7.9744e-06,               ODE=1.7000e-04,               data=1.3944e-04,               total_loss=3.1741e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.5013e-06, val_ODE: 1.8442e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0061808], b: [0.00057388]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.011093174698242173\n",
            "Epoch 317:\n",
            "IC=1.0796e-05,               ODE=1.8407e-04,               data=1.2524e-04,               total_loss=3.2010e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3871e-05, val_ODE: 1.4131e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.006046], b: [0.00077441]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.012484500779893415\n",
            "Epoch 318:\n",
            "IC=9.9049e-06,               ODE=1.7339e-04,               data=1.4791e-04,               total_loss=3.3121e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.4668e-06, val_ODE: 1.4721e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.005989], b: [0.00093418]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.011959498998869778\n",
            "Epoch 319:\n",
            "IC=1.7432e-05,               ODE=2.0445e-04,               data=1.4530e-04,               total_loss=3.6718e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2828e-05, val_ODE: 1.9293e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0058339], b: [0.00099682]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.011424590903385507\n",
            "Epoch 320:\n",
            "IC=9.5250e-06,               ODE=1.7188e-04,               data=1.3373e-04,               total_loss=3.1514e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.9625e-06, val_ODE: 1.7131e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0056846], b: [0.00093976]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010569149383644817\n",
            "Epoch 321:\n",
            "IC=1.1792e-05,               ODE=2.0693e-04,               data=1.3165e-04,               total_loss=3.5037e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 3.1536e-05, val_ODE: 2.7421e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0055985], b: [0.00068934]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.011625878352694777\n",
            "Epoch 322:\n",
            "IC=1.2152e-05,               ODE=1.7667e-04,               data=1.2263e-04,               total_loss=3.1145e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.1062e-05, val_ODE: 1.8478e-04, lr: 1.00e-02\n",
            "\n",
            "a: [-2.0056384], b: [0.00082775]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.011199097758036812\n",
            "Epoch 323:\n",
            "IC=4.1207e-06,               ODE=1.4619e-04,               data=1.0778e-04,               total_loss=2.5809e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.1959e-07, val_ODE: 1.3283e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005679], b: [0.00091818]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.010039700724749506\n",
            "Epoch 324:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=9.9699e-07,               ODE=1.2742e-04,               data=1.0185e-04,               total_loss=2.3026e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.2744e-07, val_ODE: 1.2979e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056827], b: [0.00096763]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.01025550854195255\n",
            "Epoch 325:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.9390e-06,               ODE=1.2397e-04,               data=1.0760e-04,               total_loss=2.3350e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0265e-06, val_ODE: 1.2717e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056448], b: [0.00097038]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00983731911485304\n",
            "Epoch 326:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.0095e-06,               ODE=1.2132e-04,               data=9.9542e-05,               total_loss=2.2287e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6323e-06, val_ODE: 1.2162e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056846], b: [0.0009651]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009718752360995038\n",
            "Epoch 327:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=9.4369e-07,               ODE=1.1902e-04,               data=9.9361e-05,               total_loss=2.1933e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0021e-06, val_ODE: 1.2128e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056908], b: [0.00093482]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00984751375814969\n",
            "Epoch 328:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.5177e-07,               ODE=1.1756e-04,               data=9.8190e-05,               total_loss=2.1630e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0175e-06, val_ODE: 1.2296e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056703], b: [0.0009161]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010131943533562907\n",
            "Epoch 329:\n",
            "IC=1.0207e-06,               ODE=1.2019e-04,               data=9.8087e-05,               total_loss=2.1930e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.1072e-07, val_ODE: 1.2207e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0057168], b: [0.00084838]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.009734013569055225\n",
            "Epoch 330:\n",
            "IC=8.0506e-07,               ODE=1.1917e-04,               data=9.8091e-05,               total_loss=2.1807e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.8965e-07, val_ODE: 1.1949e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0057287], b: [0.00087865]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00977431534912095\n",
            "Epoch 331:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.3530e-06,               ODE=1.2017e-04,               data=9.8438e-05,               total_loss=2.1996e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5109e-06, val_ODE: 1.2408e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056973], b: [0.00083947]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.009880544331834612\n",
            "Epoch 332:\n",
            "IC=8.1036e-07,               ODE=1.1940e-04,               data=9.9404e-05,               total_loss=2.1961e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.0722e-08, val_ODE: 1.2458e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0057063], b: [0.00090686]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009709237938484194\n",
            "Epoch 333:\n",
            "IC=4.2618e-07,               ODE=1.1913e-04,               data=9.5803e-05,               total_loss=2.1536e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1998e-07, val_ODE: 1.1754e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0057259], b: [0.00086249]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009810942055202583\n",
            "Epoch 334:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.2047e-07,               ODE=1.1777e-04,               data=9.7295e-05,               total_loss=2.1589e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.7092e-07, val_ODE: 1.1294e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005718], b: [0.00086015]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.010094490254460048\n",
            "Epoch 335:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.2431e-06,               ODE=1.1765e-04,               data=1.0004e-04,               total_loss=2.1894e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.1742e-06, val_ODE: 1.2551e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.00572], b: [0.00085384]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01019015076287787\n",
            "Epoch 336:\n",
            "IC=1.8550e-06,               ODE=1.2056e-04,               data=9.7547e-05,               total_loss=2.1997e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.8378e-06, val_ODE: 1.1876e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0057375], b: [0.0008665]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.010157439080938713\n",
            "Epoch 337:\n",
            "IC=1.4977e-06,               ODE=1.1827e-04,               data=9.7624e-05,               total_loss=2.1740e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.2435e-07, val_ODE: 1.1643e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005717], b: [0.00088302]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009804008900191272\n",
            "Epoch 338:\n",
            "IC=9.4060e-07,               ODE=1.1770e-04,               data=9.8165e-05,               total_loss=2.1680e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 5.6511e-07, val_ODE: 1.1541e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056844], b: [0.00089589]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009705870725923941\n",
            "Epoch 339:\n",
            "IC=1.8626e-06,               ODE=1.1871e-04,               data=9.7407e-05,               total_loss=2.1798e-04\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 3.5130e-07, val_ODE: 1.1608e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056849], b: [0.00080603]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009701394250996363\n",
            "Epoch 340:\n",
            "IC=6.7779e-07,               ODE=1.1491e-04,               data=9.7256e-05,               total_loss=2.1284e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5721e-06, val_ODE: 1.2409e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0056841], b: [0.0008446]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.009756390234350393\n",
            "Epoch 341:\n",
            "IC=1.0510e-06,               ODE=1.1661e-04,               data=9.7674e-05,               total_loss=2.1533e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.0153e-07, val_ODE: 1.1959e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005636], b: [0.00079928]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009571019030781303\n",
            "Epoch 342:\n",
            "IC=1.1061e-06,               ODE=1.1442e-04,               data=9.4168e-05,               total_loss=2.0969e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.2229e-06, val_ODE: 1.1685e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0055943], b: [0.00082921]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009538170246603719\n",
            "Epoch 343:\n",
            "IC=1.1540e-06,               ODE=1.1681e-04,               data=9.5100e-05,               total_loss=2.1307e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 3.3053e-06, val_ODE: 1.2077e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005606], b: [0.00085236]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.01062027953165865\n",
            "Epoch 344:\n",
            "IC=1.2323e-06,               ODE=1.2029e-04,               data=1.0024e-04,               total_loss=2.2177e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0227e-06, val_ODE: 1.2931e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0055146], b: [0.0007702]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010151868164618496\n",
            "Epoch 345:\n",
            "IC=1.2145e-06,               ODE=1.1946e-04,               data=9.8906e-05,               total_loss=2.1958e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8588e-07, val_ODE: 1.2565e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0055633], b: [0.00084827]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009651897613974735\n",
            "Epoch 346:\n",
            "IC=9.2700e-07,               ODE=1.1506e-04,               data=9.5899e-05,               total_loss=2.1189e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3151e-06, val_ODE: 1.2063e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0055172], b: [0.00084]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00967497944648631\n",
            "Epoch 347:\n",
            "IC=8.6395e-07,               ODE=1.1519e-04,               data=9.4955e-05,               total_loss=2.1101e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5083e-06, val_ODE: 1.1675e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0055099], b: [0.00082685]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009594043953694368\n",
            "Epoch 348:\n",
            "IC=1.0884e-06,               ODE=1.1474e-04,               data=9.5305e-05,               total_loss=2.1113e-04\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 1.3034e-07, val_ODE: 1.1976e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005488], b: [0.00084825]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009917037435001259\n",
            "Epoch 349:\n",
            "IC=1.1720e-06,               ODE=1.1578e-04,               data=9.9016e-05,               total_loss=2.1597e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6768e-06, val_ODE: 1.2273e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0054574], b: [0.00079088]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009682755063530921\n",
            "Epoch 350:\n",
            "IC=1.2951e-06,               ODE=1.1655e-04,               data=9.8848e-05,               total_loss=2.1669e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.2865e-06, val_ODE: 1.2792e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0053368], b: [0.00074091]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010040664311541596\n",
            "Epoch 351:\n",
            "IC=1.5429e-06,               ODE=1.1923e-04,               data=9.8641e-05,               total_loss=2.1941e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.1544e-07, val_ODE: 1.1263e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005323], b: [0.0007644]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.010018016597419748\n",
            "Epoch 352:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=9.8065e-07,               ODE=1.1777e-04,               data=9.5864e-05,               total_loss=2.1462e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0889e-06, val_ODE: 1.1887e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0052783], b: [0.00072957]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009559008825722148\n",
            "Epoch 353:\n",
            "IC=3.1636e-06,               ODE=1.2160e-04,               data=9.7112e-05,               total_loss=2.2188e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 5.6961e-06, val_ODE: 1.2677e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.00523], b: [0.00079968]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010083217499714204\n",
            "Epoch 354:\n",
            "IC=5.0276e-06,               ODE=1.2091e-04,               data=1.0381e-04,               total_loss=2.2975e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 5.1502e-06, val_ODE: 1.2472e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0051684], b: [0.00078126]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.009796374393980897\n",
            "Epoch 355:\n",
            "IC=4.5687e-06,               ODE=1.1952e-04,               data=9.8118e-05,               total_loss=2.2221e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5836e-06, val_ODE: 1.2060e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0051174], b: [0.00076901]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009411473454591528\n",
            "Epoch 356:\n",
            "IC=2.4312e-06,               ODE=1.1786e-04,               data=1.0053e-04,               total_loss=2.2082e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.0741e-06, val_ODE: 1.3413e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0051644], b: [0.00076943]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.010112269279633476\n",
            "Epoch 357:\n",
            "IC=2.6275e-06,               ODE=1.2388e-04,               data=9.7439e-05,               total_loss=2.2395e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.5872e-07, val_ODE: 1.2751e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0050845], b: [0.00082013]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009468805143298313\n",
            "Epoch 358:\n",
            "IC=2.4702e-06,               ODE=1.1889e-04,               data=9.4863e-05,               total_loss=2.1622e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.2854e-06, val_ODE: 1.1979e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0050588], b: [0.0007621]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009467454854455961\n",
            "Epoch 359:\n",
            "IC=2.3828e-06,               ODE=1.1879e-04,               data=9.5225e-05,               total_loss=2.1640e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.6545e-06, val_ODE: 1.1142e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0050333], b: [0.00076849]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009398379688810972\n",
            "Epoch 360:\n",
            "IC=1.2878e-06,               ODE=1.1336e-04,               data=9.2108e-05,               total_loss=2.0676e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6918e-06, val_ODE: 1.1307e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.005006], b: [0.00083741]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.009421478006350067\n",
            "Epoch 361:\n",
            "IC=1.0881e-06,               ODE=1.1272e-04,               data=9.3311e-05,               total_loss=2.0711e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3094e-06, val_ODE: 1.1570e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0050359], b: [0.0007882]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009671136335383605\n",
            "Epoch 362:\n",
            "IC=1.4191e-06,               ODE=1.1482e-04,               data=9.2972e-05,               total_loss=2.0921e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.9476e-06, val_ODE: 1.2581e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0049808], b: [0.00082819]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.009549919454193328\n",
            "Epoch 363:\n",
            "IC=3.4444e-06,               ODE=1.2124e-04,               data=9.9409e-05,               total_loss=2.2409e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.3880e-06, val_ODE: 1.1308e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.00494], b: [0.00082878]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009564873548703532\n",
            "Epoch 364:\n",
            "IC=4.2401e-06,               ODE=1.1509e-04,               data=9.4917e-05,               total_loss=2.1425e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.0794e-06, val_ODE: 1.1349e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0049694], b: [0.00083779]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009647008633029454\n",
            "Epoch 365:\n",
            "IC=2.0987e-06,               ODE=1.1921e-04,               data=9.9367e-05,               total_loss=2.2067e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 1.0326e-06, val_ODE: 1.3738e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0049188], b: [0.00079963]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.0105903585822321\n",
            "Epoch 366:\n",
            "IC=1.3512e-06,               ODE=1.1693e-04,               data=9.8947e-05,               total_loss=2.1723e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.4219e-06, val_ODE: 1.1466e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048807], b: [0.00071364]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009464185551106629\n",
            "Epoch 367:\n",
            "IC=1.4903e-06,               ODE=1.1322e-04,               data=9.1747e-05,               total_loss=2.0645e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.1721e-06, val_ODE: 1.2033e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048807], b: [0.00068378]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009763067618790738\n",
            "Epoch 368:\n",
            "IC=1.5180e-06,               ODE=1.1694e-04,               data=9.2562e-05,               total_loss=2.1102e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.0898e-06, val_ODE: 1.1857e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048313], b: [0.00084653]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010067103964088367\n",
            "Epoch 369:\n",
            "IC=1.5344e-06,               ODE=1.1784e-04,               data=9.5921e-05,               total_loss=2.1529e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.2162e-07, val_ODE: 1.1246e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048447], b: [0.00077609]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.009271564676580345\n",
            "Epoch 370:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.5014e-06,               ODE=1.1410e-04,               data=9.2831e-05,               total_loss=2.0844e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.6105e-06, val_ODE: 1.3439e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048106], b: [0.00066961]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0096084862114703\n",
            "Epoch 371:\n",
            "IC=2.7831e-06,               ODE=1.1896e-04,               data=9.4070e-05,               total_loss=2.1581e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 2.1014e-06, val_ODE: 1.1557e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0048015], b: [0.00069039]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010872246082611246\n",
            "Epoch 372:\n",
            "IC=4.1426e-06,               ODE=1.3361e-04,               data=1.1182e-04,               total_loss=2.4957e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.4638e-06, val_ODE: 1.4519e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0047932], b: [0.00075048]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.010325786158278283\n",
            "Epoch 373:\n",
            "IC=5.0856e-06,               ODE=1.3394e-04,               data=9.8745e-05,               total_loss=2.3777e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6173e-07, val_ODE: 1.2388e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0047457], b: [0.00077718]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009563142398322863\n",
            "Epoch 374:\n",
            "IC=2.6110e-06,               ODE=1.1926e-04,               data=9.8927e-05,               total_loss=2.2080e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.3549e-06, val_ODE: 1.2549e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0047326], b: [0.00078505]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010337307730532727\n",
            "Epoch 375:\n",
            "IC=4.8803e-06,               ODE=1.2764e-04,               data=1.0089e-04,               total_loss=2.3341e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 9.3150e-06, val_ODE: 1.2205e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0046952], b: [0.00083659]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010955784478467085\n",
            "Epoch 376:\n",
            "IC=4.6774e-06,               ODE=1.2432e-04,               data=9.8490e-05,               total_loss=2.2749e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.7062e-06, val_ODE: 1.1081e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0046992], b: [0.00083627]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009543163470240321\n",
            "Epoch 377:\n",
            "IC=2.0575e-06,               ODE=1.1636e-04,               data=9.1961e-05,               total_loss=2.1038e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.2975e-07, val_ODE: 1.1585e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0046914], b: [0.00069799]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009226494668759152\n",
            "Epoch 378:\n",
            "IC=1.5288e-06,               ODE=1.1355e-04,               data=9.2660e-05,               total_loss=2.0773e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8857e-06, val_ODE: 1.1052e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0046387], b: [0.00078218]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009277970830620708\n",
            "Epoch 379:\n",
            "IC=1.8109e-06,               ODE=1.0796e-04,               data=8.7112e-05,               total_loss=1.9688e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3897e-07, val_ODE: 1.0851e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0045857], b: [0.00068525]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.009171586416085712\n",
            "Epoch 380:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.1333e-06,               ODE=1.0719e-04,               data=8.8430e-05,               total_loss=1.9675e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5117e-06, val_ODE: 1.1123e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0045793], b: [0.00062271]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.009151731251463324\n",
            "Epoch 381:\n",
            "IC=1.0922e-06,               ODE=1.0697e-04,               data=8.6614e-05,               total_loss=1.9468e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.9406e-07, val_ODE: 1.0998e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0045896], b: [0.00069031]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009164246656464857\n",
            "Epoch 382:\n",
            "IC=1.2773e-06,               ODE=1.0970e-04,               data=9.2756e-05,               total_loss=2.0373e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.7855e-06, val_ODE: 1.1239e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0046031], b: [0.00066232]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009292845716657323\n",
            "Epoch 383:\n",
            "IC=2.1616e-06,               ODE=1.1271e-04,               data=9.1103e-05,               total_loss=2.0597e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8460e-06, val_ODE: 1.0870e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.004558], b: [0.00069162]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009152715440458852\n",
            "Epoch 384:\n",
            "IC=3.0186e-06,               ODE=1.1509e-04,               data=8.9576e-05,               total_loss=2.0768e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.4705e-07, val_ODE: 1.1356e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.004498], b: [0.0008127]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009421936660186064\n",
            "Epoch 385:\n",
            "IC=2.7764e-06,               ODE=1.1865e-04,               data=9.4358e-05,               total_loss=2.1579e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.3231e-06, val_ODE: 1.2667e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0044723], b: [0.00075994]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.009173907887646543\n",
            "Epoch 386:\n",
            "IC=3.6279e-06,               ODE=1.1682e-04,               data=9.0251e-05,               total_loss=2.1070e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3035e-06, val_ODE: 1.2824e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0044236], b: [0.00077849]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.009570383172629126\n",
            "Epoch 387:\n",
            "IC=3.5539e-06,               ODE=1.2361e-04,               data=9.5471e-05,               total_loss=2.2264e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.7245e-06, val_ODE: 1.3271e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0043697], b: [0.00071858]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009569158579634598\n",
            "Epoch 388:\n",
            "IC=4.1958e-06,               ODE=1.2540e-04,               data=9.2972e-05,               total_loss=2.2256e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.7510e-06, val_ODE: 1.3357e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0042777], b: [0.00072067]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009840687724350749\n",
            "Epoch 389:\n",
            "IC=5.6824e-06,               ODE=1.2068e-04,               data=8.8459e-05,               total_loss=2.1482e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.9276e-06, val_ODE: 1.1352e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0042694], b: [0.0007278]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00960745419724854\n",
            "Epoch 390:\n",
            "IC=1.9074e-06,               ODE=1.1070e-04,               data=9.4212e-05,               total_loss=2.0682e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.5966e-07, val_ODE: 1.0949e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0042837], b: [0.00069651]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009756205717254808\n",
            "Epoch 391:\n",
            "IC=2.7648e-06,               ODE=1.0998e-04,               data=9.6308e-05,               total_loss=2.0905e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.4098e-06, val_ODE: 1.1822e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.004178], b: [0.00074214]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009537232853064473\n",
            "Epoch 392:\n",
            "IC=4.4110e-06,               ODE=1.1986e-04,               data=9.6302e-05,               total_loss=2.2058e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3839e-07, val_ODE: 1.1349e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.004163], b: [0.00069626]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009030552622346493\n",
            "Epoch 393:\n",
            "IC=1.3988e-06,               ODE=1.1313e-04,               data=8.6866e-05,               total_loss=2.0139e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.8264e-07, val_ODE: 1.0268e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0040972], b: [0.00050536]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010332198686468681\n",
            "Epoch 394:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.3320e-06,               ODE=1.0885e-04,               data=1.0658e-04,               total_loss=2.1677e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.8252e-06, val_ODE: 1.1433e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.004023], b: [0.00064721]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00926237825369848\n",
            "Epoch 395:\n",
            "IC=3.6863e-06,               ODE=1.1215e-04,               data=8.6816e-05,               total_loss=2.0266e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.6709e-06, val_ODE: 1.0138e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.00405], b: [0.00068202]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009703067343015421\n",
            "Epoch 396:\n",
            "IC=1.4631e-06,               ODE=1.0348e-04,               data=8.5838e-05,               total_loss=1.9078e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.3970e-07, val_ODE: 1.0540e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0039833], b: [0.00080066]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009265324905302828\n",
            "Epoch 397:\n",
            "IC=2.8282e-06,               ODE=1.1383e-04,               data=9.4147e-05,               total_loss=2.1081e-04\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "val_IC: 3.1060e-07, val_ODE: 1.0647e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0039804], b: [0.00072732]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.009361069568977991\n",
            "Epoch 398:\n",
            "IC=3.3944e-06,               ODE=1.0983e-04,               data=9.7428e-05,               total_loss=2.1065e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.3414e-06, val_ODE: 1.0822e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.00392], b: [0.00079077]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.009052066471195363\n",
            "Epoch 399:\n",
            "IC=3.7331e-06,               ODE=1.1355e-04,               data=8.7132e-05,               total_loss=2.0441e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.5729e-06, val_ODE: 1.1927e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0040069], b: [0.0007482]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.009530700433607566\n",
            "Epoch 400:\n",
            "IC=3.6356e-06,               ODE=1.2313e-04,               data=9.4537e-05,               total_loss=2.2130e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 1.4951e-06, val_ODE: 9.9926e-05, lr: 5.00e-03\n",
            "\n",
            "a: [-2.003984], b: [0.00072724]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.00922699035109054\n",
            "Epoch 401:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.5926e-06,               ODE=1.2310e-04,               data=9.0302e-05,               total_loss=2.1800e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.3513e-06, val_ODE: 1.2086e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0039053], b: [0.00066219]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009042990732759784\n",
            "Epoch 402:\n",
            "IC=3.1048e-06,               ODE=1.1332e-04,               data=8.6001e-05,               total_loss=2.0243e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.9114e-06, val_ODE: 1.1600e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.003706], b: [0.00064418]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00891250380433059\n",
            "Epoch 403:\n",
            "IC=2.9128e-06,               ODE=1.0955e-04,               data=8.3389e-05,               total_loss=1.9586e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.6717e-07, val_ODE: 1.1265e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036998], b: [0.00057108]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008941610604364918\n",
            "Epoch 404:\n",
            "IC=2.4323e-06,               ODE=1.1125e-04,               data=8.6630e-05,               total_loss=2.0031e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2046e-06, val_ODE: 1.0329e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036678], b: [0.00070445]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009756635757318608\n",
            "Epoch 405:\n",
            "IC=1.6346e-06,               ODE=1.1021e-04,               data=8.7416e-05,               total_loss=1.9926e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.9045e-06, val_ODE: 1.1436e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0037417], b: [0.00073538]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.008925585955846017\n",
            "Epoch 406:\n",
            "IC=4.5688e-06,               ODE=1.1182e-04,               data=8.7501e-05,               total_loss=2.0389e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 5.8962e-07, val_ODE: 1.1556e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0037975], b: [0.00069771]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.009752035372358286\n",
            "Epoch 407:\n",
            "IC=3.1399e-06,               ODE=1.1530e-04,               data=8.9779e-05,               total_loss=2.0822e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.9492e-06, val_ODE: 1.1355e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0038664], b: [0.0007178]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009861729065373595\n",
            "Epoch 408:\n",
            "IC=2.7611e-06,               ODE=1.1589e-04,               data=8.2458e-05,               total_loss=2.0111e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 8.9640e-07, val_ODE: 1.1790e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0037894], b: [0.00064651]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.009193790919243402\n",
            "Epoch 409:\n",
            "IC=5.9803e-06,               ODE=1.3008e-04,               data=9.8152e-05,               total_loss=2.3421e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.9964e-06, val_ODE: 1.0789e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0037627], b: [0.00065551]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.010392881282243431\n",
            "Epoch 410:\n",
            "IC=4.2842e-06,               ODE=1.3375e-04,               data=1.1686e-04,               total_loss=2.5490e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.6099e-05, val_ODE: 1.6996e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0038044], b: [0.00071163]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.01026400632030329\n",
            "Epoch 411:\n",
            "IC=1.1892e-05,               ODE=1.4437e-04,               data=9.4953e-05,               total_loss=2.5122e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.2182e-06, val_ODE: 1.3177e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.003714], b: [0.00062135]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009496847970635724\n",
            "Epoch 412:\n",
            "IC=2.7147e-06,               ODE=1.2543e-04,               data=8.9600e-05,               total_loss=2.1775e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.3330e-07, val_ODE: 1.2314e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036583], b: [0.00060758]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009960133517271102\n",
            "Epoch 413:\n",
            "IC=2.4806e-06,               ODE=1.1024e-04,               data=8.5359e-05,               total_loss=1.9808e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0098e-06, val_ODE: 1.0748e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036082], b: [0.00053096]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.008860093986900465\n",
            "Epoch 414:\n",
            "IC=1.5408e-06,               ODE=1.0566e-04,               data=8.3361e-05,               total_loss=1.9056e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.8247e-06, val_ODE: 1.1452e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0035753], b: [0.00057754]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.009045153476811838\n",
            "Epoch 415:\n",
            "IC=1.1990e-06,               ODE=1.0580e-04,               data=8.0293e-05,               total_loss=1.8729e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8343e-06, val_ODE: 9.8235e-05, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0035877], b: [0.00053329]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00976180967646632\n",
            "Epoch 416:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.1270e-06,               ODE=1.0015e-04,               data=8.1530e-05,               total_loss=1.8281e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 6.6626e-07, val_ODE: 1.0283e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0035355], b: [0.00061001]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.009186185774800413\n",
            "Epoch 417:\n",
            "IC=1.1539e-06,               ODE=9.9281e-05,               data=8.4058e-05,               total_loss=1.8449e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.1548e-07, val_ODE: 1.0178e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0035], b: [0.00064854]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009064600843285921\n",
            "Epoch 418:\n",
            "IC=1.9852e-06,               ODE=1.0390e-04,               data=8.1655e-05,               total_loss=1.8754e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.0830e-06, val_ODE: 1.2394e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036256], b: [0.00070971]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009948461409782455\n",
            "Epoch 419:\n",
            "IC=5.0281e-06,               ODE=1.2641e-04,               data=9.3077e-05,               total_loss=2.2452e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.0976e-06, val_ODE: 1.1228e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0036037], b: [0.0007619]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.010198165228814143\n",
            "Epoch 420:\n",
            "IC=3.4337e-06,               ODE=1.2505e-04,               data=9.9069e-05,               total_loss=2.2755e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.9645e-06, val_ODE: 1.2662e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0034795], b: [0.00065357]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009317228605166716\n",
            "Epoch 421:\n",
            "IC=4.9794e-06,               ODE=1.1661e-04,               data=8.0665e-05,               total_loss=2.0225e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.7590e-06, val_ODE: 1.0281e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.003507], b: [0.00064103]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.009527727813900839\n",
            "Epoch 422:\n",
            "IC=3.7499e-06,               ODE=1.1728e-04,               data=8.9361e-05,               total_loss=2.1039e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.9717e-06, val_ODE: 1.2138e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0035048], b: [0.00066942]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.008905964239089605\n",
            "Epoch 423:\n",
            "IC=3.7806e-06,               ODE=1.1109e-04,               data=8.0226e-05,               total_loss=1.9509e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.4869e-06, val_ODE: 1.0799e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0034542], b: [0.00065017]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008869920703856529\n",
            "Epoch 424:\n",
            "IC=3.5376e-06,               ODE=1.0541e-04,               data=8.7614e-05,               total_loss=1.9657e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 4.2641e-06, val_ODE: 1.2266e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0034158], b: [0.00050838]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.010747217799941682\n",
            "Epoch 425:\n",
            "IC=4.2630e-06,               ODE=1.2501e-04,               data=1.0114e-04,               total_loss=2.3041e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6606e-06, val_ODE: 1.2916e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0034604], b: [0.00063815]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.009518747998212625\n",
            "Epoch 426:\n",
            "IC=7.7694e-06,               ODE=1.3562e-04,               data=9.6266e-05,               total_loss=2.3966e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.7547e-06, val_ODE: 1.2145e-04, lr: 5.00e-03\n",
            "\n",
            "a: [-2.0033503], b: [0.0007396]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.008897099646944009\n",
            "Epoch 427:\n",
            "IC=3.3082e-06,               ODE=1.0505e-04,               data=7.7368e-05,               total_loss=1.8572e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.9279e-07, val_ODE: 9.4678e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003318], b: [0.00070654]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.008678467245981576\n",
            "Epoch 428:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.0465e-06,               ODE=9.4656e-05,               data=7.4823e-05,               total_loss=1.7053e-04\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 5.1316e-07, val_ODE: 9.7376e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033102], b: [0.00074803]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "RMSE: 0.00844966827180417\n",
            "Epoch 429:\n",
            "IC=1.0875e-06,               ODE=9.4092e-05,               data=7.2693e-05,               total_loss=1.6787e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7003e-06, val_ODE: 9.4599e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033193], b: [0.00073505]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00867578698905865\n",
            "Epoch 430:\n",
            "IC=9.0596e-07,               ODE=9.1107e-05,               data=7.3618e-05,               total_loss=1.6563e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.3791e-07, val_ODE: 9.5460e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003345], b: [0.00070349]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.008544719160910482\n",
            "Epoch 431:\n",
            "IC=6.2187e-07,               ODE=9.1855e-05,               data=7.3674e-05,               total_loss=1.6615e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.1406e-07, val_ODE: 9.3876e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003338], b: [0.00068492]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.008372776283472699\n",
            "Epoch 432:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.9961e-07,               ODE=9.1080e-05,               data=7.2613e-05,               total_loss=1.6399e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.4955e-07, val_ODE: 9.0586e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.00332], b: [0.00067207]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.008662804204250594\n",
            "Epoch 433:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.3827e-07,               ODE=9.0783e-05,               data=7.4080e-05,               total_loss=1.6520e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 1.4139e-07, val_ODE: 9.3406e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033307], b: [0.00066845]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008598327575301346\n",
            "Epoch 434:\n",
            "IC=4.3033e-07,               ODE=9.2486e-05,               data=7.2453e-05,               total_loss=1.6537e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.7958e-07, val_ODE: 9.6226e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033317], b: [0.00064364]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00853229072053518\n",
            "Epoch 435:\n",
            "IC=9.1796e-07,               ODE=9.3958e-05,               data=7.4306e-05,               total_loss=1.6918e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 2.0397e-06, val_ODE: 9.6684e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003347], b: [0.00069581]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008416742136100696\n",
            "Epoch 436:\n",
            "IC=1.0519e-06,               ODE=9.3291e-05,               data=7.3061e-05,               total_loss=1.6740e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 2.3084e-07, val_ODE: 9.3359e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003363], b: [0.00063469]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.008476351764671609\n",
            "Epoch 437:\n",
            "IC=3.5485e-07,               ODE=9.3184e-05,               data=7.4364e-05,               total_loss=1.6790e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.1159e-07, val_ODE: 9.7868e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033667], b: [0.00064697]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.008446031747755954\n",
            "Epoch 438:\n",
            "IC=4.9038e-07,               ODE=9.0802e-05,               data=7.3599e-05,               total_loss=1.6489e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7212e-08, val_ODE: 9.6206e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033593], b: [0.00067153]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008428896559287576\n",
            "Epoch 439:\n",
            "IC=4.9170e-07,               ODE=9.2276e-05,               data=7.1942e-05,               total_loss=1.6471e-04\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "val_IC: 7.0047e-07, val_ODE: 9.2259e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033112], b: [0.00066165]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.008495033523876585\n",
            "Epoch 440:\n",
            "IC=6.1135e-07,               ODE=9.0838e-05,               data=7.2279e-05,               total_loss=1.6373e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 8.3071e-07, val_ODE: 9.2286e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033376], b: [0.00066264]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00837445911541956\n",
            "Epoch 441:\n",
            "IC=4.5554e-07,               ODE=9.0447e-05,               data=7.0875e-05,               total_loss=1.6178e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.1522e-07, val_ODE: 9.1839e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033486], b: [0.00061563]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0083425714402731\n",
            "Epoch 442:\n",
            "IC=3.1426e-07,               ODE=9.1618e-05,               data=7.2389e-05,               total_loss=1.6432e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.3972e-07, val_ODE: 9.5633e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003384], b: [0.00060857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008400245350075056\n",
            "Epoch 443:\n",
            "IC=9.1201e-07,               ODE=9.1563e-05,               data=7.4844e-05,               total_loss=1.6732e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.0353e-06, val_ODE: 9.3394e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033715], b: [0.00061639]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008520948069042633\n",
            "Epoch 444:\n",
            "IC=7.1154e-07,               ODE=9.2310e-05,               data=7.2933e-05,               total_loss=1.6595e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9368e-07, val_ODE: 9.6641e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003328], b: [0.00055713]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008380717343514749\n",
            "Epoch 445:\n",
            "IC=4.8360e-07,               ODE=9.2640e-05,               data=7.2205e-05,               total_loss=1.6533e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.6664e-07, val_ODE: 9.2232e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033312], b: [0.00062501]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008391388709768879\n",
            "Epoch 446:\n",
            "IC=9.8918e-07,               ODE=9.2728e-05,               data=7.3941e-05,               total_loss=1.6766e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.4344e-07, val_ODE: 9.2618e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033042], b: [0.00062672]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008396767349261237\n",
            "Epoch 447:\n",
            "IC=9.2538e-07,               ODE=9.1740e-05,               data=7.5463e-05,               total_loss=1.6813e-04\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 4.8220e-07, val_ODE: 9.8642e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003309], b: [0.00063966]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00840586707722233\n",
            "Epoch 448:\n",
            "IC=1.0407e-06,               ODE=9.2741e-05,               data=7.1904e-05,               total_loss=1.6569e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0113e-08, val_ODE: 9.1966e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033143], b: [0.00063536]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008345584088088462\n",
            "Epoch 449:\n",
            "IC=8.7404e-07,               ODE=9.2415e-05,               data=7.1878e-05,               total_loss=1.6517e-04\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "val_IC: 2.5911e-07, val_ODE: 9.3501e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0033379], b: [0.00058594]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.008980247976975969\n",
            "Epoch 450:\n",
            "IC=6.8793e-07,               ODE=9.3037e-05,               data=7.5204e-05,               total_loss=1.6893e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.8001e-07, val_ODE: 9.9453e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032766], b: [0.00058801]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008492952336596589\n",
            "Epoch 451:\n",
            "IC=6.7859e-07,               ODE=9.1757e-05,               data=7.3212e-05,               total_loss=1.6565e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8091e-08, val_ODE: 8.8976e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032866], b: [0.00058754]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.008439874904076532\n",
            "Epoch 452:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.8273e-07,               ODE=8.9156e-05,               data=7.1494e-05,               total_loss=1.6113e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8249e-07, val_ODE: 9.3729e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032852], b: [0.00060034]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00854565062018629\n",
            "Epoch 453:\n",
            "IC=7.4270e-07,               ODE=8.9720e-05,               data=7.1879e-05,               total_loss=1.6234e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 1.4687e-06, val_ODE: 1.0184e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.00326], b: [0.00061034]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008390112029461954\n",
            "Epoch 454:\n",
            "IC=1.0423e-06,               ODE=9.2100e-05,               data=7.4287e-05,               total_loss=1.6743e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.2962e-06, val_ODE: 9.9740e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032222], b: [0.00054744]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00904285885801396\n",
            "Epoch 455:\n",
            "IC=1.1569e-06,               ODE=9.2060e-05,               data=7.4109e-05,               total_loss=1.6733e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2692e-06, val_ODE: 8.9405e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003226], b: [0.00058491]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008355969140643786\n",
            "Epoch 456:\n",
            "IC=6.6987e-07,               ODE=8.9143e-05,               data=6.9633e-05,               total_loss=1.5945e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6742e-07, val_ODE: 8.9951e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032468], b: [0.00059625]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008332611229197208\n",
            "Epoch 457:\n",
            "IC=4.0039e-07,               ODE=8.8951e-05,               data=7.0587e-05,               total_loss=1.5994e-04\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "val_IC: 6.2244e-07, val_ODE: 8.9272e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032446], b: [0.00061878]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.008311513392700922\n",
            "Epoch 458:\n",
            "IC=7.0155e-07,               ODE=8.7538e-05,               data=7.1829e-05,               total_loss=1.6007e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1710e-07, val_ODE: 8.8255e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032084], b: [0.00058208]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008292645998428588\n",
            "Epoch 459:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.0774e-07,               ODE=8.8369e-05,               data=7.1828e-05,               total_loss=1.6040e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.6199e-07, val_ODE: 9.7533e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0032153], b: [0.00055916]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008628054928467565\n",
            "Epoch 460:\n",
            "IC=1.2090e-06,               ODE=9.1777e-05,               data=7.6041e-05,               total_loss=1.6903e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.3105e-06, val_ODE: 9.5220e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0031552], b: [0.00059805]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008335070087795124\n",
            "Epoch 461:\n",
            "IC=1.2164e-06,               ODE=9.2824e-05,               data=7.8501e-05,               total_loss=1.7254e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0209e-06, val_ODE: 9.3312e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0031476], b: [0.0005153]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008472320324218793\n",
            "Epoch 462:\n",
            "IC=4.5959e-07,               ODE=9.3696e-05,               data=7.3383e-05,               total_loss=1.6754e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.9145e-07, val_ODE: 1.0046e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.003051], b: [0.00056127]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008281510334446206\n",
            "Epoch 463:\n",
            "IC=8.1859e-07,               ODE=9.3388e-05,               data=7.4475e-05,               total_loss=1.6868e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.5499e-06, val_ODE: 1.0415e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029976], b: [0.00058167]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008392782117987475\n",
            "Epoch 464:\n",
            "IC=4.1548e-07,               ODE=9.2906e-05,               data=7.2823e-05,               total_loss=1.6614e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3458e-07, val_ODE: 9.4026e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029857], b: [0.00058768]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.008277579928928375\n",
            "Epoch 465:\n",
            "IC=5.4208e-07,               ODE=8.8062e-05,               data=6.8581e-05,               total_loss=1.5719e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 5.6896e-07, val_ODE: 9.3583e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029993], b: [0.00058482]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00815920230785922\n",
            "Epoch 466:\n",
            "IC=5.7593e-07,               ODE=8.8014e-05,               data=6.8627e-05,               total_loss=1.5722e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 5.1020e-07, val_ODE: 8.8148e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002955], b: [0.00057439]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008183522177877416\n",
            "Epoch 467:\n",
            "IC=6.6142e-07,               ODE=8.8425e-05,               data=6.9138e-05,               total_loss=1.5822e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3625e-06, val_ODE: 9.0005e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029817], b: [0.00056692]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.008493323483833524\n",
            "Epoch 468:\n",
            "IC=5.5219e-07,               ODE=8.7389e-05,               data=6.9269e-05,               total_loss=1.5721e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4411e-06, val_ODE: 9.7088e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029492], b: [0.00049571]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00838752560448496\n",
            "Epoch 469:\n",
            "IC=7.0423e-07,               ODE=8.9677e-05,               data=7.0589e-05,               total_loss=1.6097e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.4274e-07, val_ODE: 8.8905e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029836], b: [0.00052824]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.008247463402200724\n",
            "Epoch 470:\n",
            "IC=7.5790e-07,               ODE=8.6882e-05,               data=7.0606e-05,               total_loss=1.5825e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.0891e-07, val_ODE: 8.9216e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029967], b: [0.0005816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008172037419454265\n",
            "Epoch 471:\n",
            "IC=1.2674e-06,               ODE=9.0105e-05,               data=7.1490e-05,               total_loss=1.6286e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 7.1843e-07, val_ODE: 9.3936e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029795], b: [0.00062378]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008316178141279081\n",
            "Epoch 472:\n",
            "IC=1.6358e-06,               ODE=9.0264e-05,               data=7.2617e-05,               total_loss=1.6452e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3998e-06, val_ODE: 1.0053e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0030315], b: [0.00061207]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008568408523383706\n",
            "Epoch 473:\n",
            "IC=1.2088e-06,               ODE=8.7888e-05,               data=7.2589e-05,               total_loss=1.6169e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6212e-07, val_ODE: 9.4586e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.00303], b: [0.00060507]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008253629629690097\n",
            "Epoch 474:\n",
            "IC=6.4897e-07,               ODE=8.8936e-05,               data=7.1636e-05,               total_loss=1.6122e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.6004e-07, val_ODE: 9.1939e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0030093], b: [0.00062494]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.008364983854456765\n",
            "Epoch 475:\n",
            "IC=4.0086e-07,               ODE=8.9093e-05,               data=7.1120e-05,               total_loss=1.6061e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 1.0169e-06, val_ODE: 9.1202e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029795], b: [0.00057802]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.008168081734555481\n",
            "Epoch 476:\n",
            "IC=9.5888e-07,               ODE=9.0938e-05,               data=7.0214e-05,               total_loss=1.6211e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6768e-06, val_ODE: 9.3305e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0030034], b: [0.00059825]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008310655691134494\n",
            "Epoch 477:\n",
            "IC=1.6898e-06,               ODE=9.1559e-05,               data=6.9802e-05,               total_loss=1.6305e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.7893e-07, val_ODE: 1.0005e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029812], b: [0.00058082]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.008258771286101483\n",
            "Epoch 478:\n",
            "IC=5.5643e-07,               ODE=8.8359e-05,               data=7.0798e-05,               total_loss=1.5971e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.8285e-07, val_ODE: 8.7998e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029552], b: [0.00059179]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.00819156441562519\n",
            "Epoch 479:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.2471e-07,               ODE=8.6616e-05,               data=6.8075e-05,               total_loss=1.5492e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.8558e-07, val_ODE: 8.3303e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029325], b: [0.00054508]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00877972099966665\n",
            "Epoch 480:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.8508e-07,               ODE=8.9348e-05,               data=7.8520e-05,               total_loss=1.6875e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 1.9319e-06, val_ODE: 9.6125e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029328], b: [0.00048034]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008312326004162186\n",
            "Epoch 481:\n",
            "IC=6.1597e-07,               ODE=8.9197e-05,               data=6.8675e-05,               total_loss=1.5849e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.2271e-06, val_ODE: 8.6772e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002935], b: [0.0005295]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00885104996225868\n",
            "Epoch 482:\n",
            "IC=1.0980e-06,               ODE=9.3185e-05,               data=6.9817e-05,               total_loss=1.6410e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0794e-06, val_ODE: 9.3517e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002922], b: [0.00058393]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008350781016638805\n",
            "Epoch 483:\n",
            "IC=1.3623e-06,               ODE=9.1085e-05,               data=6.7951e-05,               total_loss=1.6040e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.8716e-07, val_ODE: 8.6111e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0029237], b: [0.00058182]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.008012590227251154\n",
            "Epoch 484:\n",
            "IC=1.2625e-06,               ODE=8.6976e-05,               data=6.7830e-05,               total_loss=1.5607e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.9860e-07, val_ODE: 9.5546e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002885], b: [0.00057107]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.008111793061176218\n",
            "Epoch 485:\n",
            "IC=9.5362e-07,               ODE=9.1111e-05,               data=7.0397e-05,               total_loss=1.6246e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5682e-06, val_ODE: 9.5951e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0028758], b: [0.00053296]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00841516210155658\n",
            "Epoch 486:\n",
            "IC=1.0012e-06,               ODE=9.5954e-05,               data=7.2478e-05,               total_loss=1.6943e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.2772e-07, val_ODE: 8.7799e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0028572], b: [0.00048519]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008160791803954098\n",
            "Epoch 487:\n",
            "IC=1.0283e-06,               ODE=9.2869e-05,               data=7.0655e-05,               total_loss=1.6455e-04\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 2.7273e-06, val_ODE: 9.8112e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027966], b: [0.00049461]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.008340444576590243\n",
            "Epoch 488:\n",
            "IC=1.9095e-06,               ODE=9.2173e-05,               data=6.7781e-05,               total_loss=1.6186e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 8.8434e-07, val_ODE: 8.9852e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027595], b: [0.00060685]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "RMSE: 0.008114131381937678\n",
            "Epoch 489:\n",
            "IC=8.8901e-07,               ODE=8.7339e-05,               data=6.6137e-05,               total_loss=1.5436e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0437e-07, val_ODE: 8.4064e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027502], b: [0.00053163]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008038473174159962\n",
            "Epoch 490:\n",
            "IC=8.6633e-07,               ODE=8.7003e-05,               data=6.8206e-05,               total_loss=1.5608e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.4728e-07, val_ODE: 8.8903e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027432], b: [0.00048971]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008151871594192636\n",
            "Epoch 491:\n",
            "IC=8.2927e-07,               ODE=8.5664e-05,               data=6.5597e-05,               total_loss=1.5209e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.3227e-06, val_ODE: 8.8607e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027647], b: [0.00044679]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.008056356994911841\n",
            "Epoch 492:\n",
            "IC=1.6738e-06,               ODE=8.5981e-05,               data=6.7040e-05,               total_loss=1.5469e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.6288e-07, val_ODE: 8.8834e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0027328], b: [0.00043325]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00804354624866578\n",
            "Epoch 493:\n",
            "IC=9.0384e-07,               ODE=8.6962e-05,               data=7.1226e-05,               total_loss=1.5909e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.9806e-06, val_ODE: 8.9356e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026789], b: [0.00053152]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.008113824850688916\n",
            "Epoch 494:\n",
            "IC=1.0413e-06,               ODE=8.7044e-05,               data=6.8593e-05,               total_loss=1.5668e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.4721e-07, val_ODE: 8.9590e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026472], b: [0.00043015]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00825172208460536\n",
            "Epoch 495:\n",
            "IC=6.8872e-07,               ODE=8.5875e-05,               data=6.5200e-05,               total_loss=1.5176e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.6405e-07, val_ODE: 8.7035e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026283], b: [0.00047707]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008100202825074872\n",
            "Epoch 496:\n",
            "IC=6.2783e-07,               ODE=8.4150e-05,               data=6.5233e-05,               total_loss=1.5001e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 9.8858e-07, val_ODE: 8.5823e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026402], b: [0.00045778]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007974044394912066\n",
            "Epoch 497:\n",
            "IC=8.8170e-07,               ODE=8.6472e-05,               data=6.6064e-05,               total_loss=1.5342e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3188e-06, val_ODE: 9.0741e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026128], b: [0.00053962]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008060417410047278\n",
            "Epoch 498:\n",
            "IC=9.7760e-07,               ODE=8.6630e-05,               data=6.9282e-05,               total_loss=1.5689e-04\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "val_IC: 1.4118e-07, val_ODE: 9.4259e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026324], b: [0.00049684]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.008054210258442988\n",
            "Epoch 499:\n",
            "IC=1.4389e-06,               ODE=8.8457e-05,               data=7.0723e-05,               total_loss=1.6062e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.9292e-06, val_ODE: 8.9437e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026338], b: [0.0005541]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.00831265577270679\n",
            "Epoch 500:\n",
            "IC=2.3852e-06,               ODE=9.0268e-05,               data=6.9663e-05,               total_loss=1.6232e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.0042e-06, val_ODE: 9.6434e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026333], b: [0.00047247]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008002374152069657\n",
            "Epoch 501:\n",
            "IC=1.6377e-06,               ODE=9.3833e-05,               data=6.7554e-05,               total_loss=1.6303e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8453e-06, val_ODE: 9.3699e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026386], b: [0.0005416]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008551332128129467\n",
            "Epoch 502:\n",
            "IC=2.3471e-06,               ODE=8.9174e-05,               data=6.9666e-05,               total_loss=1.6119e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.0104e-06, val_ODE: 8.7903e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026648], b: [0.00058264]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008255984299819878\n",
            "Epoch 503:\n",
            "IC=2.3034e-06,               ODE=8.9987e-05,               data=6.7767e-05,               total_loss=1.6006e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.0247e-07, val_ODE: 9.2024e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026553], b: [0.00056558]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008331394907761665\n",
            "Epoch 504:\n",
            "IC=1.0024e-06,               ODE=8.9662e-05,               data=6.7089e-05,               total_loss=1.5775e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.7959e-06, val_ODE: 9.2388e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.00264], b: [0.00058675]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008196147658215344\n",
            "Epoch 505:\n",
            "IC=1.4666e-06,               ODE=8.9281e-05,               data=7.3952e-05,               total_loss=1.6470e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.7085e-07, val_ODE: 9.3010e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0026152], b: [0.00054243]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.008018270048610025\n",
            "Epoch 506:\n",
            "IC=8.5246e-07,               ODE=8.6615e-05,               data=6.8669e-05,               total_loss=1.5614e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.7005e-07, val_ODE: 8.8065e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025623], b: [0.00046679]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008553537318784244\n",
            "Epoch 507:\n",
            "IC=1.3762e-06,               ODE=8.5109e-05,               data=6.9254e-05,               total_loss=1.5574e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3155e-06, val_ODE: 8.6555e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025277], b: [0.00043202]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008234285247245867\n",
            "Epoch 508:\n",
            "IC=1.4621e-06,               ODE=8.5436e-05,               data=6.4283e-05,               total_loss=1.5118e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1320e-06, val_ODE: 8.5373e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002545], b: [0.00044988]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007947477866887105\n",
            "Epoch 509:\n",
            "IC=1.0407e-06,               ODE=8.3844e-05,               data=6.4218e-05,               total_loss=1.4910e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.8360e-07, val_ODE: 8.1808e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025532], b: [0.00052106]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007895746597347703\n",
            "Epoch 510:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.0599e-07,               ODE=8.5167e-05,               data=6.7840e-05,               total_loss=1.5381e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3818e-06, val_ODE: 8.4112e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025353], b: [0.00043209]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007898424956096044\n",
            "Epoch 511:\n",
            "IC=1.2734e-06,               ODE=8.3065e-05,               data=6.4788e-05,               total_loss=1.4913e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.7867e-07, val_ODE: 8.1737e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025315], b: [0.00049055]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008060704505166886\n",
            "Epoch 512:\n",
            "IC=1.0978e-06,               ODE=8.9745e-05,               data=6.6426e-05,               total_loss=1.5727e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.5284e-07, val_ODE: 8.8312e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002553], b: [0.00053489]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.00797208428022908\n",
            "Epoch 513:\n",
            "IC=2.6342e-06,               ODE=9.5984e-05,               data=7.2154e-05,               total_loss=1.7077e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6701e-06, val_ODE: 9.0353e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0025165], b: [0.00051671]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008132511930306095\n",
            "Epoch 514:\n",
            "IC=2.5491e-06,               ODE=9.0083e-05,               data=6.7637e-05,               total_loss=1.6027e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 4.7950e-07, val_ODE: 7.8743e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024679], b: [0.00052459]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.009410786849214745\n",
            "Epoch 515:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=7.9120e-07,               ODE=8.5986e-05,               data=7.0109e-05,               total_loss=1.5689e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.8240e-06, val_ODE: 8.8935e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024214], b: [0.00049368]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008104707094646252\n",
            "Epoch 516:\n",
            "IC=1.3651e-06,               ODE=8.6011e-05,               data=6.4951e-05,               total_loss=1.5233e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.2604e-07, val_ODE: 8.7037e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024018], b: [0.00047824]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007894879739358516\n",
            "Epoch 517:\n",
            "IC=1.5625e-06,               ODE=8.7346e-05,               data=6.4945e-05,               total_loss=1.5385e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7651e-06, val_ODE: 8.9243e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002458], b: [0.00050477]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008049051570095413\n",
            "Epoch 518:\n",
            "IC=1.1503e-06,               ODE=8.9769e-05,               data=6.4734e-05,               total_loss=1.5565e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.9868e-09, val_ODE: 8.1238e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024602], b: [0.00052444]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00776611791865343\n",
            "Epoch 519:\n",
            "IC=4.6553e-07,               ODE=8.4009e-05,               data=6.4579e-05,               total_loss=1.4905e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.5281e-07, val_ODE: 9.0631e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024538], b: [0.00054699]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.008047498795566585\n",
            "Epoch 520:\n",
            "IC=9.4195e-07,               ODE=8.7145e-05,               data=6.3323e-05,               total_loss=1.5141e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6173e-06, val_ODE: 9.2593e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.002418], b: [0.00050458]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007888439238379412\n",
            "Epoch 521:\n",
            "IC=1.1957e-06,               ODE=8.8242e-05,               data=6.4740e-05,               total_loss=1.5418e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6157e-06, val_ODE: 8.0128e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0024233], b: [0.00048694]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.008156397972178684\n",
            "Epoch 522:\n",
            "IC=1.4857e-06,               ODE=8.4559e-05,               data=6.7258e-05,               total_loss=1.5330e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8359e-07, val_ODE: 8.5206e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.00238], b: [0.0004662]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007856639380461133\n",
            "Epoch 523:\n",
            "IC=1.1901e-06,               ODE=8.7129e-05,               data=6.3347e-05,               total_loss=1.5167e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0014e-06, val_ODE: 9.3173e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0023735], b: [0.00045913]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007776561646677772\n",
            "Epoch 524:\n",
            "IC=8.8929e-07,               ODE=8.1998e-05,               data=6.1775e-05,               total_loss=1.4466e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7356e-07, val_ODE: 8.4530e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0023305], b: [0.00040855]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0077137798029593314\n",
            "Epoch 525:\n",
            "IC=1.7863e-06,               ODE=8.3912e-05,               data=6.3107e-05,               total_loss=1.4881e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.9843e-06, val_ODE: 9.8847e-05, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0023172], b: [0.00040977]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007926422106717386\n",
            "Epoch 526:\n",
            "IC=2.2027e-06,               ODE=9.0191e-05,               data=6.9576e-05,               total_loss=1.6197e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 3.6222e-06, val_ODE: 1.1386e-04, lr: 2.50e-03\n",
            "\n",
            "a: [-2.0023081], b: [0.00051556]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "RMSE: 0.008889698468857548\n",
            "Epoch 527:\n",
            "IC=2.0848e-06,               ODE=9.4578e-05,               data=6.9561e-05,               total_loss=1.6622e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.5104e-07, val_ODE: 9.4001e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023367], b: [0.00057633]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00815243347612236\n",
            "Epoch 528:\n",
            "IC=7.4497e-07,               ODE=8.5426e-05,               data=6.4804e-05,               total_loss=1.5097e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.4254e-07, val_ODE: 8.7438e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023413], b: [0.00060919]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00792036902767153\n",
            "Epoch 529:\n",
            "IC=5.3289e-07,               ODE=7.9498e-05,               data=6.2973e-05,               total_loss=1.4300e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.0274e-06, val_ODE: 8.2013e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023563], b: [0.00054111]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007713294262394357\n",
            "Epoch 530:\n",
            "IC=6.4421e-07,               ODE=7.8262e-05,               data=6.1259e-05,               total_loss=1.4017e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.2764e-07, val_ODE: 8.3513e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023563], b: [0.00050227]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007763329005128596\n",
            "Epoch 531:\n",
            "IC=2.0477e-07,               ODE=7.9282e-05,               data=6.0457e-05,               total_loss=1.3994e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.2706e-07, val_ODE: 7.7162e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023336], b: [0.00052441]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.008093481114894822\n",
            "Epoch 532:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.1519e-07,               ODE=7.9453e-05,               data=6.0742e-05,               total_loss=1.4071e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.3213e-07, val_ODE: 8.2871e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023332], b: [0.00049829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0077012975212203665\n",
            "Epoch 533:\n",
            "IC=5.2293e-07,               ODE=7.9109e-05,               data=5.9985e-05,               total_loss=1.3962e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.7027e-08, val_ODE: 7.8351e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023384], b: [0.0004815]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007883329165778065\n",
            "Epoch 534:\n",
            "IC=2.1059e-07,               ODE=7.7874e-05,               data=6.1530e-05,               total_loss=1.3961e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.9738e-07, val_ODE: 8.3268e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002336], b: [0.00048766]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.007786307984527431\n",
            "Epoch 535:\n",
            "IC=3.0072e-07,               ODE=7.9250e-05,               data=6.0487e-05,               total_loss=1.4004e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.2491e-07, val_ODE: 8.0922e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023246], b: [0.0004809]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007627192713324712\n",
            "Epoch 536:\n",
            "IC=5.8966e-07,               ODE=7.8323e-05,               data=6.1167e-05,               total_loss=1.4008e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6491e-07, val_ODE: 8.1937e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023339], b: [0.00051217]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007597304325320906\n",
            "Epoch 537:\n",
            "IC=3.7409e-07,               ODE=7.8783e-05,               data=6.1644e-05,               total_loss=1.4080e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 4.9020e-07, val_ODE: 8.3947e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023549], b: [0.00051215]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.007703573049749328\n",
            "Epoch 538:\n",
            "IC=4.8427e-07,               ODE=7.9198e-05,               data=6.0291e-05,               total_loss=1.3997e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 8.5740e-07, val_ODE: 7.8886e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023212], b: [0.00047132]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007785831966170761\n",
            "Epoch 539:\n",
            "IC=4.7107e-07,               ODE=7.9597e-05,               data=6.1696e-05,               total_loss=1.4176e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.1186e-07, val_ODE: 7.8057e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023017], b: [0.00049212]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007849731147738685\n",
            "Epoch 540:\n",
            "IC=2.8475e-07,               ODE=7.9577e-05,               data=5.9571e-05,               total_loss=1.3943e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1958e-07, val_ODE: 7.9460e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022871], b: [0.00050415]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007819883772896753\n",
            "Epoch 541:\n",
            "IC=1.8638e-07,               ODE=8.0177e-05,               data=5.9578e-05,               total_loss=1.3994e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 5.8543e-07, val_ODE: 8.0660e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022895], b: [0.00051414]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007755335868392767\n",
            "Epoch 542:\n",
            "IC=1.4740e-07,               ODE=7.6640e-05,               data=5.9976e-05,               total_loss=1.3676e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 6.7781e-08, val_ODE: 7.8498e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023286], b: [0.00050307]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007574688642054326\n",
            "Epoch 543:\n",
            "IC=1.0666e-07,               ODE=7.5888e-05,               data=5.8764e-05,               total_loss=1.3476e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0442e-08, val_ODE: 8.0041e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.00231], b: [0.00048435]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007568981929181288\n",
            "Epoch 544:\n",
            "IC=1.9535e-07,               ODE=7.7105e-05,               data=5.9043e-05,               total_loss=1.3634e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.4807e-07, val_ODE: 7.8889e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022962], b: [0.00049841]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.00779570896358322\n",
            "Epoch 545:\n",
            "IC=3.3602e-07,               ODE=7.8158e-05,               data=5.8733e-05,               total_loss=1.3723e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.8586e-07, val_ODE: 7.8082e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002306], b: [0.00048671]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007640532858666635\n",
            "Epoch 546:\n",
            "IC=1.1516e-07,               ODE=7.6064e-05,               data=5.9036e-05,               total_loss=1.3521e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.3620e-08, val_ODE: 7.9582e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022967], b: [0.00048957]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00755543832775649\n",
            "Epoch 547:\n",
            "IC=1.0672e-07,               ODE=7.6832e-05,               data=5.9114e-05,               total_loss=1.3605e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 3.6565e-07, val_ODE: 8.0227e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023139], b: [0.00046232]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007568895882867452\n",
            "Epoch 548:\n",
            "IC=2.6606e-07,               ODE=7.7132e-05,               data=6.0010e-05,               total_loss=1.3741e-04\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "val_IC: 2.6572e-07, val_ODE: 7.7639e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022898], b: [0.00044253]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.007677492935639857\n",
            "Epoch 549:\n",
            "IC=2.1975e-07,               ODE=7.6870e-05,               data=6.1196e-05,               total_loss=1.3829e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.6984e-07, val_ODE: 8.5749e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022988], b: [0.00045044]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007660200644072906\n",
            "Epoch 550:\n",
            "IC=7.7164e-07,               ODE=8.0940e-05,               data=5.9054e-05,               total_loss=1.4077e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.2018e-07, val_ODE: 7.9814e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002299], b: [0.00047902]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007659955555550268\n",
            "Epoch 551:\n",
            "IC=5.3357e-07,               ODE=7.8032e-05,               data=5.8619e-05,               total_loss=1.3718e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 1.0184e-06, val_ODE: 7.7230e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022638], b: [0.00044778]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.00773978088329691\n",
            "Epoch 552:\n",
            "IC=7.3644e-07,               ODE=7.8383e-05,               data=5.9613e-05,               total_loss=1.3873e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.3912e-06, val_ODE: 8.0384e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0023026], b: [0.00040293]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0076284218319942875\n",
            "Epoch 553:\n",
            "IC=7.2838e-07,               ODE=7.7853e-05,               data=5.9608e-05,               total_loss=1.3819e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.9479e-07, val_ODE: 7.7062e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022829], b: [0.00041036]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.007699156122763889\n",
            "Epoch 554:\n",
            "IC=5.9627e-07,               ODE=7.8794e-05,               data=5.9664e-05,               total_loss=1.3905e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 8.5422e-07, val_ODE: 7.8112e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.00228], b: [0.00041519]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.007522097113024159\n",
            "Epoch 555:\n",
            "IC=8.6794e-07,               ODE=7.8658e-05,               data=5.9305e-05,               total_loss=1.3883e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.8010e-06, val_ODE: 8.3432e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002262], b: [0.00042646]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007684824741125957\n",
            "Epoch 556:\n",
            "IC=1.4176e-06,               ODE=7.9344e-05,               data=6.1618e-05,               total_loss=1.4238e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4952e-09, val_ODE: 8.1664e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022895], b: [0.00037959]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00754473959820611\n",
            "Epoch 557:\n",
            "IC=8.6579e-07,               ODE=7.8391e-05,               data=6.0233e-05,               total_loss=1.3949e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2680e-06, val_ODE: 8.0000e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022686], b: [0.00036905]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007552678565408944\n",
            "Epoch 558:\n",
            "IC=1.0976e-06,               ODE=7.8247e-05,               data=5.9796e-05,               total_loss=1.3914e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.2683e-06, val_ODE: 8.0180e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022628], b: [0.00039784]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.007571843062821892\n",
            "Epoch 559:\n",
            "IC=1.1360e-06,               ODE=7.8463e-05,               data=5.8045e-05,               total_loss=1.3764e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.2218e-07, val_ODE: 7.8739e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002249], b: [0.00036735]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007563341443026247\n",
            "Epoch 560:\n",
            "IC=5.6748e-07,               ODE=7.7480e-05,               data=5.9925e-05,               total_loss=1.3797e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.3953e-08, val_ODE: 7.7826e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022323], b: [0.00036931]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0076146759724458005\n",
            "Epoch 561:\n",
            "IC=1.4365e-07,               ODE=7.5403e-05,               data=5.8471e-05,               total_loss=1.3402e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.1547e-07, val_ODE: 7.9156e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021865], b: [0.0003903]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007694872017579054\n",
            "Epoch 562:\n",
            "IC=4.2383e-07,               ODE=7.7492e-05,               data=5.9997e-05,               total_loss=1.3791e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.8040e-07, val_ODE: 8.0619e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002206], b: [0.0003328]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0075520616758618965\n",
            "Epoch 563:\n",
            "IC=8.2479e-07,               ODE=7.7478e-05,               data=5.8918e-05,               total_loss=1.3722e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.2762e-07, val_ODE: 7.9819e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002214], b: [0.00035327]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007594523897790877\n",
            "Epoch 564:\n",
            "IC=5.7544e-07,               ODE=7.6534e-05,               data=5.7943e-05,               total_loss=1.3505e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.0271e-07, val_ODE: 7.8256e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0022182], b: [0.00041136]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00752732433064112\n",
            "Epoch 565:\n",
            "IC=3.4939e-07,               ODE=7.5373e-05,               data=5.7186e-05,               total_loss=1.3291e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.0461e-07, val_ODE: 7.6314e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002205], b: [0.00038995]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.007598183373036459\n",
            "Epoch 566:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.4339e-07,               ODE=7.5796e-05,               data=5.7107e-05,               total_loss=1.3335e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.7473e-08, val_ODE: 7.5492e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021982], b: [0.00035225]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.007581729515687676\n",
            "Epoch 567:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.4971e-07,               ODE=7.5855e-05,               data=5.9328e-05,               total_loss=1.3533e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.7892e-08, val_ODE: 7.8511e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.00219], b: [0.00037035]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007501185195678698\n",
            "Epoch 568:\n",
            "IC=3.8712e-07,               ODE=7.7338e-05,               data=6.0610e-05,               total_loss=1.3834e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.7314e-07, val_ODE: 7.5816e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021982], b: [0.00040021]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.007924108128680713\n",
            "Epoch 569:\n",
            "IC=4.9659e-07,               ODE=7.5764e-05,               data=5.8548e-05,               total_loss=1.3481e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.5624e-07, val_ODE: 7.9422e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021868], b: [0.00041694]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007615322490664217\n",
            "Epoch 570:\n",
            "IC=6.2186e-07,               ODE=7.6720e-05,               data=5.9534e-05,               total_loss=1.3688e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 3.8392e-07, val_ODE: 8.0000e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002164], b: [0.00037158]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.007705893243357265\n",
            "Epoch 571:\n",
            "IC=4.3875e-07,               ODE=8.1034e-05,               data=5.9232e-05,               total_loss=1.4070e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 2.0069e-06, val_ODE: 8.8256e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021715], b: [0.00036341]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.007890242164634612\n",
            "Epoch 572:\n",
            "IC=9.9781e-07,               ODE=8.0282e-05,               data=6.0792e-05,               total_loss=1.4207e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0460e-06, val_ODE: 7.8592e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002155], b: [0.00036567]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0075389232459419165\n",
            "Epoch 573:\n",
            "IC=1.0733e-06,               ODE=7.8035e-05,               data=6.3696e-05,               total_loss=1.4280e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.8585e-06, val_ODE: 8.2271e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021222], b: [0.00032365]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007924973136016816\n",
            "Epoch 574:\n",
            "IC=1.8759e-06,               ODE=8.0825e-05,               data=5.9613e-05,               total_loss=1.4231e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.7340e-06, val_ODE: 8.0472e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020857], b: [0.00039838]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007687196408651362\n",
            "Epoch 575:\n",
            "IC=1.9104e-06,               ODE=7.7444e-05,               data=5.8396e-05,               total_loss=1.3775e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.8443e-06, val_ODE: 7.8131e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002118], b: [0.00038408]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007578476914970473\n",
            "Epoch 576:\n",
            "IC=6.7740e-07,               ODE=7.6475e-05,               data=5.8022e-05,               total_loss=1.3517e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0695e-06, val_ODE: 7.8878e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002098], b: [0.00042391]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007441364054621588\n",
            "Epoch 577:\n",
            "IC=9.1290e-07,               ODE=7.7969e-05,               data=5.7291e-05,               total_loss=1.3617e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.8476e-07, val_ODE: 7.8859e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020912], b: [0.00038566]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007746419404834907\n",
            "Epoch 578:\n",
            "IC=5.2730e-07,               ODE=7.7737e-05,               data=5.8526e-05,               total_loss=1.3679e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.5435e-07, val_ODE: 7.6591e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020714], b: [0.0003824]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00782006464172428\n",
            "Epoch 579:\n",
            "IC=7.1773e-07,               ODE=7.6889e-05,               data=5.9647e-05,               total_loss=1.3725e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.3533e-06, val_ODE: 7.8229e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021133], b: [0.0004063]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0075554472608948065\n",
            "Epoch 580:\n",
            "IC=9.1355e-07,               ODE=7.5988e-05,               data=5.7691e-05,               total_loss=1.3459e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.5417e-07, val_ODE: 7.6298e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021167], b: [0.00043466]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0073837725252267165\n",
            "Epoch 581:\n",
            "IC=3.9844e-07,               ODE=7.5892e-05,               data=5.6971e-05,               total_loss=1.3326e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 6.6570e-07, val_ODE: 7.5914e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020874], b: [0.00042472]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.007369290222165874\n",
            "Epoch 582:\n",
            "IC=4.3273e-07,               ODE=7.4215e-05,               data=5.7933e-05,               total_loss=1.3258e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.5784e-07, val_ODE: 7.5528e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020862], b: [0.00040629]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007553799431621042\n",
            "Epoch 583:\n",
            "IC=6.8520e-07,               ODE=7.4823e-05,               data=5.7429e-05,               total_loss=1.3294e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.2799e-07, val_ODE: 7.6343e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021198], b: [0.0004108]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.007431019696242625\n",
            "Epoch 584:\n",
            "IC=5.0618e-07,               ODE=7.4394e-05,               data=5.6367e-05,               total_loss=1.3127e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7022e-07, val_ODE: 7.8422e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020828], b: [0.00041402]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007411002627416435\n",
            "Epoch 585:\n",
            "IC=2.4576e-07,               ODE=7.4388e-05,               data=5.6949e-05,               total_loss=1.3158e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0613e-07, val_ODE: 7.6689e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021162], b: [0.00041879]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0073758006357264394\n",
            "Epoch 586:\n",
            "IC=1.9098e-07,               ODE=7.4897e-05,               data=5.6287e-05,               total_loss=1.3138e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.0231e-07, val_ODE: 8.1101e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0021038], b: [0.00043521]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007442061867136663\n",
            "Epoch 587:\n",
            "IC=4.3584e-07,               ODE=7.5200e-05,               data=5.6628e-05,               total_loss=1.3226e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.3696e-07, val_ODE: 7.7835e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020869], b: [0.00041602]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007395556192251228\n",
            "Epoch 588:\n",
            "IC=5.8036e-07,               ODE=7.5065e-05,               data=5.6561e-05,               total_loss=1.3221e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0292e-06, val_ODE: 7.5405e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020874], b: [0.00042483]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007447326648931222\n",
            "Epoch 589:\n",
            "IC=5.0563e-07,               ODE=7.5399e-05,               data=5.6861e-05,               total_loss=1.3277e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.4733e-07, val_ODE: 7.6390e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020978], b: [0.00044119]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007355755129819647\n",
            "Epoch 590:\n",
            "IC=1.1654e-07,               ODE=7.5087e-05,               data=5.5895e-05,               total_loss=1.3110e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 7.5821e-07, val_ODE: 7.5688e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002066], b: [0.00038751]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.007452123261832337\n",
            "Epoch 591:\n",
            "IC=4.6425e-07,               ODE=7.5699e-05,               data=5.6487e-05,               total_loss=1.3265e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4692e-06, val_ODE: 7.4990e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020487], b: [0.00039013]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.007785324865382199\n",
            "Epoch 592:\n",
            "IC=5.5314e-07,               ODE=7.6803e-05,               data=5.7895e-05,               total_loss=1.3525e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.3839e-07, val_ODE: 7.6275e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020585], b: [0.00038624]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007758201952580624\n",
            "Epoch 593:\n",
            "IC=6.3474e-07,               ODE=7.6085e-05,               data=5.7637e-05,               total_loss=1.3436e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.9949e-07, val_ODE: 7.5518e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.00208], b: [0.00036425]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.007594019514001821\n",
            "Epoch 594:\n",
            "IC=2.0185e-07,               ODE=7.4773e-05,               data=5.6201e-05,               total_loss=1.3118e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.9950e-07, val_ODE: 7.6058e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020573], b: [0.000399]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007308481457511579\n",
            "Epoch 595:\n",
            "IC=2.2306e-07,               ODE=7.3627e-05,               data=5.5635e-05,               total_loss=1.2948e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.0389e-06, val_ODE: 7.7368e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020761], b: [0.00046158]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007366146298095025\n",
            "Epoch 596:\n",
            "IC=4.8426e-07,               ODE=7.4909e-05,               data=5.6521e-05,               total_loss=1.3191e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.8372e-07, val_ODE: 7.6348e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020533], b: [0.00041858]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007452958103428665\n",
            "Epoch 597:\n",
            "IC=6.5446e-07,               ODE=7.5502e-05,               data=5.6684e-05,               total_loss=1.3284e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0280e-06, val_ODE: 7.6008e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020592], b: [0.00044443]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007998402696180944\n",
            "Epoch 598:\n",
            "IC=5.4257e-07,               ODE=7.7282e-05,               data=5.6729e-05,               total_loss=1.3455e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.4016e-08, val_ODE: 7.2092e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020378], b: [0.00039926]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.008073522241165192\n",
            "Epoch 599:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=7.5452e-07,               ODE=7.6206e-05,               data=5.8050e-05,               total_loss=1.3501e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 3.8507e-08, val_ODE: 7.3821e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002032], b: [0.00039033]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "RMSE: 0.0074334461065133865\n",
            "Epoch 600:\n",
            "IC=6.4891e-07,               ODE=7.7172e-05,               data=6.4126e-05,               total_loss=1.4195e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.3177e-06, val_ODE: 8.2800e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.00204], b: [0.00040008]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007431277869825212\n",
            "Epoch 601:\n",
            "IC=1.3183e-06,               ODE=7.8949e-05,               data=5.9303e-05,               total_loss=1.3957e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.0221e-07, val_ODE: 8.2681e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020516], b: [0.00049473]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007458070321449571\n",
            "Epoch 602:\n",
            "IC=1.1126e-06,               ODE=7.5645e-05,               data=5.5932e-05,               total_loss=1.3269e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0628e-07, val_ODE: 7.6623e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020523], b: [0.00049204]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007293048869521355\n",
            "Epoch 603:\n",
            "IC=1.0214e-06,               ODE=7.4535e-05,               data=5.5893e-05,               total_loss=1.3145e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1926e-06, val_ODE: 7.6580e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.002001], b: [0.00046195]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007394448534032147\n",
            "Epoch 604:\n",
            "IC=6.0387e-07,               ODE=7.3908e-05,               data=5.5302e-05,               total_loss=1.2981e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1419e-06, val_ODE: 7.4455e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019796], b: [0.0004302]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007779094443198792\n",
            "Epoch 605:\n",
            "IC=1.0028e-06,               ODE=7.8798e-05,               data=5.7711e-05,               total_loss=1.3751e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.9886e-07, val_ODE: 7.6999e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019836], b: [0.00038333]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007443053733220671\n",
            "Epoch 606:\n",
            "IC=8.3802e-07,               ODE=7.6390e-05,               data=5.5520e-05,               total_loss=1.3275e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7438e-06, val_ODE: 7.7838e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.001994], b: [0.00043992]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007691381965201622\n",
            "Epoch 607:\n",
            "IC=5.7068e-07,               ODE=7.4379e-05,               data=5.7150e-05,               total_loss=1.3210e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 8.1034e-07, val_ODE: 9.1332e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019696], b: [0.00036518]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007615414912873959\n",
            "Epoch 608:\n",
            "IC=8.3039e-07,               ODE=7.7984e-05,               data=5.5549e-05,               total_loss=1.3436e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.1707e-06, val_ODE: 7.7125e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0020382], b: [0.00044772]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007319646734264825\n",
            "Epoch 609:\n",
            "IC=6.6546e-07,               ODE=7.4695e-05,               data=5.3998e-05,               total_loss=1.2936e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.2065e-07, val_ODE: 7.9367e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.001994], b: [0.0004704]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.007417628335251577\n",
            "Epoch 610:\n",
            "IC=6.5376e-07,               ODE=7.6609e-05,               data=5.6678e-05,               total_loss=1.3394e-04\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "val_IC: 6.3089e-07, val_ODE: 7.6022e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019963], b: [0.00045204]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.007351802710145334\n",
            "Epoch 611:\n",
            "IC=2.4451e-07,               ODE=7.2406e-05,               data=5.4142e-05,               total_loss=1.2679e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 6.5301e-08, val_ODE: 7.3196e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019248], b: [0.00040533]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.0072288192939663305\n",
            "Epoch 612:\n",
            "IC=2.5099e-07,               ODE=7.2844e-05,               data=5.4012e-05,               total_loss=1.2711e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.5852e-07, val_ODE: 7.7064e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018938], b: [0.00039497]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007213803543630956\n",
            "Epoch 613:\n",
            "IC=4.2252e-07,               ODE=7.4337e-05,               data=5.4146e-05,               total_loss=1.2890e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 3.0511e-07, val_ODE: 7.4349e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019162], b: [0.00039309]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007717438390956313\n",
            "Epoch 614:\n",
            "IC=4.7084e-07,               ODE=7.5695e-05,               data=5.8239e-05,               total_loss=1.3440e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.3457e-07, val_ODE: 8.0095e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0019212], b: [0.00038776]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007507326840611652\n",
            "Epoch 615:\n",
            "IC=6.8676e-07,               ODE=7.6823e-05,               data=5.4198e-05,               total_loss=1.3171e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.0580e-07, val_ODE: 7.2241e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018947], b: [0.00035815]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00723699850097325\n",
            "Epoch 616:\n",
            "IC=3.3601e-07,               ODE=7.3663e-05,               data=5.6775e-05,               total_loss=1.3077e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.7779e-08, val_ODE: 7.9156e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.001862], b: [0.00035853]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0077016076372522545\n",
            "Epoch 617:\n",
            "IC=1.5341e-06,               ODE=7.6812e-05,               data=5.6603e-05,               total_loss=1.3495e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4230e-06, val_ODE: 7.6939e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018947], b: [0.0003173]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00749607965060894\n",
            "Epoch 618:\n",
            "IC=1.1040e-06,               ODE=7.4917e-05,               data=5.6557e-05,               total_loss=1.3258e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3034e-07, val_ODE: 7.3119e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018537], b: [0.00027966]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007282217600180465\n",
            "Epoch 619:\n",
            "IC=7.1800e-07,               ODE=7.6948e-05,               data=5.6369e-05,               total_loss=1.3404e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.2880e-07, val_ODE: 7.4117e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.001863], b: [0.00033776]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007529686170341601\n",
            "Epoch 620:\n",
            "IC=6.4996e-07,               ODE=7.3539e-05,               data=5.5124e-05,               total_loss=1.2931e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.5928e-07, val_ODE: 7.4014e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018256], b: [0.00028766]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.007322539163541071\n",
            "Epoch 621:\n",
            "IC=8.4163e-07,               ODE=7.4421e-05,               data=5.7116e-05,               total_loss=1.3238e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.7604e-06, val_ODE: 7.6990e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018036], b: [0.00036599]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007680016821901839\n",
            "Epoch 622:\n",
            "IC=1.2746e-06,               ODE=7.4464e-05,               data=5.4970e-05,               total_loss=1.3071e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6764e-07, val_ODE: 7.1072e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018082], b: [0.00037888]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.007250646053672655\n",
            "Epoch 623:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=7.0490e-07,               ODE=7.2074e-05,               data=5.6347e-05,               total_loss=1.2913e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.0896e-06, val_ODE: 7.1318e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.001838], b: [0.00030763]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.008051124064870746\n",
            "Epoch 624:\n",
            "IC=5.8193e-07,               ODE=7.4639e-05,               data=5.5274e-05,               total_loss=1.3049e-04\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 1.3237e-06, val_ODE: 7.7636e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018346], b: [0.00028813]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007221020234930061\n",
            "Epoch 625:\n",
            "IC=6.8797e-07,               ODE=7.4011e-05,               data=5.3059e-05,               total_loss=1.2776e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.7340e-07, val_ODE: 7.3522e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018115], b: [0.00030458]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007137519024218315\n",
            "Epoch 626:\n",
            "IC=3.7725e-07,               ODE=7.2600e-05,               data=5.3592e-05,               total_loss=1.2657e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3379e-07, val_ODE: 7.3181e-05, lr: 1.25e-03\n",
            "\n",
            "a: [-2.0018172], b: [0.00028764]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00717268763339015\n",
            "Epoch 627:\n",
            "IC=1.3975e-07,               ODE=7.0308e-05,               data=5.2524e-05,               total_loss=1.2297e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1271e-07, val_ODE: 7.0784e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018108], b: [0.000322]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.00716310963913073\n",
            "Epoch 628:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.2794e-07,               ODE=7.0061e-05,               data=5.2323e-05,               total_loss=1.2261e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.1666e-07, val_ODE: 7.1700e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018156], b: [0.00035341]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007112513603321033\n",
            "Epoch 629:\n",
            "IC=1.4382e-07,               ODE=7.0124e-05,               data=5.1535e-05,               total_loss=1.2180e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.3719e-07, val_ODE: 7.1269e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017974], b: [0.00032012]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007202791812799817\n",
            "Epoch 630:\n",
            "IC=3.1160e-07,               ODE=7.0424e-05,               data=5.2730e-05,               total_loss=1.2347e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 1.8843e-07, val_ODE: 7.0037e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018203], b: [0.00032709]\n",
            "1/1 [==============================] - 0s 58ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.007235706131674885\n",
            "Epoch 631:\n",
            "IC=2.6706e-07,               ODE=7.0507e-05,               data=5.2163e-05,               total_loss=1.2294e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8946e-07, val_ODE: 7.2775e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001839], b: [0.00031606]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0071231283645441495\n",
            "Epoch 632:\n",
            "IC=2.0545e-07,               ODE=6.9972e-05,               data=5.1910e-05,               total_loss=1.2209e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.8825e-07, val_ODE: 6.9684e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018299], b: [0.00031154]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.007243535905919661\n",
            "Epoch 633:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.1966e-07,               ODE=6.9111e-05,               data=5.1843e-05,               total_loss=1.2117e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5033e-07, val_ODE: 7.0544e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018153], b: [0.00033151]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007146238831232062\n",
            "Epoch 634:\n",
            "IC=1.5492e-07,               ODE=6.8883e-05,               data=5.1839e-05,               total_loss=1.2088e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.5987e-08, val_ODE: 7.3241e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018196], b: [0.00030133]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007185743243057256\n",
            "Epoch 635:\n",
            "IC=1.6172e-07,               ODE=7.0587e-05,               data=5.2575e-05,               total_loss=1.2332e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.2414e-07, val_ODE: 7.0213e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017996], b: [0.00034661]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007298821972134342\n",
            "Epoch 636:\n",
            "IC=2.2856e-07,               ODE=7.0664e-05,               data=5.2537e-05,               total_loss=1.2343e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0571e-08, val_ODE: 7.0270e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018132], b: [0.00035059]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007175659397950481\n",
            "Epoch 637:\n",
            "IC=2.6313e-07,               ODE=6.9744e-05,               data=5.2231e-05,               total_loss=1.2224e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.1834e-07, val_ODE: 7.1813e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001802], b: [0.00033544]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.007095447158110294\n",
            "Epoch 638:\n",
            "IC=4.7136e-07,               ODE=6.9872e-05,               data=5.1662e-05,               total_loss=1.2201e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "val_IC: 9.3228e-07, val_ODE: 7.3151e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017908], b: [0.00032578]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.0071684405909140615\n",
            "Epoch 639:\n",
            "IC=4.3849e-07,               ODE=7.0045e-05,               data=5.2232e-05,               total_loss=1.2272e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 9.6064e-08, val_ODE: 6.9946e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017972], b: [0.00036863]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.007238351867710532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 640:\n",
            "IC=2.8848e-07,               ODE=6.9972e-05,               data=5.2492e-05,               total_loss=1.2275e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.1857e-07, val_ODE: 7.1126e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018122], b: [0.00035506]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007143681862231948\n",
            "Epoch 641:\n",
            "IC=2.5094e-07,               ODE=7.0690e-05,               data=5.1983e-05,               total_loss=1.2292e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4825e-07, val_ODE: 7.2153e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018137], b: [0.00034422]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007093156940477712\n",
            "Epoch 642:\n",
            "IC=4.5936e-07,               ODE=7.0575e-05,               data=5.2253e-05,               total_loss=1.2329e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1266e-07, val_ODE: 7.2156e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018418], b: [0.00031205]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007076004315784099\n",
            "Epoch 643:\n",
            "IC=1.9592e-07,               ODE=7.0082e-05,               data=5.1985e-05,               total_loss=1.2226e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.5103e-07, val_ODE: 7.2221e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018332], b: [0.00032887]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007088411954434554\n",
            "Epoch 644:\n",
            "IC=6.3059e-07,               ODE=6.9801e-05,               data=5.2743e-05,               total_loss=1.2317e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.3220e-07, val_ODE: 7.5665e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018427], b: [0.00029954]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007124187379598009\n",
            "Epoch 645:\n",
            "IC=4.2534e-07,               ODE=7.0777e-05,               data=5.1738e-05,               total_loss=1.2294e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 4.5813e-07, val_ODE: 6.9683e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0018125], b: [0.00033925]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00723703026394134\n",
            "Epoch 646:\n",
            "IC=2.2219e-07,               ODE=7.0296e-05,               data=5.1346e-05,               total_loss=1.2187e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 6.8628e-08, val_ODE: 6.9935e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001808], b: [0.00031322]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.007233339609275283\n",
            "Epoch 647:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.6676e-07,               ODE=6.9471e-05,               data=5.1144e-05,               total_loss=1.2078e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.4351e-07, val_ODE: 7.2060e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001794], b: [0.0003133]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007105040965470986\n",
            "Epoch 648:\n",
            "IC=3.2480e-07,               ODE=6.9749e-05,               data=5.2092e-05,               total_loss=1.2217e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0763e-07, val_ODE: 7.0074e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017996], b: [0.00033417]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007245393660879429\n",
            "Epoch 649:\n",
            "IC=1.7657e-07,               ODE=7.0330e-05,               data=5.3580e-05,               total_loss=1.2409e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9054e-07, val_ODE: 7.1000e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001801], b: [0.00033165]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007074148641258415\n",
            "Epoch 650:\n",
            "IC=3.1292e-07,               ODE=7.0243e-05,               data=5.3346e-05,               total_loss=1.2390e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.9316e-08, val_ODE: 6.9768e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017772], b: [0.00037092]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0072785249492127585\n",
            "Epoch 651:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.2388e-07,               ODE=7.1213e-05,               data=5.2758e-05,               total_loss=1.2450e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.0874e-07, val_ODE: 7.0775e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017846], b: [0.00035242]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007158509887810627\n",
            "Epoch 652:\n",
            "IC=6.0030e-07,               ODE=6.9998e-05,               data=5.2014e-05,               total_loss=1.2261e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.0212e-07, val_ODE: 6.9864e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017724], b: [0.00033969]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007229169905132474\n",
            "Epoch 653:\n",
            "IC=5.0904e-07,               ODE=6.8747e-05,               data=5.1583e-05,               total_loss=1.2084e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.3796e-07, val_ODE: 7.1056e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017776], b: [0.00031491]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007047964547919552\n",
            "Epoch 654:\n",
            "IC=1.8830e-07,               ODE=6.9407e-05,               data=5.2081e-05,               total_loss=1.2168e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.7557e-07, val_ODE: 7.4110e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001773], b: [0.00034255]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007179013247392611\n",
            "Epoch 655:\n",
            "IC=2.4333e-07,               ODE=6.9201e-05,               data=5.1865e-05,               total_loss=1.2131e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6466e-07, val_ODE: 6.9166e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001764], b: [0.00030212]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007187544461336117\n",
            "Epoch 656:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.0205e-07,               ODE=6.9254e-05,               data=5.0706e-05,               total_loss=1.2016e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.1716e-07, val_ODE: 6.9371e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001755], b: [0.00029444]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007096136828226101\n",
            "Epoch 657:\n",
            "IC=9.5900e-08,               ODE=6.8240e-05,               data=5.0967e-05,               total_loss=1.1930e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.0549e-07, val_ODE: 7.1631e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001736], b: [0.00028921]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007111257097135402\n",
            "Epoch 658:\n",
            "IC=2.1911e-07,               ODE=7.0127e-05,               data=5.1214e-05,               total_loss=1.2156e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1079e-08, val_ODE: 7.0682e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017717], b: [0.00029339]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007024083166164443\n",
            "Epoch 659:\n",
            "IC=2.1685e-07,               ODE=6.9322e-05,               data=5.1775e-05,               total_loss=1.2131e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 2.8249e-08, val_ODE: 7.0977e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017512], b: [0.00028718]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.007044843136161443\n",
            "Epoch 660:\n",
            "IC=5.5767e-07,               ODE=7.0218e-05,               data=5.1671e-05,               total_loss=1.2245e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.2189e-07, val_ODE: 7.1712e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001743], b: [0.00032689]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007076172406494015\n",
            "Epoch 661:\n",
            "IC=5.6714e-07,               ODE=6.9418e-05,               data=5.0436e-05,               total_loss=1.2042e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1521e-07, val_ODE: 6.7882e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001733], b: [0.00033012]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.007313644663214763\n",
            "Epoch 662:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.1780e-07,               ODE=6.8736e-05,               data=5.1311e-05,               total_loss=1.2026e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.8820e-07, val_ODE: 6.9406e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001716], b: [0.00034247]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00720998819347619\n",
            "Epoch 663:\n",
            "IC=2.3763e-07,               ODE=6.9005e-05,               data=5.1464e-05,               total_loss=1.2071e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.5506e-07, val_ODE: 6.9860e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017452], b: [0.00034932]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007017868986210264\n",
            "Epoch 664:\n",
            "IC=4.2610e-07,               ODE=6.8746e-05,               data=5.1461e-05,               total_loss=1.2063e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3592e-06, val_ODE: 7.2636e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001768], b: [0.00033633]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007069430272122224\n",
            "Epoch 665:\n",
            "IC=3.3136e-07,               ODE=6.9393e-05,               data=5.2415e-05,               total_loss=1.2214e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.9217e-07, val_ODE: 7.1318e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017655], b: [0.00033153]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007077808294554669\n",
            "Epoch 666:\n",
            "IC=2.9356e-07,               ODE=7.0270e-05,               data=5.2016e-05,               total_loss=1.2258e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.1434e-07, val_ODE: 6.9769e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017476], b: [0.00032618]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007135583080415413\n",
            "Epoch 667:\n",
            "IC=4.5151e-07,               ODE=6.8528e-05,               data=5.0262e-05,               total_loss=1.1924e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.9476e-07, val_ODE: 6.9276e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001753], b: [0.00032149]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007210139815570386\n",
            "Epoch 668:\n",
            "IC=6.2963e-07,               ODE=6.9000e-05,               data=5.1551e-05,               total_loss=1.2118e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.3231e-07, val_ODE: 6.9348e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017471], b: [0.00034152]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006994168331040437\n",
            "Epoch 669:\n",
            "IC=6.4827e-07,               ODE=6.9477e-05,               data=5.0156e-05,               total_loss=1.2028e-04\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "val_IC: 1.1453e-06, val_ODE: 7.2821e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017848], b: [0.00029689]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.007182263940177491\n",
            "Epoch 670:\n",
            "IC=6.2135e-07,               ODE=6.9802e-05,               data=5.1265e-05,               total_loss=1.2169e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.0073e-06, val_ODE: 7.1166e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001771], b: [0.00033054]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006983532166272144\n",
            "Epoch 671:\n",
            "IC=5.1483e-07,               ODE=6.9249e-05,               data=5.0863e-05,               total_loss=1.2063e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.4906e-07, val_ODE: 6.8438e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017605], b: [0.00032535]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007096646749672076\n",
            "Epoch 672:\n",
            "IC=2.3376e-07,               ODE=6.8939e-05,               data=5.0104e-05,               total_loss=1.1928e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.1459e-07, val_ODE: 6.9057e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017495], b: [0.00035026]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007244694949989576\n",
            "Epoch 673:\n",
            "IC=1.3739e-07,               ODE=6.8213e-05,               data=5.0278e-05,               total_loss=1.1863e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1278e-07, val_ODE: 7.3469e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017736], b: [0.00034317]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007047461916293439\n",
            "Epoch 674:\n",
            "IC=3.1103e-07,               ODE=6.9710e-05,               data=5.2510e-05,               total_loss=1.2253e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.6271e-07, val_ODE: 7.5994e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017805], b: [0.00033347]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0070763267334571995\n",
            "Epoch 675:\n",
            "IC=3.1366e-07,               ODE=7.0311e-05,               data=5.3239e-05,               total_loss=1.2386e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.6269e-07, val_ODE: 7.0560e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017586], b: [0.00032362]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00702706903867323\n",
            "Epoch 676:\n",
            "IC=4.1607e-07,               ODE=6.9643e-05,               data=5.1807e-05,               total_loss=1.2187e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.6432e-07, val_ODE: 6.9000e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017502], b: [0.00031142]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007059790447568394\n",
            "Epoch 677:\n",
            "IC=5.6259e-07,               ODE=6.9495e-05,               data=4.9761e-05,               total_loss=1.1982e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.4550e-07, val_ODE: 7.1997e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017817], b: [0.00034078]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007145363694933918\n",
            "Epoch 678:\n",
            "IC=9.2405e-07,               ODE=7.0386e-05,               data=5.1714e-05,               total_loss=1.2302e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.7074e-07, val_ODE: 6.8008e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.00176], b: [0.0003661]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007343761787274732\n",
            "Epoch 679:\n",
            "IC=3.8662e-07,               ODE=7.0711e-05,               data=5.1631e-05,               total_loss=1.2273e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.4811e-07, val_ODE: 6.8435e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001748], b: [0.00033006]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007109771967977159\n",
            "Epoch 680:\n",
            "IC=2.6481e-07,               ODE=6.8754e-05,               data=5.0169e-05,               total_loss=1.1919e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 2.4018e-07, val_ODE: 6.9282e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017326], b: [0.00029645]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.00714785155161589\n",
            "Epoch 681:\n",
            "IC=1.4875e-07,               ODE=6.8089e-05,               data=4.9972e-05,               total_loss=1.1821e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.4923e-07, val_ODE: 6.8883e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001723], b: [0.00029961]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006992942614169716\n",
            "Epoch 682:\n",
            "IC=3.1101e-07,               ODE=6.7825e-05,               data=4.9807e-05,               total_loss=1.1794e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.8259e-08, val_ODE: 7.0305e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017433], b: [0.00028799]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006986525756285612\n",
            "Epoch 683:\n",
            "IC=2.9034e-07,               ODE=6.7630e-05,               data=4.9241e-05,               total_loss=1.1716e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.8685e-08, val_ODE: 6.7473e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001722], b: [0.00027375]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.007259999818722171\n",
            "Epoch 684:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.8176e-07,               ODE=6.8310e-05,               data=4.9425e-05,               total_loss=1.1802e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.4918e-07, val_ODE: 7.0151e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017354], b: [0.00026096]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006924000379905982\n",
            "Epoch 685:\n",
            "IC=3.6196e-07,               ODE=6.7359e-05,               data=4.9639e-05,               total_loss=1.1736e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3321e-07, val_ODE: 6.8892e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017357], b: [0.00028125]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006952612730343011\n",
            "Epoch 686:\n",
            "IC=2.1374e-07,               ODE=6.7487e-05,               data=5.0872e-05,               total_loss=1.1857e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.7562e-07, val_ODE: 7.1558e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001719], b: [0.00030023]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006955115710540434\n",
            "Epoch 687:\n",
            "IC=2.9544e-07,               ODE=6.8391e-05,               data=4.9821e-05,               total_loss=1.1851e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.5796e-08, val_ODE: 6.9759e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0017183], b: [0.00029915]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006926983306440611\n",
            "Epoch 688:\n",
            "IC=2.4214e-07,               ODE=6.8930e-05,               data=4.9906e-05,               total_loss=1.1908e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.9564e-07, val_ODE: 6.7505e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016878], b: [0.00031993]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007113982236381821\n",
            "Epoch 689:\n",
            "IC=2.7612e-07,               ODE=6.8419e-05,               data=4.9187e-05,               total_loss=1.1788e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 3.8267e-07, val_ODE: 6.7296e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001689], b: [0.00033015]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.007018348584479401\n",
            "Epoch 690:\n",
            "IC=1.5831e-07,               ODE=6.7209e-05,               data=5.0292e-05,               total_loss=1.1766e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 3.7452e-07, val_ODE: 7.0439e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016787], b: [0.00033368]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.007052158855645725\n",
            "Epoch 691:\n",
            "IC=3.5221e-07,               ODE=6.8192e-05,               data=4.9356e-05,               total_loss=1.1790e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5596e-07, val_ODE: 6.9465e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016708], b: [0.00032906]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0070099552579659195\n",
            "Epoch 692:\n",
            "IC=4.1481e-07,               ODE=6.7562e-05,               data=4.9368e-05,               total_loss=1.1734e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.1896e-07, val_ODE: 6.6793e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001655], b: [0.00031381]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.0071376837201649525\n",
            "Epoch 693:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.4060e-07,               ODE=6.8220e-05,               data=4.9118e-05,               total_loss=1.1758e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1375e-07, val_ODE: 6.7776e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016568], b: [0.00032306]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.006968214004248213\n",
            "Epoch 694:\n",
            "IC=1.6410e-07,               ODE=6.8005e-05,               data=5.0506e-05,               total_loss=1.1867e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.9563e-07, val_ODE: 6.9318e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016465], b: [0.00031631]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.007093630073500628\n",
            "Epoch 695:\n",
            "IC=7.6337e-07,               ODE=6.8685e-05,               data=5.2938e-05,               total_loss=1.2239e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.3125e-06, val_ODE: 7.3468e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016618], b: [0.0003382]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007252115519056914\n",
            "Epoch 696:\n",
            "IC=4.4498e-07,               ODE=6.8876e-05,               data=5.0506e-05,               total_loss=1.1983e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3858e-07, val_ODE: 6.8804e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.00165], b: [0.00029967]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "RMSE: 0.006939323527307098\n",
            "Epoch 697:\n",
            "IC=2.2698e-07,               ODE=6.7565e-05,               data=5.0223e-05,               total_loss=1.1802e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.6544e-07, val_ODE: 6.9169e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016348], b: [0.00030313]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.006974488554218052\n",
            "Epoch 698:\n",
            "IC=4.6342e-07,               ODE=6.8617e-05,               data=5.0001e-05,               total_loss=1.1908e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.7558e-07, val_ODE: 7.1957e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0016086], b: [0.00030779]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007208151910191404\n",
            "Epoch 699:\n",
            "IC=4.1209e-07,               ODE=6.9532e-05,               data=5.0608e-05,               total_loss=1.2055e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.8980e-07, val_ODE: 7.3342e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.00161], b: [0.00028535]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007051395574129724\n",
            "Epoch 700:\n",
            "IC=6.0693e-07,               ODE=6.9025e-05,               data=5.0665e-05,               total_loss=1.2030e-04\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "val_IC: 3.7700e-07, val_ODE: 7.0072e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001601], b: [0.00031348]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.007046622609408616\n",
            "Epoch 701:\n",
            "IC=2.9018e-07,               ODE=6.7722e-05,               data=4.9633e-05,               total_loss=1.1765e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.4039e-07, val_ODE: 6.6784e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015607], b: [0.00032949]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007202585252690198\n",
            "Epoch 702:\n",
            "IC=2.3200e-07,               ODE=6.8253e-05,               data=4.8742e-05,               total_loss=1.1723e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.2865e-07, val_ODE: 6.6705e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015907], b: [0.0002804]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007193951837576811\n",
            "Epoch 703:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.7562e-07,               ODE=6.8065e-05,               data=4.9769e-05,               total_loss=1.1821e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.2738e-08, val_ODE: 6.6609e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015922], b: [0.00030341]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.007032121462466981\n",
            "Epoch 704:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.3760e-07,               ODE=6.7891e-05,               data=4.9851e-05,               total_loss=1.1798e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.3197e-08, val_ODE: 6.7342e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015738], b: [0.0002861]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007125100911213839\n",
            "Epoch 705:\n",
            "IC=1.3914e-07,               ODE=6.7162e-05,               data=5.0005e-05,               total_loss=1.1731e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.4234e-07, val_ODE: 7.1962e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015557], b: [0.0002819]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.007069803451311785\n",
            "Epoch 706:\n",
            "IC=5.0100e-07,               ODE=6.7566e-05,               data=5.0247e-05,               total_loss=1.1831e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4021e-06, val_ODE: 7.3607e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015538], b: [0.00026532]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006958565786631078\n",
            "Epoch 707:\n",
            "IC=6.2411e-07,               ODE=6.9780e-05,               data=5.0146e-05,               total_loss=1.2055e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.7036e-07, val_ODE: 7.1866e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015414], b: [0.00023698]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0069432968772888855\n",
            "Epoch 708:\n",
            "IC=3.7759e-07,               ODE=6.9245e-05,               data=4.9144e-05,               total_loss=1.1877e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.1980e-07, val_ODE: 6.8528e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001536], b: [0.00025263]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006882248424525985\n",
            "Epoch 709:\n",
            "IC=5.4450e-07,               ODE=6.6652e-05,               data=5.0091e-05,               total_loss=1.1729e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2378e-07, val_ODE: 6.5049e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015554], b: [0.00025637]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.007262375849838246\n",
            "Epoch 710:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.8602e-07,               ODE=6.7967e-05,               data=4.9863e-05,               total_loss=1.1812e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.6758e-07, val_ODE: 7.4663e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015538], b: [0.00024625]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006956395763864061\n",
            "Epoch 711:\n",
            "IC=7.8283e-07,               ODE=7.0509e-05,               data=4.8524e-05,               total_loss=1.1982e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 8.7016e-07, val_ODE: 7.1173e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001555], b: [0.00030412]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.0069748749160417406\n",
            "Epoch 712:\n",
            "IC=8.9478e-07,               ODE=6.8446e-05,               data=4.9128e-05,               total_loss=1.1847e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5881e-06, val_ODE: 7.2286e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015595], b: [0.00025663]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006972405865742034\n",
            "Epoch 713:\n",
            "IC=1.4521e-06,               ODE=6.8875e-05,               data=4.9248e-05,               total_loss=1.1958e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 6.2878e-07, val_ODE: 6.8543e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001545], b: [0.00027543]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006862885721964543\n",
            "Epoch 714:\n",
            "IC=1.2729e-06,               ODE=6.8351e-05,               data=4.8324e-05,               total_loss=1.1795e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.4829e-08, val_ODE: 6.7710e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015376], b: [0.00023529]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0068894978422251564\n",
            "Epoch 715:\n",
            "IC=6.7680e-07,               ODE=6.6558e-05,               data=4.9426e-05,               total_loss=1.1666e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.1482e-07, val_ODE: 6.8485e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015457], b: [0.00022531]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0068247595318597695\n",
            "Epoch 716:\n",
            "IC=4.0324e-07,               ODE=6.6317e-05,               data=4.9973e-05,               total_loss=1.1669e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 2.1426e-07, val_ODE: 6.7067e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001553], b: [0.00025422]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006820631839237819\n",
            "Epoch 717:\n",
            "IC=1.7344e-07,               ODE=6.5988e-05,               data=4.7803e-05,               total_loss=1.1396e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.2917e-07, val_ODE: 6.5325e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001529], b: [0.00027097]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.007122838999144149\n",
            "Epoch 718:\n",
            "IC=2.6296e-07,               ODE=6.6573e-05,               data=4.9354e-05,               total_loss=1.1619e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.3975e-07, val_ODE: 6.7337e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015283], b: [0.00025806]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.006835345288040956\n",
            "Epoch 719:\n",
            "IC=2.1199e-07,               ODE=6.7724e-05,               data=4.7920e-05,               total_loss=1.1586e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.6270e-07, val_ODE: 6.7674e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015256], b: [0.00025155]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.006967268062110797\n",
            "Epoch 720:\n",
            "IC=4.9587e-07,               ODE=6.6343e-05,               data=4.8909e-05,               total_loss=1.1575e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2524e-07, val_ODE: 6.7429e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001507], b: [0.00025322]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006804876552739199\n",
            "Epoch 721:\n",
            "IC=4.6557e-07,               ODE=6.7183e-05,               data=4.9433e-05,               total_loss=1.1708e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 7.4500e-07, val_ODE: 7.0268e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015025], b: [0.00027124]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006991052174679293\n",
            "Epoch 722:\n",
            "IC=5.4752e-07,               ODE=6.7957e-05,               data=4.8132e-05,               total_loss=1.1664e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.5035e-07, val_ODE: 6.5654e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015302], b: [0.0002587]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.007220755784220242\n",
            "Epoch 723:\n",
            "IC=5.4334e-07,               ODE=6.6565e-05,               data=5.0206e-05,               total_loss=1.1731e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.7919e-08, val_ODE: 6.7488e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015068], b: [0.00026873]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006872732798513859\n",
            "Epoch 724:\n",
            "IC=6.0987e-07,               ODE=6.6625e-05,               data=4.9875e-05,               total_loss=1.1711e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.5413e-07, val_ODE: 7.2100e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015], b: [0.00028949]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0069991736017430955\n",
            "Epoch 725:\n",
            "IC=7.2795e-07,               ODE=6.8366e-05,               data=5.1404e-05,               total_loss=1.2050e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 4.1056e-07, val_ODE: 7.0279e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.001511], b: [0.00027725]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006852428923112686\n",
            "Epoch 726:\n",
            "IC=2.1926e-07,               ODE=6.6792e-05,               data=4.7369e-05,               total_loss=1.1438e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8593e-07, val_ODE: 6.7004e-05, lr: 6.25e-04\n",
            "\n",
            "a: [-2.0015152], b: [0.00026504]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.007034805124856177\n",
            "Epoch 727:\n",
            "IC=2.4357e-07,               ODE=6.5456e-05,               data=4.7958e-05,               total_loss=1.1366e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3619e-08, val_ODE: 6.6262e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0015006], b: [0.00027433]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0067512637849209585\n",
            "Epoch 728:\n",
            "IC=1.0737e-07,               ODE=6.4679e-05,               data=4.6461e-05,               total_loss=1.1125e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.2972e-08, val_ODE: 6.5499e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014927], b: [0.00028315]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006806740819448713\n",
            "Epoch 729:\n",
            "IC=4.7453e-08,               ODE=6.4282e-05,               data=4.7009e-05,               total_loss=1.1134e-04\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 6.6166e-08, val_ODE: 6.6143e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014896], b: [0.00027837]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.006769198304989647\n",
            "Epoch 730:\n",
            "IC=8.9374e-08,               ODE=6.4498e-05,               data=4.6717e-05,               total_loss=1.1130e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3979e-07, val_ODE: 6.4839e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014858], b: [0.0002826]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.006831864740813559\n",
            "Epoch 731:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.1181e-07,               ODE=6.4608e-05,               data=4.6479e-05,               total_loss=1.1120e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.8568e-07, val_ODE: 6.5030e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.00149], b: [0.00028698]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.0068876414810248995\n",
            "Epoch 732:\n",
            "IC=1.6201e-07,               ODE=6.5871e-05,               data=4.7300e-05,               total_loss=1.1333e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.3608e-07, val_ODE: 6.6774e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001499], b: [0.000274]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.006748912353572531\n",
            "Epoch 733:\n",
            "IC=1.6164e-07,               ODE=6.4255e-05,               data=4.6863e-05,               total_loss=1.1128e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 3.5832e-07, val_ODE: 6.6488e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0015059], b: [0.00026898]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006753258590422823\n",
            "Epoch 734:\n",
            "IC=1.2641e-07,               ODE=6.4607e-05,               data=4.6321e-05,               total_loss=1.1105e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 7.7286e-08, val_ODE: 6.4978e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001498], b: [0.00028128]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006808842424922417\n",
            "Epoch 735:\n",
            "IC=1.4465e-07,               ODE=6.4197e-05,               data=4.7234e-05,               total_loss=1.1158e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.6026e-08, val_ODE: 6.4356e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0015059], b: [0.00026839]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.006906004420311511\n",
            "Epoch 736:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.6948e-07,               ODE=6.4311e-05,               data=4.6695e-05,               total_loss=1.1117e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.3722e-08, val_ODE: 6.4451e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014846], b: [0.00028798]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.006797693940513195\n",
            "Epoch 737:\n",
            "IC=9.3872e-08,               ODE=6.4691e-05,               data=4.7016e-05,               total_loss=1.1180e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.5723e-07, val_ODE: 6.7398e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001493], b: [0.00031262]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006834144638634423\n",
            "Epoch 738:\n",
            "IC=1.7879e-07,               ODE=6.5778e-05,               data=4.6799e-05,               total_loss=1.1276e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.3738e-07, val_ODE: 6.6576e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.00148], b: [0.00027391]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006870065403113964\n",
            "Epoch 739:\n",
            "IC=1.6705e-07,               ODE=6.3954e-05,               data=4.7453e-05,               total_loss=1.1157e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 1.0277e-07, val_ODE: 6.6819e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001484], b: [0.00031372]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "RMSE: 0.006748612428669\n",
            "Epoch 740:\n",
            "IC=2.1693e-07,               ODE=6.5147e-05,               data=4.8281e-05,               total_loss=1.1364e-04\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 9.9239e-08, val_ODE: 6.7977e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001466], b: [0.00030669]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.00706006256241075\n",
            "Epoch 741:\n",
            "IC=2.2645e-07,               ODE=6.6228e-05,               data=4.8640e-05,               total_loss=1.1509e-04\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "val_IC: 3.3410e-07, val_ODE: 6.4855e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014923], b: [0.0002809]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "RMSE: 0.006920048103964513\n",
            "Epoch 742:\n",
            "IC=4.0279e-07,               ODE=6.5661e-05,               data=4.6681e-05,               total_loss=1.1274e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 9.5794e-08, val_ODE: 6.4559e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014868], b: [0.00026499]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006889649050368566\n",
            "Epoch 743:\n",
            "IC=2.9769e-07,               ODE=6.4513e-05,               data=4.6835e-05,               total_loss=1.1165e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9035e-08, val_ODE: 6.6917e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014935], b: [0.00027616]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006721760936137464\n",
            "Epoch 744:\n",
            "IC=8.4385e-08,               ODE=6.3914e-05,               data=4.6241e-05,               total_loss=1.1024e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5984e-08, val_ODE: 6.4501e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014868], b: [0.00026654]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006808529511051291\n",
            "Epoch 745:\n",
            "IC=9.9159e-08,               ODE=6.3648e-05,               data=4.6324e-05,               total_loss=1.1007e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.7335e-07, val_ODE: 6.7992e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014894], b: [0.00028459]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006880743183459544\n",
            "Epoch 746:\n",
            "IC=1.1275e-07,               ODE=6.3768e-05,               data=4.7246e-05,               total_loss=1.1113e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.3093e-08, val_ODE: 6.4567e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014906], b: [0.00024569]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00674932579541477\n",
            "Epoch 747:\n",
            "IC=8.9607e-08,               ODE=6.3340e-05,               data=4.5945e-05,               total_loss=1.0937e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.1328e-09, val_ODE: 6.5703e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014803], b: [0.0002308]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006717141386821166\n",
            "Epoch 748:\n",
            "IC=7.6639e-08,               ODE=6.3868e-05,               data=4.6095e-05,               total_loss=1.1004e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.8571e-07, val_ODE: 6.6029e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014706], b: [0.0002297]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006723633794677827\n",
            "Epoch 749:\n",
            "IC=2.1277e-07,               ODE=6.4057e-05,               data=4.6389e-05,               total_loss=1.1066e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.9091e-07, val_ODE: 6.5863e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001469], b: [0.00022277]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006747207962798282\n",
            "Epoch 750:\n",
            "IC=1.6969e-07,               ODE=6.4237e-05,               data=4.6268e-05,               total_loss=1.1067e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.1899e-07, val_ODE: 6.5162e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014448], b: [0.0002198]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0067993394367937545\n",
            "Epoch 751:\n",
            "IC=1.0681e-07,               ODE=6.3660e-05,               data=4.6190e-05,               total_loss=1.0996e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 9.1790e-08, val_ODE: 6.5807e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001464], b: [0.00023697]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0068506546174058325\n",
            "Epoch 752:\n",
            "IC=9.3415e-08,               ODE=6.3621e-05,               data=4.6546e-05,               total_loss=1.1026e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.1724e-07, val_ODE: 6.4114e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014594], b: [0.00023452]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.0068009506110652315\n",
            "Epoch 753:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.7262e-07,               ODE=6.4057e-05,               data=4.6747e-05,               total_loss=1.1098e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 5.1958e-07, val_ODE: 6.6816e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014465], b: [0.00024085]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.0068031634099816555\n",
            "Epoch 754:\n",
            "IC=3.8328e-07,               ODE=6.3926e-05,               data=4.7181e-05,               total_loss=1.1149e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.0911e-07, val_ODE: 6.4944e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001448], b: [0.00023644]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006746164178357918\n",
            "Epoch 755:\n",
            "IC=1.5624e-07,               ODE=6.3669e-05,               data=4.6279e-05,               total_loss=1.1010e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 1.4957e-08, val_ODE: 6.6920e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014575], b: [0.0002548]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.006829197396351679\n",
            "Epoch 756:\n",
            "IC=1.3930e-07,               ODE=6.4438e-05,               data=4.7043e-05,               total_loss=1.1162e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4872e-07, val_ODE: 6.5118e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014565], b: [0.00026731]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006746935917646313\n",
            "Epoch 757:\n",
            "IC=1.3710e-07,               ODE=6.3951e-05,               data=4.6052e-05,               total_loss=1.1014e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.2462e-08, val_ODE: 6.4357e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014575], b: [0.00026203]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.00676449638129421\n",
            "Epoch 758:\n",
            "IC=2.1762e-07,               ODE=6.4202e-05,               data=4.6886e-05,               total_loss=1.1131e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.6808e-07, val_ODE: 6.5073e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001454], b: [0.00025359]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006702037502622543\n",
            "Epoch 759:\n",
            "IC=2.1066e-07,               ODE=6.4207e-05,               data=4.6107e-05,               total_loss=1.1052e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.5674e-08, val_ODE: 6.6005e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014405], b: [0.00023933]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006891417077979136\n",
            "Epoch 760:\n",
            "IC=1.3071e-07,               ODE=6.4195e-05,               data=4.7891e-05,               total_loss=1.1222e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.7385e-08, val_ODE: 6.6023e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014389], b: [0.00027553]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006810658656371759\n",
            "Epoch 761:\n",
            "IC=1.1061e-07,               ODE=6.4482e-05,               data=4.6676e-05,               total_loss=1.1127e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0798e-07, val_ODE: 6.5737e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014477], b: [0.00028396]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006748312659629664\n",
            "Epoch 762:\n",
            "IC=2.5675e-07,               ODE=6.4267e-05,               data=4.6505e-05,               total_loss=1.1103e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.0205e-07, val_ODE: 6.4327e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014532], b: [0.0002667]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006865162507511392\n",
            "Epoch 763:\n",
            "IC=1.5070e-07,               ODE=6.2921e-05,               data=4.7124e-05,               total_loss=1.1020e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.3635e-07, val_ODE: 6.5326e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001455], b: [0.00027389]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006672294874067924\n",
            "Epoch 764:\n",
            "IC=7.2615e-08,               ODE=6.3386e-05,               data=4.6316e-05,               total_loss=1.0977e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0594e-07, val_ODE: 6.4895e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014455], b: [0.0002618]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006697922598850403\n",
            "Epoch 765:\n",
            "IC=1.0644e-07,               ODE=6.3442e-05,               data=4.5803e-05,               total_loss=1.0935e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 5.9960e-08, val_ODE: 6.3772e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014458], b: [0.00026634]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.006779934478816018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 766:\n",
            "IC=1.4048e-07,               ODE=6.3287e-05,               data=4.5701e-05,               total_loss=1.0913e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.2696e-08, val_ODE: 6.4023e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014408], b: [0.00025581]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006712152186876623\n",
            "Epoch 767:\n",
            "IC=3.5326e-07,               ODE=6.3988e-05,               data=4.6065e-05,               total_loss=1.1041e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.1074e-07, val_ODE: 6.7435e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014262], b: [0.00023329]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006771884632262378\n",
            "Epoch 768:\n",
            "IC=3.0099e-07,               ODE=6.4407e-05,               data=4.6629e-05,               total_loss=1.1134e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 5.2883e-08, val_ODE: 6.4458e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014274], b: [0.00026216]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.0067132376668178236\n",
            "Epoch 769:\n",
            "IC=7.7464e-08,               ODE=6.3066e-05,               data=4.5741e-05,               total_loss=1.0888e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.3539e-07, val_ODE: 6.6111e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001443], b: [0.00027101]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006704612865265461\n",
            "Epoch 770:\n",
            "IC=2.1085e-07,               ODE=6.3523e-05,               data=4.6101e-05,               total_loss=1.0984e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.8376e-07, val_ODE: 6.6124e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001444], b: [0.00023443]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006702995364221381\n",
            "Epoch 771:\n",
            "IC=2.4976e-07,               ODE=6.3367e-05,               data=4.5928e-05,               total_loss=1.0955e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 3.6875e-07, val_ODE: 6.6210e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014524], b: [0.00023637]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0066969385924390695\n",
            "Epoch 772:\n",
            "IC=2.4269e-07,               ODE=6.4122e-05,               data=4.6363e-05,               total_loss=1.1073e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7904e-07, val_ODE: 6.5410e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001445], b: [0.0002501]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006738958139189654\n",
            "Epoch 773:\n",
            "IC=2.7446e-07,               ODE=6.3466e-05,               data=4.5321e-05,               total_loss=1.0906e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7683e-07, val_ODE: 6.3830e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014417], b: [0.00023985]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006661691688337055\n",
            "Epoch 774:\n",
            "IC=1.7327e-07,               ODE=6.2870e-05,               data=4.5295e-05,               total_loss=1.0834e-04\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 5.5795e-08, val_ODE: 6.5355e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014243], b: [0.0002488]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.006651106108802347\n",
            "Epoch 775:\n",
            "IC=1.0230e-07,               ODE=6.3344e-05,               data=4.5223e-05,               total_loss=1.0867e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.1327e-08, val_ODE: 6.3556e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014293], b: [0.00025095]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.0067141876144923875\n",
            "Epoch 776:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.0907e-07,               ODE=6.3051e-05,               data=4.5110e-05,               total_loss=1.0827e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.3433e-07, val_ODE: 6.5046e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014088], b: [0.00024823]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0066630966384016626\n",
            "Epoch 777:\n",
            "IC=3.0188e-07,               ODE=6.4365e-05,               data=4.6064e-05,               total_loss=1.1073e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.2383e-07, val_ODE: 6.3090e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014184], b: [0.00022468]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.006894920623748759\n",
            "Epoch 778:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=3.0314e-07,               ODE=6.3086e-05,               data=4.5894e-05,               total_loss=1.0928e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.0968e-08, val_ODE: 6.4064e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014205], b: [0.00022741]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006701685459547596\n",
            "Epoch 779:\n",
            "IC=9.5659e-08,               ODE=6.3077e-05,               data=4.4990e-05,               total_loss=1.0816e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.3562e-08, val_ODE: 6.3572e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014024], b: [0.00024628]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0066643895962815395\n",
            "Epoch 780:\n",
            "IC=1.1977e-07,               ODE=6.3118e-05,               data=4.5351e-05,               total_loss=1.0859e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 3.5129e-07, val_ODE: 6.6224e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014148], b: [0.00025632]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006761581112820409\n",
            "Epoch 781:\n",
            "IC=3.8945e-07,               ODE=6.3684e-05,               data=4.5786e-05,               total_loss=1.0986e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 6.3815e-07, val_ODE: 6.3517e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014093], b: [0.00022981]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0067136948341185694\n",
            "Epoch 782:\n",
            "IC=2.5715e-07,               ODE=6.3089e-05,               data=4.5757e-05,               total_loss=1.0910e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.6305e-08, val_ODE: 6.5251e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001404], b: [0.00025194]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006758464734447157\n",
            "Epoch 783:\n",
            "IC=1.0758e-07,               ODE=6.3283e-05,               data=4.5437e-05,               total_loss=1.0883e-04\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "val_IC: 3.2628e-08, val_ODE: 6.4440e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013955], b: [0.0002815]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "RMSE: 0.006639830492706991\n",
            "Epoch 784:\n",
            "IC=5.8218e-08,               ODE=6.2851e-05,               data=4.4672e-05,               total_loss=1.0758e-04\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "val_IC: 6.7644e-09, val_ODE: 6.4215e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013835], b: [0.00026203]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "RMSE: 0.00665162750019552\n",
            "Epoch 785:\n",
            "IC=9.4506e-08,               ODE=6.2751e-05,               data=4.4798e-05,               total_loss=1.0764e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.4467e-07, val_ODE: 6.4184e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014017], b: [0.00024574]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006672143695034586\n",
            "Epoch 786:\n",
            "IC=7.0545e-08,               ODE=6.2404e-05,               data=4.4969e-05,               total_loss=1.0744e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.6584e-08, val_ODE: 6.3510e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013814], b: [0.0002545]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006631978237472779\n",
            "Epoch 787:\n",
            "IC=1.7608e-07,               ODE=6.2368e-05,               data=4.4748e-05,               total_loss=1.0729e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.7498e-07, val_ODE: 6.4076e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.00138], b: [0.00024763]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006649069450989696\n",
            "Epoch 788:\n",
            "IC=1.7633e-07,               ODE=6.2548e-05,               data=4.5044e-05,               total_loss=1.0777e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.9627e-07, val_ODE: 6.3274e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013845], b: [0.00022264]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0068058347156653345\n",
            "Epoch 789:\n",
            "IC=5.5428e-07,               ODE=6.4573e-05,               data=4.6933e-05,               total_loss=1.1206e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 8.4829e-07, val_ODE: 7.0260e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0014052], b: [0.00026038]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006863280675578226\n",
            "Epoch 790:\n",
            "IC=4.2114e-07,               ODE=6.5033e-05,               data=4.5676e-05,               total_loss=1.1113e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.6011e-07, val_ODE: 6.3995e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013745], b: [0.00023307]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0067304516831218535\n",
            "Epoch 791:\n",
            "IC=2.6585e-07,               ODE=6.3582e-05,               data=4.5620e-05,               total_loss=1.0947e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.2528e-08, val_ODE: 6.4510e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013778], b: [0.0002268]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006718026349428129\n",
            "Epoch 792:\n",
            "IC=1.2007e-07,               ODE=6.2715e-05,               data=4.5840e-05,               total_loss=1.0868e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.7218e-08, val_ODE: 6.2578e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001362], b: [0.00023152]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006821835239200865\n",
            "Epoch 793:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.7834e-07,               ODE=6.2540e-05,               data=4.4979e-05,               total_loss=1.0770e-04\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 7.5170e-07, val_ODE: 6.8681e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013459], b: [0.00021741]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "RMSE: 0.006680092186438304\n",
            "Epoch 794:\n",
            "IC=3.9159e-07,               ODE=6.4454e-05,               data=4.5255e-05,               total_loss=1.1010e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.0444e-07, val_ODE: 6.5622e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013478], b: [0.00020443]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006737267228475094\n",
            "Epoch 795:\n",
            "IC=2.3320e-07,               ODE=6.3886e-05,               data=4.5081e-05,               total_loss=1.0920e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.7292e-08, val_ODE: 6.4903e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013404], b: [0.00023987]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00661779626101641\n",
            "Epoch 796:\n",
            "IC=1.0835e-07,               ODE=6.2817e-05,               data=4.5385e-05,               total_loss=1.0831e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.6912e-08, val_ODE: 6.2778e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013242], b: [0.00023945]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006761290304536127\n",
            "Epoch 797:\n",
            "IC=2.2432e-07,               ODE=6.2782e-05,               data=4.5818e-05,               total_loss=1.0882e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.4655e-07, val_ODE: 6.6710e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.00134], b: [0.00025405]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006668609931189927\n",
            "Epoch 798:\n",
            "IC=4.8824e-07,               ODE=6.3901e-05,               data=4.6049e-05,               total_loss=1.1044e-04\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 9.5644e-08, val_ODE: 6.3383e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001348], b: [0.00022505]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.00702825221289334\n",
            "Epoch 799:\n",
            "IC=1.4255e-07,               ODE=6.2712e-05,               data=4.7005e-05,               total_loss=1.0986e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.6589e-07, val_ODE: 6.5527e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001334], b: [0.00024053]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006596310415871733\n",
            "Epoch 800:\n",
            "IC=1.9855e-07,               ODE=6.3568e-05,               data=4.5470e-05,               total_loss=1.0924e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2822e-07, val_ODE: 6.3374e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013418], b: [0.0002323]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006630460665299837\n",
            "Epoch 801:\n",
            "IC=1.3973e-07,               ODE=6.2393e-05,               data=4.5469e-05,               total_loss=1.0800e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.9025e-08, val_ODE: 6.3073e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.00131], b: [0.00024388]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.00661448352942316\n",
            "Epoch 802:\n",
            "IC=9.8745e-08,               ODE=6.2064e-05,               data=4.4476e-05,               total_loss=1.0664e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1762e-07, val_ODE: 6.4495e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013144], b: [0.00023844]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006580643776027924\n",
            "Epoch 803:\n",
            "IC=1.4801e-07,               ODE=6.2477e-05,               data=4.4320e-05,               total_loss=1.0695e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4955e-07, val_ODE: 6.2664e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013149], b: [0.00023819]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "RMSE: 0.006605200315762327\n",
            "Epoch 804:\n",
            "IC=1.0692e-07,               ODE=6.1728e-05,               data=4.4199e-05,               total_loss=1.0603e-04\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 3.3465e-08, val_ODE: 6.2767e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001296], b: [0.00023922]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.006587249224305638\n",
            "Epoch 805:\n",
            "IC=2.1189e-07,               ODE=6.2540e-05,               data=4.4267e-05,               total_loss=1.0702e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.1105e-08, val_ODE: 6.3634e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001306], b: [0.00019492]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006716883565471078\n",
            "Epoch 806:\n",
            "IC=2.3468e-07,               ODE=6.2076e-05,               data=4.4764e-05,               total_loss=1.0708e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4310e-08, val_ODE: 6.2770e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001311], b: [0.00022512]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006712700612723006\n",
            "Epoch 807:\n",
            "IC=1.2889e-07,               ODE=6.2585e-05,               data=4.4943e-05,               total_loss=1.0766e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.2982e-07, val_ODE: 6.2961e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013044], b: [0.00023168]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006711667341373889\n",
            "Epoch 808:\n",
            "IC=1.5600e-07,               ODE=6.1465e-05,               data=4.5478e-05,               total_loss=1.0710e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.6092e-08, val_ODE: 6.3615e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013034], b: [0.00024709]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006574015259109604\n",
            "Epoch 809:\n",
            "IC=2.6748e-07,               ODE=6.2892e-05,               data=4.4965e-05,               total_loss=1.0812e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.4802e-07, val_ODE: 6.5382e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0013142], b: [0.00023116]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006624863981517608\n",
            "Epoch 810:\n",
            "IC=2.5386e-07,               ODE=6.3974e-05,               data=4.5179e-05,               total_loss=1.0941e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.3541e-07, val_ODE: 6.2715e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001302], b: [0.00021727]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00672399270774712\n",
            "Epoch 811:\n",
            "IC=1.2991e-07,               ODE=6.2290e-05,               data=4.4340e-05,               total_loss=1.0676e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.0661e-08, val_ODE: 6.2834e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001298], b: [0.00022657]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0066042354225263455\n",
            "Epoch 812:\n",
            "IC=6.3332e-08,               ODE=6.1756e-05,               data=4.4353e-05,               total_loss=1.0617e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5471e-08, val_ODE: 6.3456e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001279], b: [0.00022225]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006629747879622306\n",
            "Epoch 813:\n",
            "IC=1.9437e-07,               ODE=6.2150e-05,               data=4.4627e-05,               total_loss=1.0697e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.9417e-07, val_ODE: 6.5751e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012798], b: [0.00016957]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "RMSE: 0.00659999543636123\n",
            "Epoch 814:\n",
            "IC=2.9457e-07,               ODE=6.1883e-05,               data=4.4718e-05,               total_loss=1.0690e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5362e-07, val_ODE: 6.4529e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012906], b: [0.00018612]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006641545933204241\n",
            "Epoch 815:\n",
            "IC=1.8584e-07,               ODE=6.3459e-05,               data=4.4450e-05,               total_loss=1.0809e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1872e-07, val_ODE: 6.2296e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012708], b: [0.00021148]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "RMSE: 0.006785007216179665\n",
            "Epoch 816:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.2173e-07,               ODE=6.2796e-05,               data=4.5007e-05,               total_loss=1.0802e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7522e-07, val_ODE: 6.4361e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012772], b: [0.00023353]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.0065772706964123745\n",
            "Epoch 817:\n",
            "IC=2.2199e-07,               ODE=6.2432e-05,               data=4.4111e-05,               total_loss=1.0676e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0118e-07, val_ODE: 6.2391e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012596], b: [0.00022811]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006582682299642886\n",
            "Epoch 818:\n",
            "IC=2.8420e-07,               ODE=6.2023e-05,               data=4.3654e-05,               total_loss=1.0596e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.3588e-07, val_ODE: 6.3221e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012522], b: [0.00023535]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006571392992555301\n",
            "Epoch 819:\n",
            "IC=2.9829e-07,               ODE=6.1479e-05,               data=4.3611e-05,               total_loss=1.0539e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0649e-07, val_ODE: 6.3648e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012405], b: [0.0002183]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006526770451875992\n",
            "Epoch 820:\n",
            "IC=1.8390e-07,               ODE=6.1826e-05,               data=4.4330e-05,               total_loss=1.0634e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.6795e-08, val_ODE: 6.3867e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001249], b: [0.00020883]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006559999655621053\n",
            "Epoch 821:\n",
            "IC=1.2334e-07,               ODE=6.1988e-05,               data=4.3769e-05,               total_loss=1.0588e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4207e-07, val_ODE: 6.3256e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012383], b: [0.00016938]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.006568925630410278\n",
            "Epoch 822:\n",
            "IC=9.4518e-08,               ODE=6.1892e-05,               data=4.4867e-05,               total_loss=1.0685e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.3268e-08, val_ODE: 6.5400e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001248], b: [0.00019984]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006614251147473303\n",
            "Epoch 823:\n",
            "IC=3.3130e-07,               ODE=6.2613e-05,               data=4.4101e-05,               total_loss=1.0705e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 3.8225e-07, val_ODE: 6.5430e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012078], b: [0.00018761]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "RMSE: 0.006655952099486139\n",
            "Epoch 824:\n",
            "IC=2.9378e-07,               ODE=6.2455e-05,               data=4.3631e-05,               total_loss=1.0638e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7085e-07, val_ODE: 6.2150e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012484], b: [0.00018682]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006664910550128246\n",
            "Epoch 825:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.8041e-07,               ODE=6.1385e-05,               data=4.4202e-05,               total_loss=1.0587e-04\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 5.6041e-08, val_ODE: 6.2378e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.001231], b: [0.0001795]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006535952714599245\n",
            "Epoch 826:\n",
            "IC=3.3311e-07,               ODE=6.1876e-05,               data=4.4482e-05,               total_loss=1.0669e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.0607e-07, val_ODE: 6.2781e-05, lr: 3.12e-04\n",
            "\n",
            "a: [-2.0012214], b: [0.00019092]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006519099436559907\n",
            "Epoch 827:\n",
            "IC=1.8406e-07,               ODE=6.1071e-05,               data=4.3040e-05,               total_loss=1.0430e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.3530e-08, val_ODE: 6.1450e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012238], b: [0.0002149]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006562365780017072\n",
            "Epoch 828:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.1869e-07,               ODE=6.1056e-05,               data=4.3238e-05,               total_loss=1.0451e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.2269e-07, val_ODE: 6.1905e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012307], b: [0.00019806]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006533344159713496\n",
            "Epoch 829:\n",
            "IC=1.2591e-07,               ODE=6.0621e-05,               data=4.3954e-05,               total_loss=1.0470e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.2720e-08, val_ODE: 6.3340e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012264], b: [0.00020335]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006497870849011792\n",
            "Epoch 830:\n",
            "IC=1.3944e-07,               ODE=6.1560e-05,               data=4.3433e-05,               total_loss=1.0513e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.3348e-08, val_ODE: 6.2444e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012295], b: [0.00021077]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006542054158056005\n",
            "Epoch 831:\n",
            "IC=1.1779e-07,               ODE=6.0960e-05,               data=4.3195e-05,               total_loss=1.0427e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.2037e-07, val_ODE: 6.2224e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012279], b: [0.00020297]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064892702294995054\n",
            "Epoch 832:\n",
            "IC=1.0684e-07,               ODE=6.0164e-05,               data=4.4777e-05,               total_loss=1.0505e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.9954e-07, val_ODE: 6.4437e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012345], b: [0.0001903]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006633651399898545\n",
            "Epoch 833:\n",
            "IC=8.3226e-08,               ODE=6.1157e-05,               data=4.3875e-05,               total_loss=1.0511e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.9000e-08, val_ODE: 6.2027e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012388], b: [0.00019239]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006531204751648903\n",
            "Epoch 834:\n",
            "IC=1.3826e-07,               ODE=6.0507e-05,               data=4.3159e-05,               total_loss=1.0380e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 1.4231e-07, val_ODE: 6.2399e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012336], b: [0.00020271]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.006483747802256253\n",
            "Epoch 835:\n",
            "IC=5.1391e-08,               ODE=6.0392e-05,               data=4.2944e-05,               total_loss=1.0339e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.5996e-07, val_ODE: 6.2432e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012178], b: [0.00020865]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00648740432563032\n",
            "Epoch 836:\n",
            "IC=1.6985e-07,               ODE=6.0660e-05,               data=4.3259e-05,               total_loss=1.0409e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.4670e-07, val_ODE: 6.1669e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012093], b: [0.00021236]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00654184002657007\n",
            "Epoch 837:\n",
            "IC=2.0290e-07,               ODE=6.0857e-05,               data=4.2785e-05,               total_loss=1.0384e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.3132e-07, val_ODE: 6.1797e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012197], b: [0.00019179]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006501382233138819\n",
            "Epoch 838:\n",
            "IC=8.8354e-08,               ODE=6.0398e-05,               data=4.2940e-05,               total_loss=1.0343e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.5511e-08, val_ODE: 6.1771e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011966], b: [0.00020519]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006489073112399004\n",
            "Epoch 839:\n",
            "IC=9.3133e-08,               ODE=6.0348e-05,               data=4.3099e-05,               total_loss=1.0354e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.1757e-09, val_ODE: 6.1920e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012212], b: [0.0002021]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006477834415660589\n",
            "Epoch 840:\n",
            "IC=7.5487e-08,               ODE=6.0409e-05,               data=4.3547e-05,               total_loss=1.0403e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.0323e-07, val_ODE: 6.0988e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001222], b: [0.00017922]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "RMSE: 0.006560502302020709\n",
            "Epoch 841:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.0718e-08,               ODE=6.0116e-05,               data=4.3142e-05,               total_loss=1.0334e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.6756e-08, val_ODE: 6.2259e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001198], b: [0.000196]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006502830441706414\n",
            "Epoch 842:\n",
            "IC=9.9519e-08,               ODE=6.0370e-05,               data=4.2782e-05,               total_loss=1.0325e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0004e-07, val_ODE: 6.2186e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011964], b: [0.00020405]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006492356137629545\n",
            "Epoch 843:\n",
            "IC=1.0438e-07,               ODE=6.1481e-05,               data=4.2774e-05,               total_loss=1.0436e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1541e-07, val_ODE: 6.1895e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012054], b: [0.00019122]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006564801471488572\n",
            "Epoch 844:\n",
            "IC=7.7080e-08,               ODE=6.0916e-05,               data=4.3190e-05,               total_loss=1.0418e-04\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "val_IC: 1.2955e-07, val_ODE: 6.3314e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012], b: [0.00017856]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.006512745573704601\n",
            "Epoch 845:\n",
            "IC=6.6323e-08,               ODE=6.0597e-05,               data=4.2730e-05,               total_loss=1.0339e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.3351e-08, val_ODE: 6.1261e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001202], b: [0.00018057]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006496811682219866\n",
            "Epoch 846:\n",
            "IC=3.0613e-08,               ODE=6.0168e-05,               data=4.3115e-05,               total_loss=1.0331e-04\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.8642e-08, val_ODE: 6.2011e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011985], b: [0.00020246]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006461128651778779\n",
            "Epoch 847:\n",
            "IC=6.7232e-08,               ODE=6.0338e-05,               data=4.2633e-05,               total_loss=1.0304e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3763e-07, val_ODE: 6.1665e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011995], b: [0.00020634]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006481345327442212\n",
            "Epoch 848:\n",
            "IC=1.5167e-07,               ODE=6.0129e-05,               data=4.3150e-05,               total_loss=1.0343e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.7592e-08, val_ODE: 6.1533e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011988], b: [0.00019526]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006568757320763898\n",
            "Epoch 849:\n",
            "IC=1.5178e-07,               ODE=6.0401e-05,               data=4.2764e-05,               total_loss=1.0332e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.5766e-08, val_ODE: 6.1455e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012043], b: [0.00021861]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.0065605571720660245\n",
            "Epoch 850:\n",
            "IC=7.1549e-08,               ODE=6.0127e-05,               data=4.3066e-05,               total_loss=1.0326e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 8.6802e-08, val_ODE: 6.1788e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001208], b: [0.0002036]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.0064939384314761876\n",
            "Epoch 851:\n",
            "IC=1.1479e-07,               ODE=6.0763e-05,               data=4.2199e-05,               total_loss=1.0308e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.1510e-08, val_ODE: 6.1445e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012078], b: [0.00021348]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006538406795401621\n",
            "Epoch 852:\n",
            "IC=1.1214e-07,               ODE=5.9763e-05,               data=4.3347e-05,               total_loss=1.0322e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 7.5615e-08, val_ODE: 6.1979e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012052], b: [0.00021253]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006471030313853536\n",
            "Epoch 853:\n",
            "IC=9.9968e-08,               ODE=6.0391e-05,               data=4.3487e-05,               total_loss=1.0398e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0042e-07, val_ODE: 6.3003e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.00121], b: [0.00021501]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0066895208870608475\n",
            "Epoch 854:\n",
            "IC=8.3757e-08,               ODE=6.0775e-05,               data=4.4234e-05,               total_loss=1.0509e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 1.3930e-07, val_ODE: 6.1866e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001195], b: [0.00021146]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.0064866435824235714\n",
            "Epoch 855:\n",
            "IC=1.0862e-07,               ODE=6.0304e-05,               data=4.2654e-05,               total_loss=1.0307e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9211e-07, val_ODE: 6.1665e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001203], b: [0.000208]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006456383494624225\n",
            "Epoch 856:\n",
            "IC=8.2616e-08,               ODE=6.0322e-05,               data=4.2730e-05,               total_loss=1.0313e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9877e-08, val_ODE: 6.2015e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012004], b: [0.00023354]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.00646655001109977\n",
            "Epoch 857:\n",
            "IC=1.4181e-07,               ODE=6.0443e-05,               data=4.2913e-05,               total_loss=1.0350e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.5109e-07, val_ODE: 6.1393e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012062], b: [0.0002122]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006532646729917606\n",
            "Epoch 858:\n",
            "IC=4.2468e-07,               ODE=6.0381e-05,               data=4.3895e-05,               total_loss=1.0470e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 6.8228e-08, val_ODE: 6.2652e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001208], b: [0.0001963]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00649788744294596\n",
            "Epoch 859:\n",
            "IC=3.8311e-07,               ODE=6.1341e-05,               data=4.3337e-05,               total_loss=1.0506e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5879e-07, val_ODE: 6.1414e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0012085], b: [0.00020006]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.00653823427569459\n",
            "Epoch 860:\n",
            "IC=1.6389e-07,               ODE=6.0220e-05,               data=4.2641e-05,               total_loss=1.0302e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 5.1339e-08, val_ODE: 6.1799e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001197], b: [0.00019979]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006446921604269433\n",
            "Epoch 861:\n",
            "IC=8.4804e-08,               ODE=6.0264e-05,               data=4.2417e-05,               total_loss=1.0277e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.0502e-08, val_ODE: 6.0799e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011835], b: [0.00022455]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006480646281358683\n",
            "Epoch 862:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=8.1993e-08,               ODE=6.0671e-05,               data=4.2691e-05,               total_loss=1.0344e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.2609e-07, val_ODE: 6.1151e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011866], b: [0.00022354]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006556916435658923\n",
            "Epoch 863:\n",
            "IC=1.7038e-07,               ODE=6.0343e-05,               data=4.3508e-05,               total_loss=1.0402e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.7786e-08, val_ODE: 6.2405e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011797], b: [0.000217]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064548273519058315\n",
            "Epoch 864:\n",
            "IC=3.1191e-07,               ODE=6.1088e-05,               data=4.3087e-05,               total_loss=1.0449e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 1.0029e-06, val_ODE: 6.2950e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011928], b: [0.00021729]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "RMSE: 0.006501561216329887\n",
            "Epoch 865:\n",
            "IC=4.5098e-07,               ODE=6.0779e-05,               data=4.2793e-05,               total_loss=1.0402e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 2.8197e-07, val_ODE: 6.1441e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011806], b: [0.00020494]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0064452344079159165\n",
            "Epoch 866:\n",
            "IC=1.0823e-07,               ODE=6.0009e-05,               data=4.2548e-05,               total_loss=1.0266e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6647e-07, val_ODE: 6.0855e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011854], b: [0.00022164]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.006476793008364132\n",
            "Epoch 867:\n",
            "IC=6.9049e-08,               ODE=6.0316e-05,               data=4.2602e-05,               total_loss=1.0299e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.6303e-07, val_ODE: 6.0096e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011737], b: [0.00020851]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "RMSE: 0.006587434643743125\n",
            "Epoch 868:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.4943e-07,               ODE=5.9338e-05,               data=4.3716e-05,               total_loss=1.0320e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.0885e-09, val_ODE: 6.1370e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001184], b: [0.00020553]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064569708840450605\n",
            "Epoch 869:\n",
            "IC=2.3331e-07,               ODE=6.0956e-05,               data=4.3283e-05,               total_loss=1.0447e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.0547e-07, val_ODE: 6.3216e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001186], b: [0.00020506]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006505750696459763\n",
            "Epoch 870:\n",
            "IC=2.3225e-07,               ODE=6.0745e-05,               data=4.2495e-05,               total_loss=1.0347e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.1396e-07, val_ODE: 6.2302e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011723], b: [0.00019534]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006463072937010302\n",
            "Epoch 871:\n",
            "IC=3.7012e-07,               ODE=6.0553e-05,               data=4.2967e-05,               total_loss=1.0389e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 8.2934e-08, val_ODE: 6.1143e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011778], b: [0.00020264]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "RMSE: 0.006460323705992604\n",
            "Epoch 872:\n",
            "IC=8.6288e-08,               ODE=5.9917e-05,               data=4.1950e-05,               total_loss=1.0195e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.3720e-09, val_ODE: 6.1073e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011697], b: [0.00020365]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064400850698047895\n",
            "Epoch 873:\n",
            "IC=3.7498e-08,               ODE=5.9341e-05,               data=4.2174e-05,               total_loss=1.0155e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.7811e-09, val_ODE: 6.1028e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011704], b: [0.00019121]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006422978189052798\n",
            "Epoch 874:\n",
            "IC=5.9408e-08,               ODE=5.9645e-05,               data=4.1861e-05,               total_loss=1.0157e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 6.0341e-08, val_ODE: 6.0307e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011756], b: [0.0001887]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.006443991358048093\n",
            "Epoch 875:\n",
            "IC=1.1533e-07,               ODE=5.9607e-05,               data=4.2285e-05,               total_loss=1.0201e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.3041e-08, val_ODE: 6.0137e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011592], b: [0.00019326]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.006556067840592715\n",
            "Epoch 876:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.4935e-08,               ODE=5.9705e-05,               data=4.2665e-05,               total_loss=1.0244e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1531e-07, val_ODE: 6.0563e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001171], b: [0.00019426]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006452363891402205\n",
            "Epoch 877:\n",
            "IC=1.0584e-07,               ODE=5.9612e-05,               data=4.2198e-05,               total_loss=1.0192e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.4338e-07, val_ODE: 6.1157e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011413], b: [0.00019989]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064531772991798415\n",
            "Epoch 878:\n",
            "IC=2.1565e-07,               ODE=6.0012e-05,               data=4.2000e-05,               total_loss=1.0223e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 2.9688e-08, val_ODE: 6.0588e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011542], b: [0.00020989]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006481176249110541\n",
            "Epoch 879:\n",
            "IC=8.1657e-08,               ODE=5.9542e-05,               data=4.2629e-05,               total_loss=1.0225e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.6764e-08, val_ODE: 6.1145e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011687], b: [0.00018614]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00644702176475562\n",
            "Epoch 880:\n",
            "IC=6.3476e-08,               ODE=5.9593e-05,               data=4.2219e-05,               total_loss=1.0188e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.7840e-08, val_ODE: 6.1514e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011554], b: [0.00018093]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006450333082188401\n",
            "Epoch 881:\n",
            "IC=9.0986e-08,               ODE=5.9265e-05,               data=4.2563e-05,               total_loss=1.0192e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.6894e-08, val_ODE: 6.1410e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011575], b: [0.00016779]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00642738840974999\n",
            "Epoch 882:\n",
            "IC=9.7349e-08,               ODE=5.9540e-05,               data=4.1953e-05,               total_loss=1.0159e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.5629e-08, val_ODE: 6.0147e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011466], b: [0.00018332]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.006518229898279234\n",
            "Epoch 883:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.1696e-08,               ODE=5.9116e-05,               data=4.2304e-05,               total_loss=1.0146e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.1633e-08, val_ODE: 6.0824e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011463], b: [0.00019879]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006415042515311354\n",
            "Epoch 884:\n",
            "IC=9.9386e-08,               ODE=5.8805e-05,               data=4.2153e-05,               total_loss=1.0106e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 5.1601e-08, val_ODE: 6.1705e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011342], b: [0.00019526]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00641006607106312\n",
            "Epoch 885:\n",
            "IC=8.0184e-08,               ODE=6.0376e-05,               data=4.1636e-05,               total_loss=1.0209e-04\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "val_IC: 1.0364e-07, val_ODE: 5.9803e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011568], b: [0.0001839]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.0064828727296184\n",
            "Epoch 886:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "IC=8.5253e-08,               ODE=5.9112e-05,               data=4.2400e-05,               total_loss=1.0160e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 2.0009e-08, val_ODE: 6.0986e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011559], b: [0.00015708]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006438214667223338\n",
            "Epoch 887:\n",
            "IC=6.3746e-08,               ODE=5.9526e-05,               data=4.2046e-05,               total_loss=1.0164e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 6.5859e-08, val_ODE: 6.0643e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011563], b: [0.0001762]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006407313403124047\n",
            "Epoch 888:\n",
            "IC=4.6497e-08,               ODE=5.9554e-05,               data=4.2000e-05,               total_loss=1.0160e-04\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "val_IC: 5.2786e-08, val_ODE: 6.2005e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011523], b: [0.00019918]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006443897561659915\n",
            "Epoch 889:\n",
            "IC=5.7878e-08,               ODE=5.9678e-05,               data=4.2163e-05,               total_loss=1.0190e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.7434e-07, val_ODE: 6.1233e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011466], b: [0.00018095]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.0063933808104581534\n",
            "Epoch 890:\n",
            "IC=1.2997e-07,               ODE=5.9190e-05,               data=4.2229e-05,               total_loss=1.0155e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 5.6688e-08, val_ODE: 5.9924e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011535], b: [0.00014821]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006518534854567521\n",
            "Epoch 891:\n",
            "IC=7.0452e-08,               ODE=5.9387e-05,               data=4.1822e-05,               total_loss=1.0128e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3533e-08, val_ODE: 5.9969e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011466], b: [0.00018327]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0064687553283528055\n",
            "Epoch 892:\n",
            "IC=5.2846e-08,               ODE=5.9079e-05,               data=4.2502e-05,               total_loss=1.0163e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.3936e-07, val_ODE: 6.2021e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011442], b: [0.00019405]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006436800323092486\n",
            "Epoch 893:\n",
            "IC=1.1138e-07,               ODE=5.9346e-05,               data=4.2872e-05,               total_loss=1.0233e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.4907e-08, val_ODE: 6.1001e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011396], b: [0.00019044]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006437603211919668\n",
            "Epoch 894:\n",
            "IC=1.2846e-07,               ODE=5.9903e-05,               data=4.1958e-05,               total_loss=1.0199e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6880e-07, val_ODE: 6.0727e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001147], b: [0.00017906]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006492833608991465\n",
            "Epoch 895:\n",
            "IC=1.0858e-07,               ODE=6.0305e-05,               data=4.2427e-05,               total_loss=1.0284e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.2888e-08, val_ODE: 6.4958e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011287], b: [0.00017267]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006452799835351081\n",
            "Epoch 896:\n",
            "IC=2.5831e-07,               ODE=6.0841e-05,               data=4.1820e-05,               total_loss=1.0292e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "val_IC: 3.9977e-07, val_ODE: 5.9716e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001127], b: [0.00020389]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.006693196279272558\n",
            "Epoch 897:\n",
            "IC=2.0324e-07,               ODE=6.0811e-05,               data=4.2635e-05,               total_loss=1.0365e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.6691e-08, val_ODE: 6.1470e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001131], b: [0.00020542]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006395690096369851\n",
            "Epoch 898:\n",
            "IC=2.0931e-07,               ODE=6.0259e-05,               data=4.2132e-05,               total_loss=1.0260e-04\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 1.6823e-07, val_ODE: 6.1132e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011504], b: [0.00020043]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006433843306382567\n",
            "Epoch 899:\n",
            "IC=1.1896e-07,               ODE=5.9556e-05,               data=4.1897e-05,               total_loss=1.0157e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.8211e-08, val_ODE: 6.2758e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011456], b: [0.00019778]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006396515892480756\n",
            "Epoch 900:\n",
            "IC=2.2956e-07,               ODE=5.9640e-05,               data=4.2395e-05,               total_loss=1.0226e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.5077e-07, val_ODE: 6.0842e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011568], b: [0.0001758]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006453353609635062\n",
            "Epoch 901:\n",
            "IC=1.0548e-07,               ODE=6.0258e-05,               data=4.1910e-05,               total_loss=1.0227e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.9175e-08, val_ODE: 6.0818e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001145], b: [0.00021215]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006461848712891887\n",
            "Epoch 902:\n",
            "IC=7.0074e-08,               ODE=5.9180e-05,               data=4.2134e-05,               total_loss=1.0138e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 7.2708e-08, val_ODE: 6.0462e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001146], b: [0.00018255]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006371823522162279\n",
            "Epoch 903:\n",
            "IC=4.5931e-08,               ODE=5.8687e-05,               data=4.1705e-05,               total_loss=1.0044e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 9.6715e-09, val_ODE: 6.0553e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011513], b: [0.00015406]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006385606972095231\n",
            "Epoch 904:\n",
            "IC=7.9800e-08,               ODE=5.8930e-05,               data=4.2125e-05,               total_loss=1.0113e-04\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 3.0129e-07, val_ODE: 6.0868e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011322], b: [0.00017516]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006405655880880324\n",
            "Epoch 905:\n",
            "IC=8.6655e-08,               ODE=5.8969e-05,               data=4.1082e-05,               total_loss=1.0014e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 6.7468e-08, val_ODE: 6.0113e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011146], b: [0.00020081]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006380285298925089\n",
            "Epoch 906:\n",
            "IC=3.9203e-08,               ODE=5.8899e-05,               data=4.1250e-05,               total_loss=1.0019e-04\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "val_IC: 2.8477e-08, val_ODE: 5.9655e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011365], b: [0.00018408]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.006421070543343574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 907:\n",
            "IC=8.0212e-08,               ODE=5.8644e-05,               data=4.1314e-05,               total_loss=1.0004e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.1011e-08, val_ODE: 6.0580e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011125], b: [0.00016805]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006432226111035509\n",
            "Epoch 908:\n",
            "IC=1.4740e-07,               ODE=5.8534e-05,               data=4.2077e-05,               total_loss=1.0076e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.4539e-07, val_ODE: 6.0177e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011168], b: [0.00017263]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006369277683901982\n",
            "Epoch 909:\n",
            "IC=1.2196e-07,               ODE=5.9189e-05,               data=4.1468e-05,               total_loss=1.0078e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1823e-09, val_ODE: 6.0561e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011175], b: [0.00019443]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006484834048085095\n",
            "Epoch 910:\n",
            "IC=1.6096e-07,               ODE=5.9013e-05,               data=4.1727e-05,               total_loss=1.0090e-04\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.5661e-07, val_ODE: 5.9684e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0011137], b: [0.00016811]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006400155615999557\n",
            "Epoch 911:\n",
            "IC=1.4249e-07,               ODE=5.9275e-05,               data=4.1966e-05,               total_loss=1.0138e-04\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 1.8536e-07, val_ODE: 5.9305e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010934], b: [0.00018578]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.00643830362243797\n",
            "Epoch 912:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=7.4089e-08,               ODE=5.8859e-05,               data=4.1496e-05,               total_loss=1.0043e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1334e-08, val_ODE: 6.0311e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010931], b: [0.00016943]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006368362083847767\n",
            "Epoch 913:\n",
            "IC=8.4457e-08,               ODE=5.9043e-05,               data=4.1210e-05,               total_loss=1.0034e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1078e-07, val_ODE: 5.9491e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010989], b: [0.00017021]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.006448039510581577\n",
            "Epoch 914:\n",
            "IC=9.2282e-08,               ODE=5.8397e-05,               data=4.1381e-05,               total_loss=9.9871e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.8246e-08, val_ODE: 5.9811e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010874], b: [0.00018162]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006367330740262769\n",
            "Epoch 915:\n",
            "IC=1.1175e-07,               ODE=5.9292e-05,               data=4.1245e-05,               total_loss=1.0065e-04\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 7.1821e-08, val_ODE: 5.8535e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001081], b: [0.00018644]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "RMSE: 0.006507211895854506\n",
            "Epoch 916:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=1.1140e-07,               ODE=5.9501e-05,               data=4.2718e-05,               total_loss=1.0233e-04\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 2.3269e-07, val_ODE: 6.2671e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010748], b: [0.00017189]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "RMSE: 0.006411028471192813\n",
            "Epoch 917:\n",
            "IC=2.5606e-07,               ODE=6.0072e-05,               data=4.1807e-05,               total_loss=1.0214e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.6440e-07, val_ODE: 6.0352e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.00107], b: [0.00017418]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006425728938043652\n",
            "Epoch 918:\n",
            "IC=1.0034e-07,               ODE=5.9011e-05,               data=4.1796e-05,               total_loss=1.0091e-04\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.6461e-07, val_ODE: 5.9686e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010612], b: [0.00017258]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006423229682739848\n",
            "Epoch 919:\n",
            "IC=1.2889e-07,               ODE=5.9037e-05,               data=4.1252e-05,               total_loss=1.0042e-04\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8733e-08, val_ODE: 5.9129e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010736], b: [0.0001833]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006387188215209436\n",
            "Epoch 920:\n",
            "IC=5.1960e-08,               ODE=5.8185e-05,               data=4.1021e-05,               total_loss=9.9258e-05\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 2.1742e-08, val_ODE: 5.9522e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.001073], b: [0.00016091]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00635013940777443\n",
            "Epoch 921:\n",
            "IC=7.8610e-08,               ODE=5.8485e-05,               data=4.1411e-05,               total_loss=9.9975e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2710e-09, val_ODE: 5.9522e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010748], b: [0.00018298]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006403687886564375\n",
            "Epoch 922:\n",
            "IC=5.7102e-08,               ODE=5.8483e-05,               data=4.1082e-05,               total_loss=9.9623e-05\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 6.0058e-08, val_ODE: 5.9935e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010731], b: [0.00018676]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006356235955492365\n",
            "Epoch 923:\n",
            "IC=4.0534e-08,               ODE=5.8422e-05,               data=4.0831e-05,               total_loss=9.9293e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.0988e-08, val_ODE: 5.8867e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010593], b: [0.00015925]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006389503079182496\n",
            "Epoch 924:\n",
            "IC=1.1988e-07,               ODE=5.8249e-05,               data=4.1268e-05,               total_loss=9.9636e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 5.9225e-08, val_ODE: 6.0400e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010858], b: [0.00015454]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0063358197139078394\n",
            "Epoch 925:\n",
            "IC=9.6707e-08,               ODE=5.8972e-05,               data=4.1394e-05,               total_loss=1.0046e-04\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 2.7501e-08, val_ODE: 5.9999e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010598], b: [0.00015793]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.006400763190851701\n",
            "Epoch 926:\n",
            "IC=1.4005e-07,               ODE=5.8796e-05,               data=4.1038e-05,               total_loss=9.9974e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 9.9678e-08, val_ODE: 5.9443e-05, lr: 1.56e-04\n",
            "\n",
            "a: [-2.0010655], b: [0.00018236]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006340311411715742\n",
            "Epoch 927:\n",
            "IC=7.5550e-08,               ODE=5.7983e-05,               data=4.0850e-05,               total_loss=9.8909e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1079e-07, val_ODE: 5.8931e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010579], b: [0.00017454]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006393167454347826\n",
            "Epoch 928:\n",
            "IC=5.7479e-08,               ODE=5.7514e-05,               data=4.0831e-05,               total_loss=9.8403e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.1799e-08, val_ODE: 5.9352e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001064], b: [0.00017797]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006328290499627438\n",
            "Epoch 929:\n",
            "IC=5.5389e-08,               ODE=5.8125e-05,               data=4.0449e-05,               total_loss=9.8630e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.5901e-08, val_ODE: 5.8892e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010662], b: [0.0001793]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006355381931719695\n",
            "Epoch 930:\n",
            "IC=4.1539e-08,               ODE=5.7841e-05,               data=4.0605e-05,               total_loss=9.8488e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.5379e-08, val_ODE: 5.9426e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010633], b: [0.00017783]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006334335058734328\n",
            "Epoch 931:\n",
            "IC=1.0362e-07,               ODE=5.8205e-05,               data=4.0676e-05,               total_loss=9.8984e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1596e-07, val_ODE: 5.9313e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010614], b: [0.00016586]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006350872334906477\n",
            "Epoch 932:\n",
            "IC=6.4838e-08,               ODE=5.8355e-05,               data=4.0658e-05,               total_loss=9.9078e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.8536e-08, val_ODE: 5.8668e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010636], b: [0.0001765]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.0063685963424310816\n",
            "Epoch 933:\n",
            "IC=5.6127e-08,               ODE=5.8053e-05,               data=4.0670e-05,               total_loss=9.8778e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2435e-07, val_ODE: 5.9143e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010629], b: [0.00018072]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00635847737244415\n",
            "Epoch 934:\n",
            "IC=9.9594e-08,               ODE=5.7470e-05,               data=4.1130e-05,               total_loss=9.8700e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.2380e-08, val_ODE: 5.9441e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010638], b: [0.0001829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006308589792098765\n",
            "Epoch 935:\n",
            "IC=3.7529e-08,               ODE=5.8220e-05,               data=4.0378e-05,               total_loss=9.8635e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 7.2589e-08, val_ODE: 5.8684e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010664], b: [0.00017718]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006357444416524626\n",
            "Epoch 936:\n",
            "IC=6.8169e-08,               ODE=5.7573e-05,               data=4.0920e-05,               total_loss=9.8562e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8698e-08, val_ODE: 5.9607e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001062], b: [0.00017586]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006317475067432813\n",
            "Epoch 937:\n",
            "IC=4.9455e-08,               ODE=5.7843e-05,               data=4.0533e-05,               total_loss=9.8425e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0321e-07, val_ODE: 5.9755e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010724], b: [0.0001884]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006322780636267636\n",
            "Epoch 938:\n",
            "IC=5.9952e-08,               ODE=5.8047e-05,               data=4.0544e-05,               total_loss=9.8651e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 7.7972e-08, val_ODE: 5.8610e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010655], b: [0.0001801]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.00635259715541568\n",
            "Epoch 939:\n",
            "IC=6.6518e-08,               ODE=5.7814e-05,               data=4.0744e-05,               total_loss=9.8625e-05\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.1329e-08, val_ODE: 5.9980e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001046], b: [0.00018224]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006342958069947605\n",
            "Epoch 940:\n",
            "IC=1.5688e-07,               ODE=5.7835e-05,               data=4.0510e-05,               total_loss=9.8502e-05\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.1275e-08, val_ODE: 5.9220e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010526], b: [0.00017615]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006312994234626698\n",
            "Epoch 941:\n",
            "IC=9.9146e-08,               ODE=5.7949e-05,               data=4.0457e-05,               total_loss=9.8505e-05\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "val_IC: 2.5293e-08, val_ODE: 5.8359e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010533], b: [0.00017673]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.00638024703798506\n",
            "Epoch 942:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=5.4777e-08,               ODE=5.7559e-05,               data=4.0344e-05,               total_loss=9.7957e-05\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "val_IC: 3.8502e-08, val_ODE: 5.9472e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001065], b: [0.00017609]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006305076512632475\n",
            "Epoch 943:\n",
            "IC=5.6285e-08,               ODE=5.7453e-05,               data=4.0991e-05,               total_loss=9.8500e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.0242e-07, val_ODE: 5.9338e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010593], b: [0.00017003]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006310942620644922\n",
            "Epoch 944:\n",
            "IC=3.9935e-08,               ODE=5.8025e-05,               data=4.0545e-05,               total_loss=9.8610e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.6695e-08, val_ODE: 5.9813e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010543], b: [0.00018265]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006290844578293164\n",
            "Epoch 945:\n",
            "IC=8.2519e-08,               ODE=5.7567e-05,               data=4.0788e-05,               total_loss=9.8437e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.8711e-08, val_ODE: 5.9373e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010495], b: [0.00017694]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006325848885649704\n",
            "Epoch 946:\n",
            "IC=5.2387e-08,               ODE=5.7935e-05,               data=4.0822e-05,               total_loss=9.8810e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.7820e-07, val_ODE: 5.9847e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010583], b: [0.00018782]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006309331889505792\n",
            "Epoch 947:\n",
            "IC=5.6684e-08,               ODE=5.7596e-05,               data=4.0509e-05,               total_loss=9.8162e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.8284e-08, val_ODE: 5.8240e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010507], b: [0.00017457]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.006373614933476355\n",
            "Epoch 948:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=2.5301e-08,               ODE=5.7776e-05,               data=4.0339e-05,               total_loss=9.8140e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.2588e-08, val_ODE: 5.8406e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001057], b: [0.00017792]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006375158660289625\n",
            "Epoch 949:\n",
            "IC=3.8627e-08,               ODE=5.7517e-05,               data=4.0307e-05,               total_loss=9.7862e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0119e-07, val_ODE: 5.8903e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010386], b: [0.00018045]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006306372923308312\n",
            "Epoch 950:\n",
            "IC=6.7889e-08,               ODE=5.7620e-05,               data=4.0294e-05,               total_loss=9.7982e-05\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 8.2703e-08, val_ODE: 5.8508e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010405], b: [0.00017993]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006331585630243024\n",
            "Epoch 951:\n",
            "IC=6.2889e-08,               ODE=5.7456e-05,               data=4.0341e-05,               total_loss=9.7860e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 4.7406e-08, val_ODE: 5.9183e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.00104], b: [0.00018692]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006311628564811312\n",
            "Epoch 952:\n",
            "IC=1.3783e-07,               ODE=5.8044e-05,               data=4.0408e-05,               total_loss=9.8590e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 3.1965e-08, val_ODE: 5.7862e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010355], b: [0.00016999]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "RMSE: 0.006403998242243306\n",
            "Epoch 953:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.8032e-08,               ODE=5.7537e-05,               data=4.0327e-05,               total_loss=9.7932e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.0268e-08, val_ODE: 5.8268e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010378], b: [0.00016141]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006403217794662003\n",
            "Epoch 954:\n",
            "IC=3.2027e-08,               ODE=5.7765e-05,               data=4.0549e-05,               total_loss=9.8346e-05\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "val_IC: 5.8828e-08, val_ODE: 5.9149e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010438], b: [0.0001655]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006338496303923942\n",
            "Epoch 955:\n",
            "IC=6.7105e-08,               ODE=5.7658e-05,               data=4.0424e-05,               total_loss=9.8149e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.5612e-08, val_ODE: 5.8663e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010355], b: [0.00017184]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006298123595192517\n",
            "Epoch 956:\n",
            "IC=3.7521e-08,               ODE=5.7644e-05,               data=4.0448e-05,               total_loss=9.8130e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.8538e-08, val_ODE: 5.9234e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010386], b: [0.00015277]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006291472019643915\n",
            "Epoch 957:\n",
            "IC=4.5299e-08,               ODE=5.7341e-05,               data=4.0779e-05,               total_loss=9.8165e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 8.5325e-08, val_ODE: 6.0167e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010452], b: [0.00018697]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "RMSE: 0.006352833342483534\n",
            "Epoch 958:\n",
            "IC=6.4271e-08,               ODE=5.8039e-05,               data=4.0830e-05,               total_loss=9.8933e-05\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 4.6699e-08, val_ODE: 5.9319e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001039], b: [0.0001815]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.00627813161947748\n",
            "Epoch 959:\n",
            "IC=7.2950e-08,               ODE=5.7787e-05,               data=4.0459e-05,               total_loss=9.8320e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.1168e-08, val_ODE: 5.9016e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001038], b: [0.00016922]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006291503282823151\n",
            "Epoch 960:\n",
            "IC=8.9330e-08,               ODE=5.7653e-05,               data=4.0111e-05,               total_loss=9.7853e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2611e-07, val_ODE: 5.8688e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010326], b: [0.00016274]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006291819942702757\n",
            "Epoch 961:\n",
            "IC=9.0313e-08,               ODE=5.7294e-05,               data=4.0432e-05,               total_loss=9.7816e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.1681e-07, val_ODE: 5.9224e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010273], b: [0.0001778]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "RMSE: 0.006303050230164657\n",
            "Epoch 962:\n",
            "IC=8.3211e-08,               ODE=5.7781e-05,               data=4.0398e-05,               total_loss=9.8262e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 5.1950e-08, val_ODE: 5.9344e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010312], b: [0.00018043]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006288152577710374\n",
            "Epoch 963:\n",
            "IC=4.1742e-08,               ODE=5.7478e-05,               data=4.0287e-05,               total_loss=9.7806e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.4474e-08, val_ODE: 5.9176e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010169], b: [0.00017613]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "RMSE: 0.006294371930196077\n",
            "Epoch 964:\n",
            "IC=5.4314e-08,               ODE=5.8001e-05,               data=4.0113e-05,               total_loss=9.8168e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3374e-08, val_ODE: 5.8761e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010254], b: [0.00016868]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006327810330646922\n",
            "Epoch 965:\n",
            "IC=4.7005e-08,               ODE=5.7512e-05,               data=4.0688e-05,               total_loss=9.8247e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 7.2202e-08, val_ODE: 5.8948e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010269], b: [0.00016279]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006298962490017475\n",
            "Epoch 966:\n",
            "IC=1.4513e-07,               ODE=5.8136e-05,               data=4.0492e-05,               total_loss=9.8773e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 3.4632e-07, val_ODE: 5.9574e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010333], b: [0.00015375]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006288613488716123\n",
            "Epoch 967:\n",
            "IC=1.1122e-07,               ODE=5.7625e-05,               data=4.0354e-05,               total_loss=9.8090e-05\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "val_IC: 5.8375e-08, val_ODE: 5.8987e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010161], b: [0.00014798]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "RMSE: 0.006282658966977935\n",
            "Epoch 968:\n",
            "IC=8.9566e-08,               ODE=5.7396e-05,               data=4.1213e-05,               total_loss=9.8699e-05\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "val_IC: 5.5573e-08, val_ODE: 5.9876e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010207], b: [0.00015304]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "RMSE: 0.006299377877125803\n",
            "Epoch 969:\n",
            "IC=8.9330e-08,               ODE=5.7527e-05,               data=4.0193e-05,               total_loss=9.7810e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.0745e-08, val_ODE: 5.9072e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010176], b: [0.00016746]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.0062889550187093775\n",
            "Epoch 970:\n",
            "IC=8.9950e-08,               ODE=5.7868e-05,               data=4.0090e-05,               total_loss=9.8048e-05\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.3901e-07, val_ODE: 5.9082e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010273], b: [0.00016972]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006264184830147242\n",
            "Epoch 971:\n",
            "IC=1.8144e-07,               ODE=5.7443e-05,               data=4.0269e-05,               total_loss=9.7894e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 9.9608e-08, val_ODE: 5.8156e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001024], b: [0.0001753]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006318403402021983\n",
            "Epoch 972:\n",
            "IC=4.1530e-08,               ODE=5.7208e-05,               data=4.0366e-05,               total_loss=9.7615e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.7207e-08, val_ODE: 5.9178e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010226], b: [0.00016344]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0062785969562288765\n",
            "Epoch 973:\n",
            "IC=5.2408e-08,               ODE=5.7283e-05,               data=4.0207e-05,               total_loss=9.7543e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 2.3149e-08, val_ODE: 5.8714e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010161], b: [0.00017517]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006276497721997098\n",
            "Epoch 974:\n",
            "IC=4.8787e-08,               ODE=5.7729e-05,               data=3.9895e-05,               total_loss=9.7673e-05\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "val_IC: 1.4185e-07, val_ODE: 5.8798e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010264], b: [0.00017404]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.0062739228194299375\n",
            "Epoch 975:\n",
            "IC=5.7824e-08,               ODE=5.7293e-05,               data=4.0239e-05,               total_loss=9.7590e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 4.5295e-08, val_ODE: 5.8361e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010195], b: [0.00016427]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.00627858464055182\n",
            "Epoch 976:\n",
            "IC=5.5239e-08,               ODE=5.7411e-05,               data=4.0019e-05,               total_loss=9.7485e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.5210e-08, val_ODE: 5.8838e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001019], b: [0.00015859]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0062822849009850495\n",
            "Epoch 977:\n",
            "IC=4.5085e-08,               ODE=5.7302e-05,               data=3.9877e-05,               total_loss=9.7224e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.1245e-08, val_ODE: 5.8287e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010216], b: [0.00016171]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006278496671680218\n",
            "Epoch 978:\n",
            "IC=6.2664e-08,               ODE=5.7487e-05,               data=3.9718e-05,               total_loss=9.7267e-05\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 4.4319e-08, val_ODE: 5.8437e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010235], b: [0.0001764]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "RMSE: 0.0062773025419716666\n",
            "Epoch 979:\n",
            "IC=6.3142e-08,               ODE=5.6996e-05,               data=4.0339e-05,               total_loss=9.7399e-05\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "val_IC: 6.9474e-08, val_ODE: 5.8267e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001023], b: [0.00016243]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "RMSE: 0.006297105150123823\n",
            "Epoch 980:\n",
            "IC=2.8177e-08,               ODE=5.7460e-05,               data=3.9719e-05,               total_loss=9.7208e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.4658e-08, val_ODE: 5.8990e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001013], b: [0.00016139]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006286642598127937\n",
            "Epoch 981:\n",
            "IC=8.8432e-08,               ODE=5.7276e-05,               data=3.9662e-05,               total_loss=9.7027e-05\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 2.4604e-08, val_ODE: 5.8194e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001013], b: [0.00017305]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006302317087341628\n",
            "Epoch 982:\n",
            "IC=4.1217e-08,               ODE=5.7225e-05,               data=4.0381e-05,               total_loss=9.7648e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 4.4020e-08, val_ODE: 5.8433e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.001007], b: [0.00015804]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006323129750480947\n",
            "Epoch 983:\n",
            "IC=4.5136e-08,               ODE=5.7147e-05,               data=4.0439e-05,               total_loss=9.7631e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.0153e-07, val_ODE: 5.8802e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010068], b: [0.00016613]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.0062695755937264225\n",
            "Epoch 984:\n",
            "IC=6.7520e-08,               ODE=5.7075e-05,               data=3.9796e-05,               total_loss=9.6938e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 5.1572e-08, val_ODE: 5.8561e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009978], b: [0.00016938]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006264827483520621\n",
            "Epoch 985:\n",
            "IC=2.3647e-08,               ODE=5.7005e-05,               data=4.0444e-05,               total_loss=9.7472e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.3617e-07, val_ODE: 5.9171e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010102], b: [0.00016432]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006273142422228556\n",
            "Epoch 986:\n",
            "IC=1.2158e-07,               ODE=5.7483e-05,               data=4.0438e-05,               total_loss=9.8042e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.9716e-07, val_ODE: 5.8851e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010166], b: [0.0001567]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006266558927949391\n",
            "Epoch 987:\n",
            "IC=9.2203e-08,               ODE=5.7663e-05,               data=4.0103e-05,               total_loss=9.7858e-05\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 8.2890e-08, val_ODE: 5.8271e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010066], b: [0.00016726]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006255102323452265\n",
            "Epoch 988:\n",
            "IC=1.0140e-07,               ODE=5.7773e-05,               data=4.0031e-05,               total_loss=9.7906e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 1.8101e-07, val_ODE: 5.9668e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010092], b: [0.00017172]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "RMSE: 0.006266803639793169\n",
            "Epoch 989:\n",
            "IC=1.1571e-07,               ODE=5.7393e-05,               data=4.0201e-05,               total_loss=9.7710e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 1.2001e-07, val_ODE: 5.9594e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010016], b: [0.0001525]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006289744390469365\n",
            "Epoch 990:\n",
            "IC=1.6022e-07,               ODE=5.7285e-05,               data=4.0587e-05,               total_loss=9.8032e-05\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_IC: 3.1614e-07, val_ODE: 5.9843e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010045], b: [0.00016559]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.006289278392729745\n",
            "Epoch 991:\n",
            "IC=9.4586e-08,               ODE=5.7782e-05,               data=4.0149e-05,               total_loss=9.8025e-05\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 1.5344e-07, val_ODE: 5.9165e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009956], b: [0.00015592]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006260659481743213\n",
            "Epoch 992:\n",
            "IC=1.4892e-07,               ODE=5.7193e-05,               data=4.0516e-05,               total_loss=9.7858e-05\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "val_IC: 6.5174e-08, val_ODE: 5.8897e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0010052], b: [0.00016815]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "RMSE: 0.006247802120188633\n",
            "Epoch 993:\n",
            "IC=1.2448e-07,               ODE=5.7485e-05,               data=3.9755e-05,               total_loss=9.7365e-05\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "val_IC: 7.4098e-08, val_ODE: 5.7655e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009952], b: [0.00017014]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.006300987800030795\n",
            "Epoch 994:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=6.2348e-08,               ODE=5.6608e-05,               data=4.0297e-05,               total_loss=9.6968e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 8.4727e-08, val_ODE: 5.8536e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.000992], b: [0.00015185]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006256583322613763\n",
            "Epoch 995:\n",
            "IC=7.5060e-08,               ODE=5.7659e-05,               data=3.9629e-05,               total_loss=9.7362e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.1677e-07, val_ODE: 5.7550e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009987], b: [0.00016168]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.00638303733173953\n",
            "Epoch 996:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IC=4.6150e-08,               ODE=5.6749e-05,               data=4.0522e-05,               total_loss=9.7317e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 1.2479e-07, val_ODE: 5.8127e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009892], b: [0.00015773]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "RMSE: 0.006258588999150206\n",
            "Epoch 997:\n",
            "IC=9.2899e-08,               ODE=5.7420e-05,               data=3.9629e-05,               total_loss=9.7143e-05\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "val_IC: 4.9728e-08, val_ODE: 5.8657e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.000994], b: [0.00016916]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "RMSE: 0.006244234290594922\n",
            "Epoch 998:\n",
            "IC=6.8639e-08,               ODE=5.6696e-05,               data=4.0032e-05,               total_loss=9.6797e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.1394e-08, val_ODE: 5.8225e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009906], b: [0.00017729]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "RMSE: 0.006269063487752852\n",
            "Epoch 999:\n",
            "IC=5.5962e-08,               ODE=5.7144e-05,               data=4.0058e-05,               total_loss=9.7257e-05\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "val_IC: 2.0019e-08, val_ODE: 5.8629e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009801], b: [0.00016446]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "RMSE: 0.006254030386484153\n",
            "Epoch 1000:\n",
            "IC=8.9866e-08,               ODE=5.7319e-05,               data=3.9730e-05,               total_loss=9.7139e-05\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "val_IC: 8.4835e-08, val_ODE: 5.8641e-05, lr: 7.81e-05\n",
            "\n",
            "a: [-2.0009894], b: [0.0001828]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "RMSE: 0.006253265505343555\n"
          ]
        }
      ],
      "source": [
        "# Set up training configurations\n",
        "n_epochs = 1000\n",
        "IC_weight= tf.constant(1.0, dtype=tf.float32)\n",
        "ODE_weight= tf.constant(1.0, dtype=tf.float32)\n",
        "data_weight= tf.constant(1.0, dtype=tf.float32)\n",
        "loss_tracker = LossTracking()\n",
        "val_loss_hist = []\n",
        "a_list, b_list = [], []\n",
        "\n",
        "# Initial value for unknown parameters\n",
        "a_init, b_init = -1, 1\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate=2e-2)\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "\n",
        "    # Instantiate the PINN model\n",
        "    PINN = create_PINN(a_init=a_init, b_init=b_init)\n",
        "    PINN.compile(optimizer=optimizer)\n",
        "\n",
        "    # Configure callbacks\n",
        "    _callbacks = [keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=100),\n",
        "                 tf.keras.callbacks.ModelCheckpoint('PINN_model.h5', monitor='val_loss', save_best_only=True),\n",
        "                 PrintParameters()]\n",
        "    callbacks = tf.keras.callbacks.CallbackList(\n",
        "                    _callbacks, add_history=False, model=PINN)\n",
        "\n",
        "    # Start training process\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(f\"Epoch {epoch}:\")\n",
        "\n",
        "        for (X_ODE), (X, y) in zip(train_ds_ODE, train_ds_data):\n",
        "\n",
        "            # Calculate gradients\n",
        "            ODE_loss, IC_loss, data_loss, total_loss, gradients = train_step(X_ODE, X, y, IC_weight,\n",
        "                                                                             ODE_weight, data_weight, PINN)\n",
        "            # Gradient descent\n",
        "            PINN.optimizer.apply_gradients(zip(gradients, PINN.trainable_variables))\n",
        "\n",
        "            # Loss tracking\n",
        "            loss_tracker.update(total_loss, IC_loss, ODE_loss, data_loss)\n",
        "\n",
        "        # Loss summary\n",
        "        loss_tracker.history()\n",
        "        loss_tracker.print()\n",
        "        loss_tracker.reset()\n",
        "\n",
        "        # Parameter recording\n",
        "        a_list.append(PINN.layers[-1].a.numpy())\n",
        "        b_list.append(PINN.layers[-1].b.numpy())\n",
        "\n",
        "        ####### Validation\n",
        "        val_res = ODE_residual_calculator(tf.reshape(tf.linspace(0.0, 10.0, 1000), [-1, 1]), PINN)\n",
        "        val_ODE = tf.cast(tf.reduce_mean(tf.square(val_res)), tf.float32)\n",
        "\n",
        "        u_init=tf.constant([[1.0, 0.8, 0.5]])\n",
        "        val_pred_init, _ = PINN.predict(tf.zeros((1, 1)))\n",
        "        val_IC = tf.reduce_mean(tf.square(val_pred_init - u_init))\n",
        "        print(f\"val_IC: {val_IC.numpy():.4e}, val_ODE: {val_ODE.numpy():.4e}, lr: {PINN.optimizer.lr.numpy():.2e}\")\n",
        "\n",
        "        # Callback at the end of epoch\n",
        "        callbacks.on_epoch_end(epoch, logs={'val_loss': val_IC+val_ODE})\n",
        "        val_loss_hist.append(val_IC+val_ODE)\n",
        "\n",
        "        # Test dataset\n",
        "        pred_test, _ = PINN.predict(X_test, batch_size=12800)\n",
        "        print(f\"RMSE: {mean_squared_error(y_test.flatten(), pred_test.flatten(), squared=False)}\")\n",
        "\n",
        "\n",
        "        # Re-shuffle dataset\n",
        "        train_ds_data = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))\n",
        "        train_ds_data = train_ds_data.shuffle(10000).batch(data_batch_size)\n",
        "\n",
        "        train_ds_ODE = tf.data.Dataset.from_tensor_slices((X_train_ODE))\n",
        "        train_ds_ODE = train_ds_ODE.shuffle(10*N_collocation).batch(ODE_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7ce82fe0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "7ce82fe0",
        "outputId": "a5c39d73-681c-4256-c04a-5f10026e72c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# History\n",
        "%matplotlib inline\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "ax[0].plot(range(n_epochs), loss_tracker.loss_history['IC_loss'])\n",
        "ax[1].plot(range(n_epochs), loss_tracker.loss_history['ODE_loss'])\n",
        "ax[2].plot(range(n_epochs), loss_tracker.loss_history['Data_loss'])\n",
        "ax[0].set_title('IC Loss', fontsize=14)\n",
        "ax[1].set_title('ODE Loss', fontsize=14)\n",
        "ax[2].set_title('Data Loss', fontsize=14)\n",
        "for axs in ax:\n",
        "    axs.set_yscale('log')\n",
        "    axs.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "33e17f11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "33e17f11",
        "outputId": "3d668504-c946-4faf-b2e3-aad039ce4610"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Parameter history\n",
        "%matplotlib inline\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "ax[0].plot(range(n_epochs), a_list, lw=3)\n",
        "ax[0].set_ylabel('a', fontsize=16)\n",
        "ax[0].set_xlabel('Iterations', fontsize=16)\n",
        "ax[0].set_ylim((-2.2, -0.7))\n",
        "ax[0].axhline(y=-2, color='r', linestyle='--')\n",
        "\n",
        "ax[1].plot(range(n_epochs), b_list, lw=3)\n",
        "ax[1].set_ylabel('b', fontsize=16)\n",
        "ax[1].set_xlabel('Iterations', fontsize=16)\n",
        "ax[1].set_ylim((-0.2, 1.2))\n",
        "ax[1].axhline(y=0, color='r', linestyle='--')\n",
        "\n",
        "for axs in ax:\n",
        "    axs.tick_params(axis='both', which='major', labelsize=14)\n",
        "    axs.grid(True)\n",
        "fig.suptitle('Parameter Evolution', fontsize=16)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de65ed98",
      "metadata": {
        "id": "de65ed98"
      },
      "source": [
        "#### Collect input/output of f-NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b707d118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b707d118",
        "outputId": "446ed941-ffcd-4619-d02c-8945ed4a48b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        }
      ],
      "source": [
        "t = np.linspace(0, 10, 10000).reshape(-1, 1)\n",
        "u, f = PINN.predict(t, batch_size=12800)\n",
        "\n",
        "# Configure dataframe\n",
        "df = pd.DataFrame({\n",
        "    't': t.flatten(),\n",
        "    'u1': u[:, 0],\n",
        "    'u2': u[:, 1],\n",
        "    'u3': u[:, 2],\n",
        "    'f1': f[:, 0],\n",
        "    'f2': f[:, 1]\n",
        "})\n",
        "df.to_csv('f_NN_IO.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "62a4d0e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "62a4d0e9",
        "outputId": "89ccd6ea-fba3-43b1-907a-ac4339ca3acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'f2')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sanity check\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
        "\n",
        "ax[0].scatter(np.exp(-df.t.values/10)*df.u2.values*df.u3.values, df.f1)\n",
        "ax[0].set_title('f1')\n",
        "\n",
        "ax[1].scatter(df.u1.values*df.u3.values, df.f2)\n",
        "ax[1].set_title('f2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "076f98ad",
      "metadata": {
        "id": "076f98ad"
      },
      "source": [
        "#### Assess accuracy: u prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5af3d332",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5af3d332",
        "outputId": "000466e1-cc2d-425b-8655-2a684b52ba5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "t = np.linspace(0, 10, 5000).reshape(-1, 1)\n",
        "pred_u, pred_f = PINN.predict(t, batch_size=12800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "571b7bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "571b7bc1",
        "outputId": "392f9a8c-801a-4f23-ce02-9f53ea4af12a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "ax[0].scatter(t.flatten(), y_test[:, 0], label='truth')\n",
        "ax[0].scatter(t.flatten(), pred_u[:, 0], label='predict')\n",
        "ax[0].set_title('u1')\n",
        "ax[1].scatter(t.flatten(), y_test[:, 1], label='truth')\n",
        "ax[1].scatter(t.flatten(), pred_u[:, 1], label='predict')\n",
        "ax[1].set_title('u2')\n",
        "ax[2].scatter(t.flatten(), y_test[:, 2], label='truth')\n",
        "ax[2].scatter(t.flatten(), pred_u[:, 2], label='predict')\n",
        "ax[2].set_title('u3')\n",
        "\n",
        "for axs in ax:\n",
        "    axs.set_xlabel('Time (t)', fontsize=14)\n",
        "    axs.set_ylabel('u values', fontsize=14)\n",
        "    axs.tick_params(axis='both', which='major', labelsize=12)\n",
        "    axs.legend(fontsize=12, frameon=True)\n",
        "    axs.grid(True)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87e76e31",
      "metadata": {
        "id": "87e76e31"
      },
      "source": [
        "#### Access accuracy: f prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2e9e1aa8",
      "metadata": {
        "id": "2e9e1aa8"
      },
      "outputs": [],
      "source": [
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(X_test)\n",
        "    u, f = PINN(X_test)\n",
        "\n",
        "# Calculate gradients\n",
        "dudt = tape.batch_jacobian(u, X_test)[:, :, 0]\n",
        "du1_dt, du2_dt, du3_dt = dudt[:, :1], dudt[:, 1:2], dudt[:, 2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "236650a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "236650a6",
        "outputId": "a72eb0a7-6f79-4c49-8fa4-ed349edb1172"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "ax[0].scatter(du1_dt.numpy().flatten(), f[:, 0].numpy())\n",
        "ax[0].set_xlabel('$du_1$/dt', fontsize=14)\n",
        "ax[0].set_ylabel('$f_1$', fontsize=14)\n",
        "ax[1].scatter(du2_dt.numpy().flatten(), f[:, 1].numpy())\n",
        "ax[1].set_xlabel('$du_2$/dt', fontsize=14)\n",
        "ax[1].set_ylabel('$f_2$', fontsize=14)\n",
        "\n",
        "for axs in ax:\n",
        "    axs.tick_params(axis='both', which='major', labelsize=12)\n",
        "    axs.grid(True)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic Regression"
      ],
      "metadata": {
        "id": "8SkjPSdRneY5"
      },
      "id": "8SkjPSdRneY5"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "78fe71d8",
      "metadata": {
        "id": "78fe71d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa43bcf0-f574-4630-e058-0a2baae27476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysr\n",
            "  Downloading pysr-0.17.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/75.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.12)\n",
            "Requirement already satisfied: pandas<3.0.0,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.2.2)\n",
            "Collecting juliacall==0.9.15 (from pysr)\n",
            "  Downloading juliacall-0.9.15-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (8.1.7)\n",
            "Requirement already satisfied: setuptools>=50.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (67.7.2)\n",
            "Collecting juliapkg~=0.1.8 (from juliacall==0.9.15->pysr)\n",
            "  Downloading juliapkg-0.1.10-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy<2.0.0,>=1.0.0->pysr) (1.3.0)\n",
            "Collecting semantic-version~=2.9 (from juliapkg~=0.1.8->juliacall==0.9.15->pysr)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0.0,>=0.21.0->pysr) (1.16.0)\n",
            "Installing collected packages: semantic-version, juliapkg, juliacall, pysr\n",
            "Successfully installed juliacall-0.9.15 juliapkg-0.1.10 pysr-0.17.1 semantic-version-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pysr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pysr import PySRRegressor\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/f_NN_IO.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjeGN8XnTeO",
        "outputId": "e09a191c-bf7b-44e1-f2a6-c7da541c782c"
      },
      "id": "dGjeGN8XnTeO",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[juliapkg] Locating Julia ^1.6.1\n",
            "[juliapkg] Querying Julia versions from https://julialang-s3.julialang.org/bin/versions.json\n",
            "[juliapkg] WARNING: About to install Julia 1.10.2 to /root/.julia/environments/pyjuliapkg/pyjuliapkg/install.\n",
            "[juliapkg]   If you use juliapkg in more than one environment, you are likely to have Julia\n",
            "[juliapkg]   installed in multiple locations. It is recommended to install JuliaUp\n",
            "[juliapkg]   (https://github.com/JuliaLang/juliaup) or Julia (https://julialang.org/downloads)\n",
            "[juliapkg]   yourself.\n",
            "[juliapkg] Downloading Julia from https://julialang-s3.julialang.org/bin/linux/x64/1.10/julia-1.10.2-linux-x86_64.tar.gz\n",
            "             downloaded 99.9 MB of 161.8 MB\n",
            "             download complete\n",
            "[juliapkg] Verifying download\n",
            "[juliapkg] Installing Julia 1.10.2 to /root/.julia/environments/pyjuliapkg/pyjuliapkg/install\n",
            "[juliapkg] Using Julia 1.10.2 at /root/.julia/environments/pyjuliapkg/pyjuliapkg/install/bin/julia\n",
            "[juliapkg] Using Julia project at /root/.julia/environments/pyjuliapkg\n",
            "[juliapkg] Installing packages:\n",
            "           julia> import Pkg\n",
            "           julia> Pkg.add([Pkg.PackageSpec(name=\"PythonCall\", uuid=\"6099a3de-0909-46bc-b1f4-468b9a2dfc0d\"), Pkg.PackageSpec(name=\"SymbolicRegression\", uuid=\"8254be44-1295-4e6a-a16d-46603ac705cb\"), Pkg.PackageSpec(name=\"ClusterManagers\", uuid=\"34f1f09b-3a8b-5176-ab39-66d58a4d544e\"), Pkg.PackageSpec(name=\"Serialization\", uuid=\"9e88b42a-f829-5b0c-bbe9-9e923198166b\"), Pkg.PackageSpec(name=\"Zygote\", uuid=\"e88e6eb3-aa80-5325-afca-941959d7151f\")])\n",
            "           julia> Pkg.resolve()\n",
            "           julia> Pkg.precompile()\n",
            "Detected Jupyter notebook. Loading juliacall extension. Set `PYSR_AUTOLOAD_EXTENSIONS=no` to disable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sywJObTDrT-B",
        "outputId": "2a7d7427-c7a2-46dd-f15c-e16b6c014893"
      },
      "id": "sywJObTDrT-B",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          t        u1        u2        u3        f1        f2\n",
              "0  0.000000  0.999696  0.800049  0.500400  0.400939  0.440344\n",
              "1  0.001000  1.000096  0.800490  0.498799  0.400007  0.439146\n",
              "2  0.002000  1.000495  0.800930  0.497197  0.399071  0.437946\n",
              "3  0.003000  1.000894  0.801369  0.495594  0.398132  0.436745\n",
              "4  0.004000  1.001291  0.801806  0.493988  0.397189  0.435542\n",
              "5  0.005001  1.001687  0.802243  0.492382  0.396243  0.434337\n",
              "6  0.006001  1.002083  0.802678  0.490773  0.395293  0.433131\n",
              "7  0.007001  1.002478  0.803111  0.489163  0.394340  0.431923\n",
              "8  0.008001  1.002871  0.803544  0.487552  0.393383  0.430713\n",
              "9  0.009001  1.003264  0.803976  0.485939  0.392422  0.429502"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-425ea5db-9cb0-4de2-adc1-4c5bf4ed79e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>u1</th>\n",
              "      <th>u2</th>\n",
              "      <th>u3</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999696</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>0.500400</td>\n",
              "      <td>0.400939</td>\n",
              "      <td>0.440344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001000</td>\n",
              "      <td>1.000096</td>\n",
              "      <td>0.800490</td>\n",
              "      <td>0.498799</td>\n",
              "      <td>0.400007</td>\n",
              "      <td>0.439146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002000</td>\n",
              "      <td>1.000495</td>\n",
              "      <td>0.800930</td>\n",
              "      <td>0.497197</td>\n",
              "      <td>0.399071</td>\n",
              "      <td>0.437946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003000</td>\n",
              "      <td>1.000894</td>\n",
              "      <td>0.801369</td>\n",
              "      <td>0.495594</td>\n",
              "      <td>0.398132</td>\n",
              "      <td>0.436745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004000</td>\n",
              "      <td>1.001291</td>\n",
              "      <td>0.801806</td>\n",
              "      <td>0.493988</td>\n",
              "      <td>0.397189</td>\n",
              "      <td>0.435542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.005001</td>\n",
              "      <td>1.001687</td>\n",
              "      <td>0.802243</td>\n",
              "      <td>0.492382</td>\n",
              "      <td>0.396243</td>\n",
              "      <td>0.434337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.006001</td>\n",
              "      <td>1.002083</td>\n",
              "      <td>0.802678</td>\n",
              "      <td>0.490773</td>\n",
              "      <td>0.395293</td>\n",
              "      <td>0.433131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.007001</td>\n",
              "      <td>1.002478</td>\n",
              "      <td>0.803111</td>\n",
              "      <td>0.489163</td>\n",
              "      <td>0.394340</td>\n",
              "      <td>0.431923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.008001</td>\n",
              "      <td>1.002871</td>\n",
              "      <td>0.803544</td>\n",
              "      <td>0.487552</td>\n",
              "      <td>0.393383</td>\n",
              "      <td>0.430713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.009001</td>\n",
              "      <td>1.003264</td>\n",
              "      <td>0.803976</td>\n",
              "      <td>0.485939</td>\n",
              "      <td>0.392422</td>\n",
              "      <td>0.429502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-425ea5db-9cb0-4de2-adc1-4c5bf4ed79e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-425ea5db-9cb0-4de2-adc1-4c5bf4ed79e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-425ea5db-9cb0-4de2-adc1-4c5bf4ed79e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-659bc2ab-c520-4412-8e60-781b349088a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-659bc2ab-c520-4412-8e60-781b349088a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-659bc2ab-c520-4412-8e60-781b349088a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8871843983470025,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          6.252625262526252,\n          4.684468446844685,\n          1.7311731173117313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10534110583895621,\n        \"min\": 0.65100867,\n        \"max\": 1.0625501,\n        \"num_unique_values\": 9983,\n        \"samples\": [\n          0.70255536,\n          0.9381852,\n          0.65225965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5885812635577384,\n        \"min\": -0.8769355,\n        \"max\": 0.87043107,\n        \"num_unique_values\": 9996,\n        \"samples\": [\n          0.42870083,\n          0.063872844,\n          -0.48512152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9142548997666464,\n        \"min\": -1.2407514,\n        \"max\": 1.2449626,\n        \"num_unique_values\": 9996,\n        \"samples\": [\n          -1.0777912,\n          1.2358885,\n          1.0313421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2374535645800577,\n        \"min\": -0.49894774,\n        \"max\": 0.4271402,\n        \"num_unique_values\": 9998,\n        \"samples\": [\n          -0.10401569,\n          -0.14583306,\n          0.10045342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7132814872731097,\n        \"min\": -0.9554632,\n        \"max\": 0.9324334,\n        \"num_unique_values\": 9990,\n        \"samples\": [\n          0.86887115,\n          0.27844688,\n          -0.34730658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Symbolic regression model\n",
        "model = PySRRegressor(\n",
        "    niterations=20,  # < Increase me for better results\n",
        "    binary_operators=[\"+\", \"*\"],\n",
        "    unary_operators=[\n",
        "        \"cos\",\n",
        "        \"exp\",\n",
        "        \"sin\",\n",
        "        \"inv(x) = 1/x\",\n",
        "    ],\n",
        "    extra_sympy_mappings={\"inv\": lambda x: 1 / x},\n",
        "    loss=\"L1DistLoss()\",\n",
        "    model_selection=\"score\",\n",
        "    complexity_of_operators={\n",
        "        \"sin\": 3, \"cos\": 3, \"exp\": 3,\n",
        "        \"inv(x) = 1/x\": 3\n",
        "    }\n",
        ")\n",
        "\n",
        "# NN for f1\n",
        "X = df.iloc[:, :4].to_numpy()\n",
        "f1 = df.loc[:, 'f1'].to_numpy()\n",
        "\n",
        "model.fit(X, f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YRwHKIJTnOc6",
        "outputId": "644c6fbf-7bb8-4ac7-e566-66b30191e850"
      },
      "id": "YRwHKIJTnOc6",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:857: FutureWarning: loss has been renamed to elementwise_loss in PySRRegressor. Please use that instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1297: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling Julia backend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ Info: Started!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expressions evaluated per second: 7.900e+02\n",
            "Head worker occupation: 97.2%. This is high, and will prevent efficient resource usage. Increase `ncyclesperiteration` to reduce load on head worker.\n",
            "Progress: 3 / 300 total iterations (1.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.014e-01  1.594e+01  y = -0.03497\n",
            "3           1.371e-01  1.925e-01  y = (x₃ * x₂)\n",
            "5           6.784e-02  3.517e-01  y = ((x₃ * x₂) * 0.68361)\n",
            "7           6.640e-02  1.071e-02  y = ((0.52929 * (x₃ * x₂)) * 1.2296)\n",
            "8           6.543e-02  1.473e-02  y = (x₃ * (x₂ * cos(0.91068)))\n",
            "10          6.533e-02  7.094e-04  y = ((0.52929 * sin(x₃ * x₂)) * 1.2296)\n",
            "13          6.522e-02  5.706e-04  y = sin((sin(0.52929) * (x₃ * x₂)) * 1.2296)\n",
            "14          6.471e-02  7.935e-03  y = (sin(sin(sin(x₃ * x₂))) * 0.68361)\n",
            "17          6.449e-02  1.122e-03  y = ((cos(cos(0.18275) * (x₃ * x₂)) * (x₃ * x₂)) * 0.68361)\n",
            "19          6.424e-02  1.931e-03  y = ((cos((0.082699 * cos(x₂)) * x₀) * (0.52929 + 0.020794)) *...\n",
            "                                   (x₃ * x₂))\n",
            "20          5.818e-02  9.902e-02  y = ((x₃ * (0.69636 * cos(cos(inv(0.89999 + x₀) + x₁)))) * x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 1.200e+03\n",
            "Head worker occupation: 1.3%\n",
            "Progress: 8 / 300 total iterations (2.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.014e-01  1.594e+01  y = -0.034148\n",
            "3           1.371e-01  1.924e-01  y = (x₃ * x₂)\n",
            "5           6.784e-02  3.517e-01  y = ((x₃ * x₂) * 0.68361)\n",
            "7           6.640e-02  1.071e-02  y = ((0.52929 * (x₃ * x₂)) * 1.2296)\n",
            "8           6.543e-02  1.473e-02  y = (x₃ * (x₂ * cos(0.91068)))\n",
            "10          6.533e-02  7.094e-04  y = ((0.52929 * sin(x₃ * x₂)) * 1.2296)\n",
            "13          6.522e-02  5.706e-04  y = sin((sin(0.52929) * (x₃ * x₂)) * 1.2296)\n",
            "14          6.471e-02  7.935e-03  y = (sin(sin(sin(x₃ * x₂))) * 0.68361)\n",
            "16          6.028e-02  3.543e-02  y = ((x₂ * x₃) * cos(cos(exp(-0.56341 * x₀))))\n",
            "18          5.655e-02  3.192e-02  y = (((x₂ * x₃) * cos(sin(exp(0.034406 * x₀)))) * 1.101)\n",
            "20          5.572e-02  7.366e-03  y = ((x₂ * x₃) * cos(sin(exp(0.034406 * ((x₃ + -0.85484) + x₀)...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.080e+03\n",
            "Head worker occupation: 1.0%\n",
            "Progress: 18 / 300 total iterations (6.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.013e-01  1.594e+01  y = -0.013875\n",
            "3           1.371e-01  1.921e-01  y = (x₃ * x₂)\n",
            "5           6.784e-02  3.517e-01  y = ((x₃ * x₂) * 0.68361)\n",
            "7           6.543e-02  1.808e-02  y = (((x₂ * x₃) * 0.50797) * 1.2075)\n",
            "10          6.533e-02  4.730e-04  y = ((0.52929 * sin(x₃ * x₂)) * 1.2296)\n",
            "13          6.522e-02  5.706e-04  y = sin((sin(0.52929) * (x₃ * x₂)) * 1.2296)\n",
            "14          6.471e-02  7.935e-03  y = (sin(sin(sin(x₃ * x₂))) * 0.68361)\n",
            "16          6.028e-02  3.543e-02  y = ((x₂ * x₃) * cos(cos(exp(-0.56341 * x₀))))\n",
            "18          5.655e-02  3.192e-02  y = (((x₂ * x₃) * cos(sin(exp(0.034406 * x₀)))) * 1.101)\n",
            "20          5.572e-02  7.366e-03  y = ((x₂ * x₃) * cos(sin(exp(0.034406 * ((x₃ + -0.85484) + x₀)...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.210e+03\n",
            "Head worker occupation: 0.9%\n",
            "Progress: 32 / 300 total iterations (10.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.019237\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.540e-02  1.922e-04  y = (0.65271 * sin(x₃ * x₂))\n",
            "10          6.533e-02  4.872e-04  y = ((0.52929 * sin(x₃ * x₂)) * 1.2296)\n",
            "11          6.453e-02  1.245e-02  y = (0.65271 * sin(sin(x₃ * x₂)))\n",
            "13          6.452e-02  3.868e-05  y = ((0.52929 * sin(sin(x₃ * x₂))) * 1.2296)\n",
            "16          6.028e-02  2.266e-02  y = ((x₂ * x₃) * cos(cos(exp(-0.56341 * x₀))))\n",
            "18          5.655e-02  3.192e-02  y = (((x₂ * x₃) * cos(sin(exp(0.034406 * x₀)))) * 1.101)\n",
            "20          5.572e-02  7.366e-03  y = ((x₂ * x₃) * cos(sin(exp(0.034406 * ((x₃ + -0.85484) + x₀)...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.790e+03\n",
            "Head worker occupation: 0.8%\n",
            "Progress: 48 / 300 total iterations (16.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.523e-02  2.773e-03  y = sin(0.61801 * (x₃ * x₂))\n",
            "10          6.497e-02  1.985e-03  y = ((sin(x₃ * x₂) * 0.95494) * 0.6553)\n",
            "11          6.453e-02  6.872e-03  y = (0.65271 * sin(sin(x₃ * x₂)))\n",
            "12          5.522e-02  1.556e-01  y = (x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "15          5.018e-02  3.192e-02  y = sin(x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.380e+03\n",
            "Head worker occupation: 0.8%\n",
            "Progress: 60 / 300 total iterations (20.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.497e-02  6.709e-03  y = (sin(x₂ * x₃) * 0.63744)\n",
            "10          6.497e-02  1.708e-05  y = ((sin(x₃ * x₂) * 0.95494) * 0.6553)\n",
            "11          6.453e-02  6.872e-03  y = (0.65271 * sin(sin(x₃ * x₂)))\n",
            "12          5.522e-02  1.556e-01  y = (x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "15          5.018e-02  3.192e-02  y = sin(x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.250e+03\n",
            "Head worker occupation: 0.7%\n",
            "Progress: 76 / 300 total iterations (25.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "11          6.453e-02  2.071e-03  y = (0.65271 * sin(sin(x₃ * x₂)))\n",
            "12          5.522e-02  1.556e-01  y = (x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "15          5.018e-02  3.192e-02  y = sin(x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.790e+03\n",
            "Head worker occupation: 0.7%\n",
            "Progress: 90 / 300 total iterations (30.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "11          6.453e-02  2.071e-03  y = (0.65271 * sin(sin(x₃ * x₂)))\n",
            "12          5.522e-02  1.556e-01  y = (x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀))))\n",
            "13          3.896e-02  3.490e-01  y = sin(x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "14          3.366e-02  1.460e-01  y = ((x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀)))) * x₁)\n",
            "17          3.147e-02  2.247e-02  y = ((x₃ * sin(x₂ * cos(0.76974 * (-0.16899 * x₀)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.410e+03\n",
            "Head worker occupation: 0.6%\n",
            "Progress: 101 / 300 total iterations (33.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.231e-02  2.141e-01  y = (x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "13          3.896e-02  2.755e-02  y = sin(x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "14          3.366e-02  1.460e-01  y = ((x₃ * (x₂ * cos(0.76974 * (-0.16899 * x₀)))) * x₁)\n",
            "17          3.147e-02  2.247e-02  y = ((x₃ * sin(x₂ * cos(0.76974 * (-0.16899 * x₀)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.100e+03\n",
            "Head worker occupation: 0.6%\n",
            "Progress: 113 / 300 total iterations (37.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.231e-02  2.141e-01  y = (x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "12          3.923e-02  3.783e-02  y = (x₃ * (x₂ * cos((-0.16899 + 0.32036) * x₀)))\n",
            "13          3.314e-02  1.687e-01  y = (x₃ * (x₂ * sin(cos(-0.16899 * x₀))))\n",
            "14          2.766e-02  1.807e-01  y = ((x₃ * x₁) * (x₂ * cos((-0.16899 * x₀) * -0.85193)))\n",
            "15          2.636e-02  4.805e-02  y = (x₃ * (x₂ * sin(cos((-0.16899 + 0.32036) * x₀))))\n",
            "18          2.530e-02  1.376e-02  y = ((x₃ * x₁) * (x₂ * cos((-0.16899 * x₁) * (x₀ + (x₃ * x₂)))...\n",
            "                                  ))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.620e+03\n",
            "Head worker occupation: 0.6%\n",
            "Progress: 127 / 300 total iterations (42.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.231e-02  2.141e-01  y = (x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "12          3.923e-02  3.783e-02  y = (x₃ * (x₂ * cos((-0.16899 + 0.32036) * x₀)))\n",
            "13          3.314e-02  1.687e-01  y = (x₃ * (x₂ * sin(cos(-0.16899 * x₀))))\n",
            "14          2.766e-02  1.807e-01  y = ((x₃ * x₁) * (x₂ * cos((-0.16899 * x₀) * -0.85193)))\n",
            "15          2.636e-02  4.805e-02  y = (x₃ * (x₂ * sin(cos((-0.16899 + 0.32036) * x₀))))\n",
            "18          2.530e-02  1.376e-02  y = ((x₃ * x₁) * (x₂ * cos((-0.16899 * x₁) * (x₀ + (x₃ * x₂)))...\n",
            "                                  ))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.720e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 143 / 300 total iterations (47.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.231e-02  2.141e-01  y = (x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "12          2.133e-02  3.425e-01  y = (x₃ * (x₂ * exp((-0.16899 * 0.62571) * x₀)))\n",
            "17          2.124e-02  8.348e-04  y = (x₃ * (x₂ * exp((-0.16899 * cos(0.78685)) * (x₀ + -0.24442...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.500e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 155 / 300 total iterations (51.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.231e-02  2.141e-01  y = (x₃ * (x₂ * cos(-0.16899 * x₀)))\n",
            "12          2.133e-02  3.425e-01  y = (x₃ * (x₂ * exp((-0.16899 * 0.62571) * x₀)))\n",
            "17          2.124e-02  8.348e-04  y = (x₃ * (x₂ * exp((-0.16899 * cos(0.78685)) * (x₀ + -0.24442...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.540e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 167 / 300 total iterations (55.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.493e-02  7.401e-03  y = (sin(x₂ * x₃) * 0.62859)\n",
            "10          4.207e-02  2.169e-01  y = (x₃ * (x₂ * exp(-0.16159 * x₀)))\n",
            "12          2.133e-02  3.397e-01  y = (x₃ * (x₂ * exp((-0.16899 * 0.62571) * x₀)))\n",
            "17          2.124e-02  8.348e-04  y = (x₃ * (x₂ * exp((-0.16899 * cos(0.78685)) * (x₀ + -0.24442...\n",
            "                                  ))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.770e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 180 / 300 total iterations (60.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.491e-02  7.662e-03  y = (sin(x₃ * x₂) * 0.63192)\n",
            "10          3.643e-02  2.887e-01  y = (x₃ * (x₂ * exp(-0.15076 * x₀)))\n",
            "12          2.133e-02  2.677e-01  y = (x₃ * (x₂ * exp((-0.16899 * 0.62571) * x₀)))\n",
            "15          2.060e-02  1.160e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "18          2.016e-02  7.258e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.550e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 190 / 300 total iterations (63.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.491e-02  7.662e-03  y = (sin(x₃ * x₂) * 0.63192)\n",
            "10          2.322e-02  5.139e-01  y = (x₃ * (x₂ * exp(-0.11778 * x₀)))\n",
            "12          2.133e-02  4.254e-02  y = (x₃ * (x₂ * exp((-0.16899 * 0.62571) * x₀)))\n",
            "14          2.091e-02  1.003e-02  y = (x₃ * (x₂ * (exp(-0.11399 * (x₀ + 0.041659)) * 1.0342)))\n",
            "15          2.060e-02  1.476e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "18          2.016e-02  7.258e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.230e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 205 / 300 total iterations (68.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.541e-02  1.260e-04  y = (((x₃ + -0.0029506) * 0.61192) * x₂)\n",
            "8           6.491e-02  7.662e-03  y = (sin(x₃ * x₂) * 0.63192)\n",
            "10          2.235e-02  5.332e-01  y = (x₃ * (x₂ * exp(-0.11399 * x₀)))\n",
            "12          2.104e-02  3.016e-02  y = (x₃ * (x₂ * exp(-0.11778 * (-0.37302 + x₀))))\n",
            "14          2.091e-02  3.158e-03  y = (x₃ * (x₂ * (exp(-0.11399 * (x₀ + 0.041659)) * 1.0342)))\n",
            "15          2.060e-02  1.476e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "18          2.016e-02  7.258e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.090e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 218 / 300 total iterations (72.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "10          2.235e-02  5.332e-01  y = (x₃ * (x₂ * exp(-0.11399 * x₀)))\n",
            "12          2.096e-02  3.212e-02  y = (x₃ * (x₂ * (exp(-0.11399 * x₀) * 1.0342)))\n",
            "14          2.091e-02  1.201e-03  y = (x₃ * (x₂ * (exp(-0.11399 * (x₀ + 0.041659)) * 1.0342)))\n",
            "15          2.060e-02  1.476e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "18          2.016e-02  7.258e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.560e+03\n",
            "Head worker occupation: 0.5%\n",
            "Progress: 234 / 300 total iterations (78.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "9           5.811e-02  1.106e-01  y = (x₃ * (x₂ * (1.0004 + (-0.11399 * x₀))))\n",
            "10          2.235e-02  9.557e-01  y = (x₃ * (x₂ * exp(-0.11399 * x₀)))\n",
            "12          2.096e-02  3.212e-02  y = (x₃ * (x₂ * (exp(-0.11399 * x₀) * 1.0342)))\n",
            "14          2.091e-02  1.201e-03  y = (x₃ * (x₂ * (exp(-0.11399 * (x₀ + 0.041659)) * 1.0342)))\n",
            "15          2.060e-02  1.476e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "18          2.016e-02  7.258e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.560e+03\n",
            "Head worker occupation: 0.4%\n",
            "Progress: 249 / 300 total iterations (83.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "9           5.811e-02  1.106e-01  y = (x₃ * (x₂ * (1.0004 + (-0.11399 * x₀))))\n",
            "10          2.133e-02  1.002e+00  y = (x₃ * (x₂ * exp(-0.10566 * x₀)))\n",
            "12          2.096e-02  8.904e-03  y = (x₃ * (x₂ * (exp(-0.11399 * x₀) * 1.0342)))\n",
            "14          2.091e-02  1.201e-03  y = (x₃ * (x₂ * (exp(-0.11399 * (x₀ + 0.041659)) * 1.0342)))\n",
            "15          2.060e-02  1.476e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "17          2.044e-02  3.919e-03  y = sin((x₃ * exp(-0.11399 * (x₀ + (x₁ * -0.54674)))) * x₂)\n",
            "18          2.016e-02  1.393e-02  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.560e+03\n",
            "Head worker occupation: 0.4%\n",
            "Progress: 261 / 300 total iterations (87.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "9           5.811e-02  1.106e-01  y = (x₃ * (x₂ * (1.0004 + (-0.11399 * x₀))))\n",
            "10          2.133e-02  1.002e+00  y = (x₃ * (x₂ * exp(-0.10566 * x₀)))\n",
            "12          2.096e-02  8.904e-03  y = (x₃ * (x₂ * (exp(-0.11399 * x₀) * 1.0342)))\n",
            "14          2.091e-02  1.224e-03  y = (x₃ * (x₂ * exp(-0.11399 * ((x₀ + -0.11399) + -0.11399))))\n",
            "15          2.060e-02  1.471e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "17          2.044e-02  3.919e-03  y = sin((x₃ * exp(-0.11399 * (x₀ + (x₁ * -0.54674)))) * x₂)\n",
            "18          2.016e-02  1.393e-02  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.680e+03\n",
            "Head worker occupation: 0.4%\n",
            "Progress: 276 / 300 total iterations (92.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "9           5.811e-02  1.106e-01  y = (x₃ * (x₂ * (1.0004 + (-0.11399 * x₀))))\n",
            "10          2.132e-02  1.003e+00  y = (x₃ * (x₂ * exp(-0.10636 * x₀)))\n",
            "12          2.091e-02  9.645e-03  y = ((x₃ * exp(-0.11399 * (x₀ + -0.22244))) * x₂)\n",
            "14          2.091e-02  7.251e-05  y = (x₃ * (x₂ * exp(-0.11399 * ((x₀ + -0.11399) + -0.11399))))\n",
            "15          2.060e-02  1.471e-02  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "17          2.044e-02  3.919e-03  y = sin((x₃ * exp(-0.11399 * (x₀ + (x₁ * -0.54674)))) * x₂)\n",
            "18          2.016e-02  1.393e-02  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.410e+03\n",
            "Head worker occupation: 0.4%\n",
            "Progress: 286 / 300 total iterations (95.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           2.012e-01  1.594e+01  y = -0.021079\n",
            "3           1.371e-01  1.919e-01  y = (x₃ * x₂)\n",
            "5           6.543e-02  3.698e-01  y = ((x₂ * x₃) * 0.6133)\n",
            "7           6.491e-02  3.951e-03  y = ((x₃ * (x₂ + -0.021173)) * 0.63192)\n",
            "8           6.491e-02  1.156e-05  y = (sin(x₃ * x₂) * 0.63192)\n",
            "9           5.811e-02  1.106e-01  y = (x₃ * (x₂ * (1.0004 + (-0.11399 * x₀))))\n",
            "10          2.132e-02  1.003e+00  y = (x₃ * (x₂ * exp(-0.10636 * x₀)))\n",
            "12          2.090e-02  9.767e-03  y = (x₃ * (x₂ * exp(-0.11399 * (x₀ + -0.23465))))\n",
            "15          2.060e-02  4.871e-03  y = sin(x₃ * (x₂ * exp(-0.11778 * (-0.53605 + x₀))))\n",
            "17          2.044e-02  3.919e-03  y = sin((x₃ * exp(-0.11399 * (x₀ + (x₁ * -0.54674)))) * x₂)\n",
            "18          2.016e-02  1.393e-02  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * (x...\n",
            "                                  ₀ + x₃))))))\n",
            "20          1.988e-02  6.937e-03  y = ((x₃ * 1.0764) * (x₂ * exp(-0.15076 * (x₀ + (-0.15076 * ((...\n",
            "                                  x₀ + x₃) + x₃))))))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PySRRegressor.equations_ = [\n",
              "\t    pick     score                                           equation  \\\n",
              "\t0         0.000000                                        -0.02107861   \n",
              "\t1         0.191903                                          (x3 * x2)   \n",
              "\t2         0.369787                            ((x2 * x3) * 0.6132991)   \n",
              "\t3         0.003951          ((x3 * (x2 + -0.021173326)) * 0.63191724)   \n",
              "\t4         0.000012                        (sin(x3 * x2) * 0.63191724)   \n",
              "\t5         0.110604     (x3 * (x2 * (1.0003778 + (-0.11399094 * x0))))   \n",
              "\t6   >>>>  1.002972                (x3 * (x2 * exp(-0.10635711 * x0)))   \n",
              "\t7         0.009767  (x3 * (x2 * exp(-0.11399094 * (x0 + -0.2346462...   \n",
              "\t8         0.004878  sin(x3 * (x2 * exp(-0.117780805 * (x0 + -0.510...   \n",
              "\t9         0.009735  (x3 * (x2 * (sin(exp(-0.12999047 * x0)) * (1.2...   \n",
              "\t10        0.002281  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t11        0.006937  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t\n",
              "\t        loss  complexity  \n",
              "\t0   0.201200           1  \n",
              "\t1   0.137071           3  \n",
              "\t2   0.065426           5  \n",
              "\t3   0.064911           7  \n",
              "\t4   0.064910           8  \n",
              "\t5   0.058114           9  \n",
              "\t6   0.021315          10  \n",
              "\t7   0.020903          12  \n",
              "\t8   0.020599          15  \n",
              "\t9   0.020202          17  \n",
              "\t10  0.020156          18  \n",
              "\t11  0.019878          20  \n",
              "]"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PySRRegressor.equations_ = [\n",
              "\t    pick     score                                           equation  \\\n",
              "\t0         0.000000                                        -0.02107861   \n",
              "\t1         0.191903                                          (x3 * x2)   \n",
              "\t2         0.369787                            ((x2 * x3) * 0.6132991)   \n",
              "\t3         0.003951          ((x3 * (x2 + -0.021173326)) * 0.63191724)   \n",
              "\t4         0.000012                        (sin(x3 * x2) * 0.63191724)   \n",
              "\t5         0.110604     (x3 * (x2 * (1.0003778 + (-0.11399094 * x0))))   \n",
              "\t6   &gt;&gt;&gt;&gt;  1.002972                (x3 * (x2 * exp(-0.10635711 * x0)))   \n",
              "\t7         0.009767  (x3 * (x2 * exp(-0.11399094 * (x0 + -0.2346462...   \n",
              "\t8         0.004878  sin(x3 * (x2 * exp(-0.117780805 * (x0 + -0.510...   \n",
              "\t9         0.009735  (x3 * (x2 * (sin(exp(-0.12999047 * x0)) * (1.2...   \n",
              "\t10        0.002281  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t11        0.006937  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t\n",
              "\t        loss  complexity  \n",
              "\t0   0.201200           1  \n",
              "\t1   0.137071           3  \n",
              "\t2   0.065426           5  \n",
              "\t3   0.064911           7  \n",
              "\t4   0.064910           8  \n",
              "\t5   0.058114           9  \n",
              "\t6   0.021315          10  \n",
              "\t7   0.020903          12  \n",
              "\t8   0.020599          15  \n",
              "\t9   0.020202          17  \n",
              "\t10  0.020156          18  \n",
              "\t11  0.019878          20  \n",
              "]</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PySRRegressor</label><div class=\"sk-toggleable__content\"><pre>PySRRegressor.equations_ = [\n",
              "\t    pick     score                                           equation  \\\n",
              "\t0         0.000000                                        -0.02107861   \n",
              "\t1         0.191903                                          (x3 * x2)   \n",
              "\t2         0.369787                            ((x2 * x3) * 0.6132991)   \n",
              "\t3         0.003951          ((x3 * (x2 + -0.021173326)) * 0.63191724)   \n",
              "\t4         0.000012                        (sin(x3 * x2) * 0.63191724)   \n",
              "\t5         0.110604     (x3 * (x2 * (1.0003778 + (-0.11399094 * x0))))   \n",
              "\t6   &gt;&gt;&gt;&gt;  1.002972                (x3 * (x2 * exp(-0.10635711 * x0)))   \n",
              "\t7         0.009767  (x3 * (x2 * exp(-0.11399094 * (x0 + -0.2346462...   \n",
              "\t8         0.004878  sin(x3 * (x2 * exp(-0.117780805 * (x0 + -0.510...   \n",
              "\t9         0.009735  (x3 * (x2 * (sin(exp(-0.12999047 * x0)) * (1.2...   \n",
              "\t10        0.002281  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t11        0.006937  ((x3 * 1.0763566) * (x2 * exp(-0.1507572 * (x0...   \n",
              "\t\n",
              "\t        loss  complexity  \n",
              "\t0   0.201200           1  \n",
              "\t1   0.137071           3  \n",
              "\t2   0.065426           5  \n",
              "\t3   0.064911           7  \n",
              "\t4   0.064910           8  \n",
              "\t5   0.058114           9  \n",
              "\t6   0.021315          10  \n",
              "\t7   0.020903          12  \n",
              "\t8   0.020599          15  \n",
              "\t9   0.020202          17  \n",
              "\t10  0.020156          18  \n",
              "\t11  0.019878          20  \n",
              "]</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :4].to_numpy()\n",
        "f2 = df.loc[:, 'f2'].to_numpy()\n",
        "\n",
        "model.fit(X, f2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PBlWyMCgqhTT",
        "outputId": "b2e366f2-9e31-4891-a125-e0eedcd41fca"
      },
      "id": "PBlWyMCgqhTT",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1822: UserWarning: The discovered expressions are being reset. Please set `warm_start=True` if you wish to continue to start a search where you left off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1297: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "[ Info: Started!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expressions evaluated per second: 2.130e+03\n",
            "Head worker occupation: 0.1%\n",
            "Progress: 6 / 300 total iterations (2.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.236e-02  2.532e-02  y = ((x₃ * 0.99533) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.570e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 22 / 300 total iterations (7.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.236e-02  2.532e-02  y = ((x₃ * 0.99533) * x₁)\n",
            "12          1.228e-02  9.517e-04  y = ((x₃ * x₁) * exp(0.03656 * (-1.7886 * 0.1336)))\n",
            "14          1.220e-02  3.014e-03  y = ((x₃ * x₁) * exp((x₁ * -0.85258) * (0.10589 * 0.1336)))\n",
            "16          1.213e-02  3.087e-03  y = ((x₃ * x₁) * exp((-0.85258 * ((0.10589 * 0.1336) * 0.85885...\n",
            "                                  )) * x₁))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.560e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 33 / 300 total iterations (11.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.235e-02  2.563e-02  y = ((x₃ * 0.99525) * x₁)\n",
            "12          1.228e-02  8.651e-04  y = ((x₃ * x₁) * exp(0.03656 * (-1.7886 * 0.1336)))\n",
            "14          1.218e-02  4.080e-03  y = ((x₃ * x₁) * exp(0.03656 * (-1.7886 * (0.1336 * x₁))))\n",
            "16          1.213e-02  2.021e-03  y = ((x₃ * x₁) * exp((-0.85258 * ((0.10589 * 0.1336) * 0.85885...\n",
            "                                  )) * x₁))\n",
            "17          1.198e-02  1.245e-02  y = ((x₃ * x₁) * cos((x₁ * x₂) * (exp(x₂) * 0.1336)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.310e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 50 / 300 total iterations (16.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.235e-02  2.563e-02  y = ((x₃ * 0.99525) * x₁)\n",
            "12          1.228e-02  8.716e-04  y = ((x₃ * x₁) * exp(-0.032569 * (-0.49547 * -0.54101)))\n",
            "13          1.219e-02  7.352e-03  y = ((x₃ * x₁) * cos(x₁ * sin(0.18038)))\n",
            "14          1.199e-02  1.617e-02  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ * (x₁ * x₁))))\n",
            "15          1.186e-02  1.117e-02  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ + inv(-0.31128))))\n",
            "17          1.185e-02  2.453e-04  y = ((x₃ * x₁) * cos((-0.032569 * inv(0.49772)) * (x₀ * -0.311...\n",
            "                                  28)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.320e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 62 / 300 total iterations (20.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99281)\n",
            "12          1.213e-02  8.274e-04  y = ((x₃ * cos((x₁ * -0.19061) * 0.8542)) * x₁)\n",
            "14          1.199e-02  5.597e-03  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ * (x₁ * x₁))))\n",
            "15          1.186e-02  1.117e-02  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ + inv(-0.31128))))\n",
            "16          1.184e-02  1.025e-03  y = ((x₃ * x₁) * cos(-0.032569 * (((x₃ * x₀) * x₁) * x₁)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.970e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 77 / 300 total iterations (25.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.219e-02  1.078e-05  y = ((x₃ * x₁) * cos(x₁ * 0.18038))\n",
            "12          1.213e-02  2.868e-03  y = ((x₃ * cos((x₁ * -0.19061) * 0.8542)) * x₁)\n",
            "14          1.199e-02  5.597e-03  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ * (x₁ * x₁))))\n",
            "15          1.186e-02  1.117e-02  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ + inv(-0.31128))))\n",
            "16          1.184e-02  1.025e-03  y = ((x₃ * x₁) * cos(-0.032569 * (((x₃ * x₀) * x₁) * x₁)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 6.080e+03\n",
            "Head worker occupation: 0.2%\n",
            "Progress: 92 / 300 total iterations (30.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "12          1.197e-02  1.269e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.78561)))\n",
            "14          1.189e-02  3.318e-03  y = ((x₃ * cos((-0.017618 * (x₀ + 2.6701)) * x₁)) * x₁)\n",
            "15          1.186e-02  2.555e-03  y = ((x₃ * x₁) * cos(-0.032569 * (x₀ + inv(-0.31128))))\n",
            "16          1.184e-02  1.025e-03  y = ((x₃ * x₁) * cos(-0.032569 * (((x₃ * x₀) * x₁) * x₁)))\n",
            "17          1.180e-02  3.718e-03  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + 0.9715...\n",
            "                                  6)))\n",
            "20          1.162e-02  5.263e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.930e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 102 / 300 total iterations (34.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "12          1.197e-02  1.269e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.78561)))\n",
            "13          1.185e-02  9.378e-03  y = ((x₃ * x₁) * cos(cos(x₀) * 0.18038))\n",
            "16          1.184e-02  2.792e-04  y = ((x₃ * x₁) * cos(-0.032569 * (((x₃ * x₀) * x₁) * x₁)))\n",
            "17          1.180e-02  3.718e-03  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + 0.9715...\n",
            "                                  6)))\n",
            "20          1.162e-02  5.263e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.600e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 115 / 300 total iterations (38.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "12          1.184e-02  6.530e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "15          1.181e-02  7.850e-04  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * cos(0.78561))))\n",
            "17          1.180e-02  5.283e-04  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + 0.9715...\n",
            "                                  6)))\n",
            "19          1.172e-02  3.505e-03  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + (x₂ + ...\n",
            "                                  0.0038131))))\n",
            "20          1.162e-02  8.778e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.690e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 128 / 300 total iterations (42.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "12          1.184e-02  6.530e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "15          1.181e-02  7.850e-04  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * cos(0.78561))))\n",
            "17          1.180e-02  5.283e-04  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + 0.9715...\n",
            "                                  6)))\n",
            "19          1.172e-02  3.505e-03  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + (x₂ + ...\n",
            "                                  0.0038131))))\n",
            "20          1.162e-02  8.778e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.470e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 141 / 300 total iterations (47.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "12          1.184e-02  6.530e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "15          1.181e-02  7.850e-04  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * cos(0.78561))))\n",
            "17          1.180e-02  5.283e-04  y = ((x₃ * x₁) * cos(-0.032569 * ((x₀ * cos(0.97156)) + 0.9715...\n",
            "                                  6)))\n",
            "18          1.171e-02  7.923e-03  y = ((x₃ * cos((-0.017618 * (x₀ + (0.57131 + (x₃ + x₂)))) * x₃...\n",
            "                                  )) * x₁)\n",
            "20          1.162e-02  3.932e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.670e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 158 / 300 total iterations (52.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "11          1.187e-02  1.093e-02  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.184e-02  2.128e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "14          1.176e-02  3.584e-03  y = ((x₃ * x₁) * cos((x₀ + x₂) * (-0.032569 * 0.78561)))\n",
            "18          1.171e-02  1.042e-03  y = ((x₃ * cos((-0.017618 * (x₀ + (0.57131 + (x₃ + x₂)))) * x₃...\n",
            "                                  )) * x₁)\n",
            "20          1.162e-02  3.932e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.880e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 170 / 300 total iterations (56.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "11          1.187e-02  1.093e-02  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.184e-02  2.128e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "14          1.176e-02  3.584e-03  y = ((x₃ * x₁) * cos((x₀ + x₂) * (-0.032569 * 0.78561)))\n",
            "16          1.171e-02  1.793e-03  y = ((x₃ * x₁) * cos(-0.025526 * ((x₃ * x₁) * (x₃ + x₀))))\n",
            "18          1.171e-02  2.902e-04  y = ((x₃ * cos((-0.017618 * (x₀ + (0.57131 + (x₃ + x₂)))) * x₃...\n",
            "                                  )) * x₁)\n",
            "20          1.162e-02  3.932e-03  y = ((x₃ * cos((-0.017618 * (x₀ + ((0.57131 + (x₃ + x₂)) + 2.6...\n",
            "                                  701))) * x₁)) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.940e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 184 / 300 total iterations (61.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "11          1.187e-02  1.093e-02  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.184e-02  2.128e-03  y = ((x₃ * x₁) * cos(x₀ * (-0.032569 * 0.63394)))\n",
            "14          1.176e-02  3.584e-03  y = ((x₃ * x₁) * cos((x₀ + x₂) * (-0.032569 * 0.78561)))\n",
            "16          1.166e-02  4.056e-03  y = ((x₃ * x₁) * cos(((x₀ + x₂) * (-0.032569 * 0.78561)) * x₁)...\n",
            "                                  )\n",
            "18          1.160e-02  2.611e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (1.0813 + x₂)) + (x₁ + x₂)))) ...\n",
            "                                  * x₁)\n",
            "20          1.152e-02  3.391e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (0.24861 + (1.4782 + x₂))) + (...\n",
            "                                  x₃ + x₂)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 6.390e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 202 / 300 total iterations (67.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * x₁) * 0.99279)\n",
            "10          1.200e-02  3.286e-03  y = ((x₃ * cos(-0.017618 * x₀)) * x₁)\n",
            "11          1.187e-02  1.093e-02  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.181e-02  4.925e-03  y = ((x₃ * cos((0.017313 * x₀) * -1.3103)) * x₁)\n",
            "14          1.176e-02  2.186e-03  y = ((x₃ * x₁) * cos((x₀ + x₂) * (-0.032569 * 0.78561)))\n",
            "16          1.165e-02  4.452e-03  y = ((x₃ * x₁) * cos(((x₀ + x₂) * -0.032569) * (x₁ * -0.8038))...\n",
            "                                  )\n",
            "17          1.164e-02  1.360e-03  y = ((x₃ * x₁) * cos((x₀ + x₂) * (-0.032569 * sin(0.78561))))\n",
            "18          1.160e-02  3.070e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (1.0813 + x₂)) + (x₁ + x₂)))) ...\n",
            "                                  * x₁)\n",
            "19          1.140e-02  1.742e-02  y = ((x₃ * x₁) * cos(-0.025526 * (((cos(x₀) * x₃) * x₁) * x₀))...\n",
            "                                  )\n",
            "20          1.138e-02  1.684e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (1.0813 + (x₂ * x₀))) + (x₁ + ...\n",
            "                                  x₃)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.930e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 212 / 300 total iterations (70.667%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.162e-02  5.492e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.2757))))\n",
            "18          1.159e-02  7.089e-04  y = ((x₃ * cos(0.01656 * ((x₀ + 1.4693) + ((x₁ + x₃) + x₂)))) ...\n",
            "                                  * x₁)\n",
            "19          1.140e-02  1.650e-02  y = ((x₃ * x₁) * cos(-0.025526 * (((cos(x₀) * x₃) * x₁) * x₀))...\n",
            "                                  )\n",
            "20          1.138e-02  1.684e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (1.0813 + (x₂ * x₀))) + (x₁ + ...\n",
            "                                  x₃)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.910e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 229 / 300 total iterations (76.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.162e-02  5.492e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.2757))))\n",
            "18          1.159e-02  7.089e-04  y = ((x₃ * cos(0.01656 * ((x₀ + 1.4693) + ((x₁ + x₃) + x₂)))) ...\n",
            "                                  * x₁)\n",
            "19          1.140e-02  1.650e-02  y = ((x₃ * x₁) * cos(-0.025526 * (((cos(x₀) * x₃) * x₁) * x₀))...\n",
            "                                  )\n",
            "20          1.138e-02  1.684e-03  y = ((x₃ * cos(0.01656 * ((x₀ + (1.0813 + (x₂ * x₀))) + (x₁ + ...\n",
            "                                  x₃)))) * x₁)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.670e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 241 / 300 total iterations (80.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.162e-02  5.492e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.2757))))\n",
            "16          1.155e-02  3.201e-03  y = ((x₃ * x₁) * cos(-0.025526 * ((x₀ + (x₂ + -1.2757)) + x₃))...\n",
            "                                  )\n",
            "17          1.121e-02  3.009e-02  y = ((x₃ * x₁) * cos(-0.025526 * ((cos(x₀) * x₃) * x₀)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.770e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 258 / 300 total iterations (86.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.162e-02  5.492e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.2757))))\n",
            "16          1.155e-02  3.201e-03  y = ((x₃ * x₁) * cos(-0.025526 * ((x₀ + (x₂ + -1.2757)) + x₃))...\n",
            "                                  )\n",
            "17          1.121e-02  3.009e-02  y = ((x₃ * x₁) * cos(-0.025526 * ((cos(x₀) * x₃) * x₀)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 5.580e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 271 / 300 total iterations (90.333%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.162e-02  5.492e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.2757))))\n",
            "16          1.155e-02  3.201e-03  y = ((x₃ * x₁) * cos(-0.025526 * ((x₀ + (x₂ + -1.2757)) + x₃))...\n",
            "                                  )\n",
            "17          1.121e-02  3.009e-02  y = ((x₃ * x₁) * cos(-0.025526 * ((cos(x₀) * x₃) * x₀)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 6.100e+03\n",
            "Head worker occupation: 0.3%\n",
            "Progress: 285 / 300 total iterations (95.000%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           1.704e-01  1.594e+01  y = x₃\n",
            "3           1.300e-02  1.287e+00  y = (x₃ * x₁)\n",
            "5           1.220e-02  3.195e-02  y = ((x₃ * 0.99279) * x₁)\n",
            "10          1.196e-02  3.896e-03  y = ((x₃ * x₁) * cos(-0.025526 * x₀))\n",
            "11          1.187e-02  7.880e-03  y = ((x₃ + ((0.015087 * x₃) * (-0.12291 * x₀))) * x₁)\n",
            "12          1.175e-02  9.730e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + x₂)))\n",
            "14          1.161e-02  5.922e-03  y = ((x₃ * x₁) * cos(-0.025526 * (x₀ + (x₂ + -1.0401))))\n",
            "16          1.149e-02  5.244e-03  y = ((x₃ * x₁) * cos(-0.025526 * ((x₀ + (x₂ + -1.2757)) + x₂))...\n",
            "                                  )\n",
            "17          1.121e-02  2.515e-02  y = ((x₃ * x₁) * cos(-0.025526 * ((cos(x₀) * x₃) * x₀)))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PySRRegressor.equations_ = [\n",
              "\t   pick     score                                           equation  \\\n",
              "\t0        0.000000                                                 x3   \n",
              "\t1  >>>>  1.286630                                          (x3 * x1)   \n",
              "\t2        0.031950                           ((x3 * 0.99278754) * x1)   \n",
              "\t3        0.003896               ((x3 * x1) * cos(-0.025526183 * x0))   \n",
              "\t4        0.007880  ((x3 + ((0.015087071 * x3) * (-0.12290903 * x0...   \n",
              "\t5        0.009730        ((x3 * x1) * cos(-0.025526183 * (x0 + x2)))   \n",
              "\t6        0.005922  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + -1...   \n",
              "\t7        0.005414  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + (x...   \n",
              "\t8        0.024809  ((x3 * x1) * cos(-0.025526183 * ((cos(x0) * x3...   \n",
              "\t\n",
              "\t       loss  complexity  \n",
              "\t0  0.170414           1  \n",
              "\t1  0.013000           3  \n",
              "\t2  0.012196           5  \n",
              "\t3  0.011960          10  \n",
              "\t4  0.011866          11  \n",
              "\t5  0.011751          12  \n",
              "\t6  0.011613          14  \n",
              "\t7  0.011488          16  \n",
              "\t8  0.011207          17  \n",
              "]"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PySRRegressor.equations_ = [\n",
              "\t   pick     score                                           equation  \\\n",
              "\t0        0.000000                                                 x3   \n",
              "\t1  &gt;&gt;&gt;&gt;  1.286630                                          (x3 * x1)   \n",
              "\t2        0.031950                           ((x3 * 0.99278754) * x1)   \n",
              "\t3        0.003896               ((x3 * x1) * cos(-0.025526183 * x0))   \n",
              "\t4        0.007880  ((x3 + ((0.015087071 * x3) * (-0.12290903 * x0...   \n",
              "\t5        0.009730        ((x3 * x1) * cos(-0.025526183 * (x0 + x2)))   \n",
              "\t6        0.005922  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + -1...   \n",
              "\t7        0.005414  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + (x...   \n",
              "\t8        0.024809  ((x3 * x1) * cos(-0.025526183 * ((cos(x0) * x3...   \n",
              "\t\n",
              "\t       loss  complexity  \n",
              "\t0  0.170414           1  \n",
              "\t1  0.013000           3  \n",
              "\t2  0.012196           5  \n",
              "\t3  0.011960          10  \n",
              "\t4  0.011866          11  \n",
              "\t5  0.011751          12  \n",
              "\t6  0.011613          14  \n",
              "\t7  0.011488          16  \n",
              "\t8  0.011207          17  \n",
              "]</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PySRRegressor</label><div class=\"sk-toggleable__content\"><pre>PySRRegressor.equations_ = [\n",
              "\t   pick     score                                           equation  \\\n",
              "\t0        0.000000                                                 x3   \n",
              "\t1  &gt;&gt;&gt;&gt;  1.286630                                          (x3 * x1)   \n",
              "\t2        0.031950                           ((x3 * 0.99278754) * x1)   \n",
              "\t3        0.003896               ((x3 * x1) * cos(-0.025526183 * x0))   \n",
              "\t4        0.007880  ((x3 + ((0.015087071 * x3) * (-0.12290903 * x0...   \n",
              "\t5        0.009730        ((x3 * x1) * cos(-0.025526183 * (x0 + x2)))   \n",
              "\t6        0.005922  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + -1...   \n",
              "\t7        0.005414  ((x3 * x1) * cos(-0.025526183 * (x0 + (x2 + (x...   \n",
              "\t8        0.024809  ((x3 * x1) * cos(-0.025526183 * ((cos(x0) * x3...   \n",
              "\t\n",
              "\t       loss  complexity  \n",
              "\t0  0.170414           1  \n",
              "\t1  0.013000           3  \n",
              "\t2  0.012196           5  \n",
              "\t3  0.011960          10  \n",
              "\t4  0.011866          11  \n",
              "\t5  0.011751          12  \n",
              "\t6  0.011613          14  \n",
              "\t7  0.011488          16  \n",
              "\t8  0.011207          17  \n",
              "]</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}